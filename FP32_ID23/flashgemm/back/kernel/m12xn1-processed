".macro    KERNEL12x1_PACK_K1                                \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm4, %%xmm20         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm4, %%xmm21         \n"

"   prefetcht0         256(%%rax)                            \n"

"   movss           16(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm4, %%xmm22         \n"

"   movss           20(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm4, %%xmm23         \n"

"   movss           24(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm4, %%xmm24         \n"

"   movss           28(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm4, %%xmm25         \n"

"   movss           32(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm4, %%xmm26         \n"

"    leaq      (%%rbx, %%r8, 4), %%rbx                       \n"// B

"   movss           36(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm4, %%xmm27         \n"

"   movss           40(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm4, %%xmm28         \n"

"   movss           44(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm4, %%xmm29         \n"
"   movss           (%%rbx), %%xmm6                          \n"
"    addq              $48, %%rax                            \n"

"   movss           (%%rax), %%xmm0                          \n"
"   vfmadd231ps              %%xmm2, %%xmm4, %%xmm30         \n"

"   movss           4(%%rax), %%xmm1                         \n"
"   vfmadd231ps              %%xmm3, %%xmm4, %%xmm31         \n"
"   vmovss           %%xmm4, (%%rbp)                         \n"
"    addq              $4, %%rbp                             \n"//64->16                         

".endm                                                       \n"

".macro    KERNEL12x1_PACK_K2                                \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm20         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm21         \n"

"   movss           16(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm22         \n"

"   prefetcht0         256(%%rax)                            \n"

"   movss           20(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm23         \n"

"   movss           24(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm24         \n"

"   movss           28(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm25         \n"

"   movss           32(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm26         \n"

"    leaq      (%%rbx, %%r8, 4), %%rbx                       \n"// B

"   movss           36(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm27         \n"

"   prefetcht0         4(%%rbx)                              \n"//                  

"   movss           40(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm28         \n"

"   movss           44(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm29         \n"
"   movss           (%%rbx), %%xmm4                          \n"
"    addq              $48, %%rax                            \n"

"   movss           (%%rax), %%xmm0                          \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm30         \n"

"   movss           4(%%rax), %%xmm1                         \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm31         \n"
"   vmovss           %%xmm6, (%%rbp)                         \n"
"    addq              $4, %%rbp                             \n"//64->16                         

".endm                                                       \n"

".macro    KERNEL12x1_PACK_END_K                             \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm20         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm21         \n"

"   movss           16(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm22         \n"

"   prefetcht0         256(%%rax)                            \n"

"   movss           20(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm23         \n"

"   movss           24(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm24         \n"

"   movss           28(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm25         \n"

"   movss           32(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm26         \n"

"   movss           36(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm27         \n"

"   movss           40(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm28         \n"

"   movss           44(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm29         \n"
"    addq              $48, %%rax                            \n"

"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm30         \n"
"   vmovss           %%xmm6, (%%rbp)                         \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm31         \n"

".endm                                                       \n"

//-----------------------------------------------------------------------

".macro    KERNEL12x1_K1                                     \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm4, %%xmm20         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm4, %%xmm21         \n"

"   prefetcht0         256(%%rax)                            \n"

"   movss           16(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm4, %%xmm22         \n"

"   movss           20(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm4, %%xmm23         \n"

"   movss           24(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm4, %%xmm24         \n"

"   movss           28(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm4, %%xmm25         \n"

"   movss           32(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm4, %%xmm26         \n"

"    addq              $4, %%rbx                             \n"// B

"   movss           36(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm4, %%xmm27         \n"

"   movss           40(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm4, %%xmm28         \n"

"   movss           44(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm4, %%xmm29         \n"
"   movss           (%%rbx), %%xmm6                          \n"
"    addq              $48, %%rax                            \n"

"   movss           (%%rax), %%xmm0                          \n"
"   vfmadd231ps              %%xmm2, %%xmm4, %%xmm30         \n"

"   movss           4(%%rax), %%xmm1                         \n"
"   vfmadd231ps              %%xmm3, %%xmm4, %%xmm31         \n"

".endm                                                       \n"

".macro    KERNEL12x1_K2                                     \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm20         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm21         \n"

"   movss           16(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm22         \n"

"   prefetcht0         256(%%rax)                            \n"

"   movss           20(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm23         \n"

"   movss           24(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm24         \n"

"   movss           28(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm25         \n"

"   movss           32(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm26         \n"

"    addq             $4, %%rbx                              \n"//                

"   movss           36(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm27         \n"

"   prefetcht0         4(%%rbx)                              \n"//                       

"   movss           40(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm28         \n"

"   movss           44(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm29         \n"
"   movss           (%%rbx), %%xmm4                          \n"
"    addq              $48, %%rax                            \n"

"   movss           (%%rax), %%xmm0                          \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm30         \n"

"   movss           4(%%rax), %%xmm1                         \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm31         \n"

".endm                                                       \n"

".macro    KERNEL12x1_END_K                                  \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm20         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm21         \n"

"   movss           16(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm22         \n"

"   prefetcht0         256(%%rax)                            \n"

"   movss           20(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm23         \n"

"   movss           24(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm24         \n"

"   movss           28(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm25         \n"

"   movss           32(%%rax), %%xmm0                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm26         \n"

"   movss           36(%%rax), %%xmm1                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm27         \n"

"   movss           40(%%rax), %%xmm2                        \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm28         \n"

"   movss           44(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm29         \n"
"   movss           (%%rbx), %%xmm4                          \n"
"    addq              $48, %%rax                            \n"

"   movss           (%%rax), %%xmm0                          \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm30         \n"

"   movss           4(%%rax), %%xmm1                         \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm31         \n"

".endm                                                       \n"

".macro    ADD_C_12x1                                        \n"

"   movss           (%%r10), %%xmm0                          \n"
"    vaddps             %%xmm0, %%xmm20, %%xmm20             \n"
"   movss           (%%r11), %%xmm1                          \n"
"    vaddps             %%xmm1, %%xmm21, %%xmm21             \n"
"   movss           (%%r12), %%xmm2                          \n"
"    vaddps             %%xmm2, %%xmm22, %%xmm22             \n"
"   movss           (%%r13), %%xmm3                          \n"
"    vaddps             %%xmm3, %%xmm23, %%xmm23             \n"

"    leaq              (%%r13, %%r8, 4), %%r10               \n"// C0
"    leaq             (%%r10, %%r8, 4), %%r11                \n"// C1
"    leaq             (%%r11, %%r8, 4), %%r12                \n"// C2
"    leaq             (%%r12, %%r8, 4), %%r13                \n"// C3

"   movss           (%%r10), %%xmm4                          \n"
"    vaddps             %%xmm4, %%xmm24, %%xmm24             \n"
"   movss           (%%r11), %%xmm5                          \n"
"    vaddps             %%xmm5, %%xmm25, %%xmm25             \n"
"   movss           (%%r12), %%xmm6                          \n"
"    vaddps             %%xmm6, %%xmm26, %%xmm26             \n"
"   movss           (%%r13), %%xmm7                          \n"
"    vaddps             %%xmm7, %%xmm27, %%xmm27             \n"

"    leaq              (%%r13, %%r8, 4), %%r10               \n"// C0
"    leaq             (%%r10, %%r8, 4), %%r11                \n"// C1
"    leaq             (%%r11, %%r8, 4), %%r12                \n"// C2
"    leaq             (%%r12, %%r8, 4), %%r13                \n"// C3

"   movss           (%%r10), %%xmm0                          \n"
"    vaddps             %%xmm0, %%xmm28, %%xmm28             \n"
"   movss           (%%r11), %%xmm1                          \n"
"    vaddps             %%xmm1, %%xmm29, %%xmm29             \n"
"   movss           (%%r12), %%xmm2                          \n"
"    vaddps             %%xmm2, %%xmm30, %%xmm30             \n"
"   movss           (%%r13), %%xmm3                          \n"
"    vaddps             %%xmm3, %%xmm31, %%xmm31             \n"

"    mov      %%rcx, %%r10                                   \n"// C0
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3

".endm                                                       \n"

".macro    SAVE_12x1                                         \n"

"   vmovss           %%xmm20, (%%r10)                        \n"
"   vmovss           %%xmm21, (%%r11)                        \n"
"    subq             $12, %%rdi                             \n"
"   vmovss           %%xmm22, (%%r12)                        \n"
"   vmovss           %%xmm23, (%%r13)                        \n"

"    leaq      (%%r13, %%r8, 4), %%r10                       \n"// C0
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3

"   vmovss           %%xmm24, (%%r10)                        \n"
"   vmovss           %%xmm25, (%%r11)                        \n"
"   vmovss           %%xmm26, (%%r12)                        \n"
"   vmovss           %%xmm27, (%%r13)                        \n"

"    leaq      (%%r13, %%r8, 4), %%r10                       \n"// C0
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3

"   vmovss           %%xmm28, (%%r10)                        \n"
"   vmovss           %%xmm29, (%%r11)                        \n"
"   vmovss           %%xmm30, (%%r12)                        \n"
"   vmovss           %%xmm31, (%%r13)                        \n"

"    leaq      (%%r13, %%r8, 4), %%rcx                       \n"// C0

".endm                                                       \n"

//-----------------------------------------------------------------------

".macro    KERNEL8x1_K1                                      \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm4, %%xmm24         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm4, %%xmm25         \n"

"   prefetcht0         256(%%rax)                            \n"

"   movss           16(%%rax), %%xmm8                        \n"
"   vfmadd231ps              %%xmm2, %%xmm4, %%xmm26         \n"

"   movss           20(%%rax), %%xmm9                        \n"
"   vfmadd231ps              %%xmm3, %%xmm4, %%xmm27         \n"

"   movss           24(%%rax), %%xmm10                       \n"
"   vfmadd231ps              %%xmm8, %%xmm4, %%xmm28         \n"

"   prefetcht0         4(%%rbx)                              \n"//                        

"   movss           28(%%rax), %%xmm11                       \n"
"   vfmadd231ps              %%xmm9, %%xmm4, %%xmm29         \n"
"    addq              $4, %%rbx                             \n"//
"   vfmadd231ps              %%xmm10, %%xmm4, %%xmm30        \n"

"    addq              $32, %%rax                            \n"
"   movss           (%%rbx), %%xmm6                          \n"
"   vfmadd231ps              %%xmm11, %%xmm4, %%xmm31        \n"

"   movss           (%%rax), %%xmm0                          \n"
"   movss           4(%%rax), %%xmm1                         \n"

".endm                                                       \n"

".macro    KERNEL8x1_K2                                      \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm24         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm25         \n"

"   prefetcht0         256(%%rax)                            \n"

"   movss           16(%%rax), %%xmm8                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm26         \n"

"   movss           20(%%rax), %%xmm9                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm27         \n"

"   movss           24(%%rax), %%xmm10                       \n"
"   vfmadd231ps              %%xmm8, %%xmm6, %%xmm28         \n"

"   prefetcht0         4(%%rbx)                              \n"//           

"   movss           28(%%rax), %%xmm11                       \n"
"   vfmadd231ps              %%xmm9, %%xmm6, %%xmm29         \n"
"    addq              $4, %%rbx                             \n"// B
"   vfmadd231ps              %%xmm10, %%xmm6, %%xmm30        \n"

"    addq              $32, %%rax                            \n"
"   movss           (%%rbx), %%xmm4                          \n"
"   vfmadd231ps              %%xmm11, %%xmm6, %%xmm31        \n"

"   movss           (%%rax), %%xmm0                          \n"
"   movss           4(%%rax), %%xmm1                         \n"

".endm                                                       \n"

".macro    KERNEL8x1_END_K                                   \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm24         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm25         \n"

"   prefetcht0         256(%%rax)                            \n"

"   movss           16(%%rax), %%xmm8                        \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm26         \n"

"   movss           20(%%rax), %%xmm9                        \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm27         \n"

"   movss           24(%%rax), %%xmm10                       \n"
"   vfmadd231ps              %%xmm8, %%xmm6, %%xmm28         \n"

"   movss           28(%%rax), %%xmm11                       \n"
"   vfmadd231ps              %%xmm9, %%xmm6, %%xmm29         \n"
"   vfmadd231ps              %%xmm10, %%xmm6, %%xmm30        \n"

"    addq              $32, %%rax                            \n"
"   vfmadd231ps              %%xmm11, %%xmm6, %%xmm31        \n"

".endm                                                       \n"

".macro    ADD_C_8x1                                         \n"

"   movss           (%%r10), %%xmm4                          \n"
"    vaddps             %%xmm4, %%xmm24, %%xmm24             \n"
"   movss           (%%r11), %%xmm5                          \n"
"    vaddps             %%xmm5, %%xmm25, %%xmm25             \n"
"   movss           (%%r12), %%xmm6                          \n"
"    vaddps             %%xmm6, %%xmm26, %%xmm26             \n"
"   movss           (%%r13), %%xmm7                          \n"
"    vaddps             %%xmm7, %%xmm27, %%xmm27             \n"

"    leaq              (%%r13, %%r8, 4), %%r10               \n"// C0
"    leaq             (%%r10, %%r8, 4), %%r11                \n"// C1
"    leaq             (%%r11, %%r8, 4), %%r12                \n"// C2
"    leaq             (%%r12, %%r8, 4), %%r13                \n"// C3

"   movss           (%%r10), %%xmm0                          \n"
"    vaddps             %%xmm0, %%xmm28, %%xmm28             \n"
"   movss           (%%r11), %%xmm1                          \n"
"    vaddps             %%xmm1, %%xmm29, %%xmm29             \n"
"   movss           (%%r12), %%xmm2                          \n"
"    vaddps             %%xmm2, %%xmm30, %%xmm30             \n"
"   movss           (%%r13), %%xmm3                          \n"
"    vaddps             %%xmm3, %%xmm31, %%xmm31             \n"

"    mov      %%rcx, %%r10                                   \n"// C0
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3

".endm                                                       \n"

".macro    SAVE_8x1                                          \n"

"   vmovss           %%xmm24, (%%r10)                        \n"
"   vmovss           %%xmm25, (%%r11)                        \n"
"    subq             $8, %%rdi                              \n"
"   vmovss           %%xmm26, (%%r12)                        \n"
"   vmovss           %%xmm27, (%%r13)                        \n"

"    leaq      (%%r13, %%r8, 4), %%r10                       \n"// C0
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3

"   vmovss           %%xmm28, (%%r10)                        \n"
"   vmovss           %%xmm29, (%%r11)                        \n"
"   vmovss           %%xmm30, (%%r12)                        \n"
"   vmovss           %%xmm31, (%%r13)                        \n"

"    leaq      (%%r13, %%r8, 4), %%rcx                       \n"// C0

".endm                                                       \n"

//-----------------------------------------------------------------------

".macro    KERNEL4x1_K1                                      \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm4, %%xmm28         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm4, %%xmm29         \n"
"    addq              $16, %%rax                            \n"

"   prefetcht0         256(%%rax)                            \n"
"    addq              $4, %%rbx                             \n"// B
"   movss           (%%rax), %%xmm0                          \n"
"   vfmadd231ps              %%xmm2, %%xmm4, %%xmm30         \n"

"   movss           4(%%rax), %%xmm1                         \n"
"   vfmadd231ps              %%xmm3, %%xmm4, %%xmm31         \n"

"   prefetcht0         4(%%rbx)                              \n"
"   movss           (%%rbx), %%xmm6                          \n"

".endm                                                       \n"

".macro    KERNEL4x1_K2                                      \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm28         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm29         \n"
"    addq              $16, %%rax                            \n"

"   prefetcht0         256(%%rax)                            \n"
"    addq              $4, %%rbx                             \n"// B
"   movss           (%%rax), %%xmm0                          \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm30         \n"

"   movss           4(%%rax), %%xmm1                         \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm31         \n"

"   movss           (%%rbx), %%xmm4                          \n"
"   prefetcht0         4(%%rbx)                              \n"

".endm                                                       \n"

".macro    KERNEL4x1_END_K                                   \n"

"   movss           8(%%rax), %%xmm2                         \n"
"   vfmadd231ps              %%xmm0, %%xmm6, %%xmm28         \n"

"   movss           12(%%rax), %%xmm3                        \n"
"   vfmadd231ps              %%xmm1, %%xmm6, %%xmm29         \n"
"    addq              $16, %%rax                            \n"

"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm30         \n"
"   vfmadd231ps              %%xmm3, %%xmm6, %%xmm31         \n"

".endm                                                       \n"

".macro    ADD_C_4x1                                         \n"

"   movss           (%%r10), %%xmm0                          \n"
"    vaddps             %%xmm0, %%xmm28, %%xmm28             \n"
"   movss           (%%r11), %%xmm1                          \n"
"    vaddps             %%xmm1, %%xmm29, %%xmm29             \n"
"   movss           (%%r12), %%xmm2                          \n"
"    vaddps             %%xmm2, %%xmm30, %%xmm30             \n"
"   movss           (%%r13), %%xmm3                          \n"
"    vaddps             %%xmm3, %%xmm31, %%xmm31             \n"

"    mov      %%rcx, %%r10                                   \n"// C0
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3

".endm                                                       \n"

".macro    SAVE_4x1                                          \n"
"   subq             $4, %%rdi                               \n"

"   vmovss           %%xmm28, (%%r10)                        \n"
"   vmovss           %%xmm29, (%%r11)                        \n"
"   vmovss           %%xmm30, (%%r12)                        \n"
"   vmovss           %%xmm31, (%%r13)                        \n"

"    leaq      (%%r13, %%r8, 4), %%rcx                       \n"// C0

".endm                                                       \n"
											

//-----------------------------------------------------------------

".macro    KERNEL1x1_K1                                      \n"
"   prefetcht0         256(%%rax)                            \n"
"   addq              $4, %%rax                              \n"

"   movss           (%%rax), %%xmm2                          \n"
"   vfmadd231ps              %%xmm0, %%xmm4, %%xmm30         \n"
							           		
"    addq              $4, %%rbx                             \n"// B    
"   movss              (%%rbx), %%xmm6                       \n"
"   prefetcht0         4(%%rbx)                              \n"

".endm                                                       \n"

".macro    KERNEL1x1_K2                                      \n"
"   prefetcht0         256(%%rax)                            \n"
"    addq              $4, %%rax                             \n"

"   movss           (%%rax), %%xmm0                          \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm30         \n"
                  		
"    addq              $4, %%rbx                             \n"// B        
"   movss              (%%rbx), %%xmm4                       \n"
"   prefetcht0         4(%%rbx)                              \n"

".endm                                                       \n"

".macro    KERNEL1x1_END_K                                   \n"
"   vfmadd231ps              %%xmm2, %%xmm6, %%xmm30         \n"
"    addq              $4, %%rax                             \n"
".endm                                                       \n"

".macro    ADD_C_1x1                                         \n"
"   movss           (%%r10), %%xmm2                          \n"
"    vaddps             %%xmm2, %%xmm30, %%xmm30             \n"
"    mov      %%rcx, %%r10                                   \n"// C0
".endm                                                       \n"

".macro    SAVE_1x1                                          \n"
"   vmovss           %%xmm30, (%%r10)                        \n"
"   subq             $1, %%rdi                               \n"
"    leaq      (%%r10, %%r8, 4), %%rcx                       \n"// C0

".endm                                                       \n"

//-----------------------------------------------------------------

"SMM_NN_KERNEL12x1:                                          \n"

"   mov     %[C], %%rcx                                      \n"
"   mov     %[A], %%rax                                      \n"
"   mov     %[B], %%rbx                                      \n"

"   prefetcht0         (%%rax)                               \n"

"    mov     %[K], %%rdx                                     \n"// K
"    mov      %[LN], %%r8                                    \n"
"    mov      %[Bc], %%r14                                   \n"
"    mov      %[M], %%rdi                                    \n"
"    mov     %[k_tag], %%r15                                 \n"

"   prefetcht0         (%%rbx)                               \n"
"    mov     %%rbx, %%r9                                     \n"// B
"    mov     %%rdx, %%rsi                                    \n"// K

"BEGIN_PACK12x1:                                             \n"

"    mov     %%r9, %%rbx                                     \n"// B
"   prefetcht0         (%%rbx)                               \n"

"    mov      %%rcx, %%r10                                   \n"// C0
"   prefetcht1         (%%r10)                               \n"
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"   prefetcht1         (%%r11)                               \n"
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"   prefetcht1         (%%r12)                               \n"
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3
"   prefetcht1         (%%r13)                               \n"

"    mov     %%rsi, %%rdx                                    \n"// K
"    mov     %%r14, %%rbp                                    \n"// Bc

"   movss          (%%rbx), %%xmm4                           \n"
"    vpxorq         %%xmm20, %%xmm20, %%xmm20                \n"
"    vpxorq         %%xmm21, %%xmm21, %%xmm21                \n"
"   movss           (%%rax), %%xmm0                          \n"
"    vpxorq         %%xmm22, %%xmm22, %%xmm22                \n"
"    vpxorq         %%xmm23, %%xmm23, %%xmm23                \n"
"   movss           4(%%rax), %%xmm1                         \n"
"    vpxorq         %%xmm24, %%xmm24, %%xmm24                \n"
"    vpxorq         %%xmm25, %%xmm25, %%xmm25                \n"
"    vpxorq         %%xmm26, %%xmm26, %%xmm26                \n"
"    vpxorq         %%xmm27, %%xmm27, %%xmm27                \n"
"    vpxorq         %%xmm28, %%xmm28, %%xmm28                \n"
"    vpxorq         %%xmm29, %%xmm29, %%xmm29                \n"
"    vpxorq         %%xmm30, %%xmm30, %%xmm30                \n"
"    vpxorq         %%xmm31, %%xmm31, %%xmm31                \n"

"    subq     $8, %%rdx                                      \n"

"MAIN_PACK_K12x1:                                            \n"

"    KERNEL12x1_PACK_K1                                      \n"
"    KERNEL12x1_PACK_K2                                      \n"
"    KERNEL12x1_PACK_K1                                      \n"
"    KERNEL12x1_PACK_K2                                      \n"
"    KERNEL12x1_PACK_K1                                      \n"
"    KERNEL12x1_PACK_K2                                      \n"
"    KERNEL12x1_PACK_K1                                      \n"
"   cmp     $0, %%rdx                                        \n"
"    je         EDGE_PACK_K12x1                              \n"
"    KERNEL12x1_PACK_K2                                      \n"

"    subq     $8, %%rdx                                      \n"
"   jmp     MAIN_PACK_K12x1                                  \n"

"EDGE_PACK_K12x1:                                            \n"

"    KERNEL12x1_PACK_END_K                                   \n"
"    jmp      BEGIN_SAVE_12x1                                \n"

//-----------------------------------------------------------------

"BEGIN_M12x1:                                                \n"

"    mov     %%r14, %%rbx                                    \n"// Bc
"   prefetcht0         (%%rbx)                               \n"

"    mov      %%rcx, %%r10                                   \n"// C0
"   prefetcht1         (%%r10)                               \n"
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"   prefetcht1         (%%r11)                               \n"
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"   prefetcht1         (%%r12)                               \n"
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3
"   prefetcht1         (%%r13)                               \n"

"    mov     %%rsi, %%rdx                                    \n"// K                                    

"   movss          (%%rbx), %%xmm4                           \n"
"    vpxorq         %%xmm20, %%xmm20, %%xmm20                \n"
"    vpxorq         %%xmm21, %%xmm21, %%xmm21                \n"
"    vpxorq         %%xmm22, %%xmm22, %%xmm22                \n"
"   movss           (%%rax), %%xmm0                          \n"
"    vpxorq         %%xmm23, %%xmm23, %%xmm23                \n"
"    vpxorq         %%xmm24, %%xmm24, %%xmm24                \n"
"   movss           4(%%rax), %%xmm1                         \n"
"    vpxorq         %%xmm25, %%xmm25, %%xmm25                \n"
"    vpxorq         %%xmm26, %%xmm26, %%xmm26                \n"
"    vpxorq         %%xmm27, %%xmm27, %%xmm27                \n"
"    vpxorq         %%xmm28, %%xmm28, %%xmm28                \n"
"    vpxorq         %%xmm29, %%xmm29, %%xmm29                \n"
"    vpxorq         %%xmm30, %%xmm30, %%xmm30                \n"
"    vpxorq         %%xmm31, %%xmm31, %%xmm31                \n"

"    subq     $8, %%rdx                                      \n"

"MAIN_K12x1:                                                 \n"

"    KERNEL12x1_K1                                           \n"
"    KERNEL12x1_K2                                           \n"
"    KERNEL12x1_K1                                           \n"
"    KERNEL12x1_K2                                           \n"
"    KERNEL12x1_K1                                           \n"
"    KERNEL12x1_K2                                           \n"
"    KERNEL12x1_K1                                           \n"
"   cmp     $0, %%rdx                                        \n"
"    je         EDGE_K12x1                                   \n"
"    KERNEL12x1_K2                                           \n"

"    subq     $8, %%rdx                                      \n"
"   jmp     MAIN_K12x1                                       \n"

"EDGE_K12x1:                                                 \n"

"    KERNEL12x1_END_K                                        \n"

"BEGIN_SAVE_12x1:                                            \n"
"    cmp     $0, %%r15                                       \n"
"    je      SAVE_C12x1                                      \n"
"    ADD_C_12x1                                              \n"

"SAVE_C12x1:                                                 \n"
"    SAVE_12x1                                               \n"

"    cmpq      $12, %%rdi                                    \n"
"    jnb     BEGIN_M12x1                                     \n"// 不小于（或等于）则跳转                             

//------------------------------------------------------------------

"BEGIN_M8_N1:                                                \n"
"   cmpq      $8, %%rdi                                      \n"// M % 8
"    jb       BEGIN_M4_N1                                    \n"//小于则跳转

"    mov     %%r14, %%rbx                                    \n"// Bc
"   prefetcht0         (%%rbx)                               \n"

"    mov      %%rcx, %%r10                                   \n"// C0
"   prefetcht1         (%%r10)                               \n"
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"   prefetcht1         (%%r11)                               \n"
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"   prefetcht1         (%%r12)                               \n"
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3
"   prefetcht1         (%%r13)                               \n"

"    mov     %%rsi, %%rdx                                    \n"// K
"   movss          (%%rbx), %%xmm4                           \n"
"    vpxorq         %%xmm24, %%xmm24, %%xmm24                \n"
"    vpxorq         %%xmm25, %%xmm25, %%xmm25                \n"
"   movss           (%%rax), %%xmm0                          \n"
"    vpxorq         %%xmm26, %%xmm26, %%xmm26                \n"
"    vpxorq         %%xmm27, %%xmm27, %%xmm27                \n"
"   movss           4(%%rax), %%xmm1                         \n"
"    vpxorq         %%xmm28, %%xmm28, %%xmm28                \n"
"    vpxorq         %%xmm29, %%xmm29, %%xmm29                \n"
"    vpxorq         %%xmm30, %%xmm30, %%xmm30                \n"
"    vpxorq         %%xmm31, %%xmm31, %%xmm31                \n"

"    subq     $8, %%rdx                                      \n"

"MAIN_K_M8_N1:                                               \n"

"    KERNEL8x1_K1                                            \n"
"    KERNEL8x1_K2                                            \n"
"    KERNEL8x1_K1                                            \n"
"    KERNEL8x1_K2                                            \n"
"    KERNEL8x1_K1                                            \n"
"    KERNEL8x1_K2                                            \n"
"    KERNEL8x1_K1                                            \n"
"   cmp     $0, %%rdx                                        \n"
"    je         EDGE_K_M8_N1                                 \n"
"    KERNEL8x1_K2                                            \n"

"    subq     $8, %%rdx                                      \n"
"   jmp     MAIN_K_M8_N1                                     \n"

"EDGE_K_M8_N1:                                               \n"

"    KERNEL8x1_END_K                                         \n"

"    cmp     $0, %%r15                                       \n"
"    je      SAVE_C_8x1                                      \n"
"    ADD_C_8x1                                               \n"

"SAVE_C_8x1:                                                 \n"
"    SAVE_8x1                                                \n"

//----------------------------------------------------------------

"BEGIN_M4_N1:                                                \n"

"    cmpq      $4, %%rdi                                     \n"// M % 4
"    jb       BEGIN_M1_N1                                    \n"

"    mov     %%r14, %%rbx                                    \n"// Bc
"   prefetcht0         (%%rbx)                               \n"

"    mov      %%rcx, %%r10                                   \n"// C0
"   prefetcht1         (%%r10)                               \n"
"    leaq     (%%r10, %%r8, 4), %%r11                        \n"// C1
"   prefetcht1         (%%r11)                               \n"
"    leaq     (%%r11, %%r8, 4), %%r12                        \n"// C2
"   prefetcht1         (%%r12)                               \n"
"    leaq     (%%r12, %%r8, 4), %%r13                        \n"// C3
"   prefetcht1         (%%r13)                               \n"

"    mov     %%rsi, %%rdx                                    \n"// K

"   movss          (%%rbx), %%xmm4                           \n"
"   movss           (%%rax), %%xmm0                          \n"
"    vpxorq         %%xmm28, %%xmm28, %%xmm28                \n"
"    vpxorq         %%xmm29, %%xmm29, %%xmm29                \n"
"   movss           4(%%rax), %%xmm1                         \n"
"    vpxorq         %%xmm30, %%xmm30, %%xmm30                \n"
"    vpxorq         %%xmm31, %%xmm31, %%xmm31                \n"

"    subq     $8, %%rdx                                      \n"

"MAIN_K_M4_N1:                                               \n"

"    KERNEL4x1_K1                                            \n"
"    KERNEL4x1_K2                                            \n"
"    KERNEL4x1_K1                                            \n"
"    KERNEL4x1_K2                                            \n"
"    KERNEL4x1_K1                                            \n"
"    KERNEL4x1_K2                                            \n"
"    KERNEL4x1_K1                                            \n"
"   cmp     $0, %%rdx                                        \n"
"    je         EDGE_K_M4_N1                                 \n"
"    KERNEL4x1_K2                                            \n"

"    subq     $8, %%rdx                                      \n"
"   jmp     MAIN_K_M4_N1                                     \n"

"EDGE_K_M4_N1:                                               \n"

"    KERNEL4x1_END_K                                         \n"

"    cmp     $0, %%r15                                       \n"
"    je      SAVE_C_4x1                                      \n"
"    ADD_C_4x1                                               \n"

"SAVE_C_4x1:                                                 \n"
"    SAVE_4x1                                                \n"

//----------------------------------------------------------------


"BEGIN_M1_N1:                                                \n"
"    cmpq      $1, %%rdi                                     \n"// M % 1
"    jb       END_M_N1                                       \n"

"    mov     %%r14, %%rbx                                    \n"// Bc
"   prefetcht0         (%%rbx)                               \n"

"    mov      %%rcx, %%r10                                   \n"// C0
"   prefetcht1         (%%r10)                               \n"

"    mov     %%rsi, %%rdx                                    \n"// K

"   movss          (%%rbx), %%xmm4                           \n"
"   movss           (%%rax), %%xmm0                          \n"// A0                
"    vpxorq         %%xmm30, %%xmm30, %%xmm30                \n"

"    subq     $8, %%rdx                                      \n"

"MAIN_K_M1_N1:                                               \n"
"    KERNEL1x1_K1                                            \n"
"    KERNEL1x1_K2                                            \n"
"    KERNEL1x1_K1                                            \n"
"    KERNEL1x1_K2                                            \n"
"    KERNEL1x1_K1                                            \n"
"    KERNEL1x1_K2                                            \n"
"    KERNEL1x1_K1                                            \n"
"   cmp     $0, %%rdx                                        \n"
"    je         EDGE_K_M1_N1                                 \n"
"    KERNEL1x1_K2                                            \n"

"    subq     $8, %%rdx                                      \n"
"   jmp     MAIN_K_M1_N1                                     \n"

"EDGE_K_M1_N1:                                               \n"
"    KERNEL1x1_END_K                                         \n"

"    cmp     $0, %%r15                                       \n"
"    je      SAVE_C_1x1                                      \n"
"    ADD_C_1x1                                               \n"
									
"SAVE_C_1x1:                                                 \n"
"    SAVE_1x1                                                \n"
"   cmpq      $1, %%rdi                                      \n"
"    jnb     BEGIN_M1_N1                                     \n"//不小于（或等于）则跳转                                

//-----------------------------------------------------------------


"END_M_N1:                                                   \n"

