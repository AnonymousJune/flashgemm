.macro	f32_kernel_m12n32_pack_1							

   vbroadcastss	8(%%rax), %%zmm2       // A2   			
   vfmadd231ps		%%zmm0, %%zmm4, %%zmm8 // A0*(B0-15) 			
   vfmadd231ps		%%zmm0, %%zmm5, %%zmm9 // A0*(B16-31) 			

   vbroadcastss	12(%%rax), %%zmm3       // A3    			
   vfmadd231ps		%%zmm1, %%zmm4, %%zmm10 // A1*(B0-15) 		
   vfmadd231ps		%%zmm1, %%zmm5, %%zmm11 // A1*(B16-31) 		

   prefetcht0 		256(%%rax)                 		

   vbroadcastss	16(%%rax), %%zmm0      // A4   			
   vfmadd231ps		%%zmm2, %%zmm4, %%zmm12 		
   vfmadd231ps		%%zmm2, %%zmm5, %%zmm13 		

   prefetcht2 		128(%%rbx)                 		

   vbroadcastss	20(%%rax), %%zmm1     // A5		
   vfmadd231ps		%%zmm3, %%zmm4, %%zmm14 		
   vfmadd231ps		%%zmm3, %%zmm5, %%zmm15 		

   vbroadcastss	24(%%rax), %%zmm2     // A6    			
   vfmadd231ps		%%zmm0, %%zmm4, %%zmm16 		
   vfmadd231ps		%%zmm0, %%zmm5, %%zmm17 		

   prefetcht2 		192(%%rbx)                 		

   vbroadcastss	28(%%rax), %%zmm3     // A7    			
   vfmadd231ps		%%zmm1, %%zmm4, %%zmm18 		
   vfmadd231ps		%%zmm1, %%zmm5, %%zmm19 		

   vbroadcastss	32(%%rax), %%zmm0     // A8    			
   vfmadd231ps		%%zmm2, %%zmm4, %%zmm20 		
   vfmadd231ps		%%zmm2, %%zmm5, %%zmm21 		

	leaq  	(%%rbx, %%r8, 4), %%rbx 				 // B

   vbroadcastss	36(%%rax), %%zmm1     // A9    			
   vfmadd231ps		%%zmm3, %%zmm4, %%zmm22 		
   vfmadd231ps		%%zmm3, %%zmm5, %%zmm23 		

   vbroadcastss	40(%%rax), %%zmm2     // A10    			
   vfmadd231ps		%%zmm0, %%zmm4, %%zmm24 		
   vfmadd231ps		%%zmm0, %%zmm5, %%zmm25 		

   prefetcht0 		384(%%rax)                 		

   vbroadcastss	44(%%rax), %%zmm3    // A11    			
   vfmadd231ps		%%zmm1, %%zmm4, %%zmm26 		
   vmovups 		(%%rbx), %%zmm6 // next B0       			
	addq  			$48, %%rax 	 //下一组A(已读12个)					
   vfmadd231ps		%%zmm1, %%zmm5, %%zmm27 		

   vbroadcastss	(%%rax), %%zmm0     // next A0    				
   vfmadd231ps		%%zmm2, %%zmm4, %%zmm28 		
   vmovups 		64(%%rbx), %%zmm7 // next B1       		
   vfmadd231ps		%%zmm2, %%zmm5, %%zmm29 		

   vbroadcastss	4(%%rax), %%zmm1    // next A1    			
   vfmadd231ps		%%zmm3, %%zmm4, %%zmm30 		
   vmovups 		%%zmm4, (%%rbp)  // pack B0 to Bc     			
   vfmadd231ps		%%zmm3, %%zmm5, %%zmm31 		
   vmovups 		%%zmm5, 64(%%rbp)// pack B1 to Bc       		
	addq  			$128, %%rbp 					

.endm 												

.macro	f32_kernel_m12n32_pack_2							

   vbroadcastss	8(%%rax), %%zmm2     // next A2    			
   vfmadd231ps		%%zmm0, %%zmm6, %%zmm8 			
   vfmadd231ps		%%zmm0, %%zmm7, %%zmm9 			

   prefetcht0 		256(%%rax)                 		

   vbroadcastss	12(%%rax), %%zmm3     // next A3    			
   vfmadd231ps		%%zmm1, %%zmm6, %%zmm10 		
   vfmadd231ps		%%zmm1, %%zmm7, %%zmm11 		

   prefetcht2 		128(%%rbx)                 		

   vbroadcastss	16(%%rax), %%zmm0     // next A4    			
   vfmadd231ps		%%zmm2, %%zmm6, %%zmm12 		
   vfmadd231ps		%%zmm2, %%zmm7, %%zmm13 		

   prefetcht2 		192(%%rbx)                 		

   vbroadcastss	20(%%rax), %%zmm1     // next A5    			
   vfmadd231ps		%%zmm3, %%zmm6, %%zmm14 		
   vfmadd231ps		%%zmm3, %%zmm7, %%zmm15 		

   vbroadcastss	24(%%rax), %%zmm2     // next A6    			
   vfmadd231ps		%%zmm0, %%zmm6, %%zmm16 		
   vfmadd231ps		%%zmm0, %%zmm7, %%zmm17 		

   vbroadcastss	28(%%rax), %%zmm3     // next A7    			
   vfmadd231ps		%%zmm1, %%zmm6, %%zmm18 		
   vfmadd231ps		%%zmm1, %%zmm7, %%zmm19 		

   vbroadcastss	32(%%rax), %%zmm0     // next A8    			
   vfmadd231ps		%%zmm2, %%zmm6, %%zmm20 		
   vfmadd231ps		%%zmm2, %%zmm7, %%zmm21 		

	leaq  	(%%rbx, %%r8, 4), %%rbx 				 // B

   vbroadcastss	36(%%rax), %%zmm1     // next A9    			
   vfmadd231ps		%%zmm3, %%zmm6, %%zmm22 		
   vfmadd231ps		%%zmm3, %%zmm7, %%zmm23 		

   vbroadcastss	40(%%rax), %%zmm2     // next A10    			
   vfmadd231ps		%%zmm0, %%zmm6, %%zmm24 		
   vfmadd231ps		%%zmm0, %%zmm7, %%zmm25 		

   vbroadcastss	44(%%rax), %%zmm3     // next A11    			
   vfmadd231ps		%%zmm1, %%zmm6, %%zmm26 		
   vmovups 		(%%rbx), %%zmm4 // next next B0       			
	addq  			$48, %%rax 	 // 下一组A(已读12个) 						
   vfmadd231ps		%%zmm1, %%zmm7, %%zmm27 		

   vbroadcastss	(%%rax), %%zmm0    	 // next next A0			
   vfmadd231ps		%%zmm2, %%zmm6, %%zmm28		
   vmovups 		64(%%rbx), %%zmm5 // next next B1      		
   vfmadd231ps		%%zmm2, %%zmm7, %%zmm29 		

   vbroadcastss	4(%%rax), %%zmm1    	 // next next A1    			
   vfmadd231ps		%%zmm3, %%zmm6, %%zmm30 		
   vmovups 		%%zmm6, (%%rbp)   // pack B0 to Bc      			
   vfmadd231ps		%%zmm3, %%zmm7, %%zmm31 		
   vmovups 		%%zmm7, 64(%%rbp) // pack B1 to Bc      		
	addq  			$128, %%rbp 					

.endm

.macro	f32_kernel_m12n32_pack_1_end							

   vbroadcastss	8(%%rax), %%zmm2       // A2   			
   vfmadd231ps		%%zmm0, %%zmm4, %%zmm8 // A0*(B0-15) 			
   vfmadd231ps		%%zmm0, %%zmm5, %%zmm9 // A0*(B16-31) 			

   vbroadcastss	12(%%rax), %%zmm3       // A3    			
   vfmadd231ps		%%zmm1, %%zmm4, %%zmm10 // A1*(B0-15) 		
   vfmadd231ps		%%zmm1, %%zmm5, %%zmm11 // A1*(B16-31) 		

   prefetcht0 		256(%%rax)                 		

   vbroadcastss	16(%%rax), %%zmm0      // A4   			
   vfmadd231ps		%%zmm2, %%zmm4, %%zmm12 		
   vfmadd231ps		%%zmm2, %%zmm5, %%zmm13 		

   prefetcht2 		128(%%rbx)                 		

   vbroadcastss	20(%%rax), %%zmm1     // A5		
   vfmadd231ps		%%zmm3, %%zmm4, %%zmm14 		
   vfmadd231ps		%%zmm3, %%zmm5, %%zmm15 		

   vbroadcastss	24(%%rax), %%zmm2     // A6    			
   vfmadd231ps		%%zmm0, %%zmm4, %%zmm16 		
   vfmadd231ps		%%zmm0, %%zmm5, %%zmm17 		

   prefetcht2 		192(%%rbx)                 		

   vbroadcastss	28(%%rax), %%zmm3     // A7    			
   vfmadd231ps		%%zmm1, %%zmm4, %%zmm18 		
   vfmadd231ps		%%zmm1, %%zmm5, %%zmm19 		

   vbroadcastss	32(%%rax), %%zmm0     // A8    			
   vfmadd231ps		%%zmm2, %%zmm4, %%zmm20 		
   vfmadd231ps		%%zmm2, %%zmm5, %%zmm21 		

   vbroadcastss	36(%%rax), %%zmm1     // A9    			
   vfmadd231ps		%%zmm3, %%zmm4, %%zmm22 		
   vfmadd231ps		%%zmm3, %%zmm5, %%zmm23 		

   vbroadcastss	40(%%rax), %%zmm2     // A10    			
   vfmadd231ps		%%zmm0, %%zmm4, %%zmm24 		
   vfmadd231ps		%%zmm0, %%zmm5, %%zmm25 		

   prefetcht0 		384(%%rax)                 		

   vbroadcastss	44(%%rax), %%zmm3    // A11    			
   vfmadd231ps		%%zmm1, %%zmm4, %%zmm26 		       			
	addq  			$48, %%rax 	 //下一组A(已读12个)					
   vfmadd231ps		%%zmm1, %%zmm5, %%zmm27 		

   vbroadcastss	(%%rax), %%zmm0     // next A0    				
   vfmadd231ps		%%zmm2, %%zmm4, %%zmm28 		       		
   vfmadd231ps		%%zmm2, %%zmm5, %%zmm29 		

   vbroadcastss	4(%%rax), %%zmm1    // next A1    			
   vfmadd231ps		%%zmm3, %%zmm4, %%zmm30 		
   vmovups 		%%zmm4, (%%rbp)  // pack B0 to Bc     			
   vfmadd231ps		%%zmm3, %%zmm5, %%zmm31 		
   vmovups 		%%zmm5, 64(%%rbp)// pack B1 to Bc       		
	addq  			$128, %%rbp 					

.endm 												

.macro	f32_kernel_m12n32_pack_2_end							

   vbroadcastss	8(%%rax), %%zmm2     // next A2    			
   vfmadd231ps		%%zmm0, %%zmm6, %%zmm8 			
   vfmadd231ps		%%zmm0, %%zmm7, %%zmm9 			

   prefetcht0 		256(%%rax)                 		

   vbroadcastss	12(%%rax), %%zmm3     // next A3    			
   vfmadd231ps		%%zmm1, %%zmm6, %%zmm10 		
   vfmadd231ps		%%zmm1, %%zmm7, %%zmm11 		

   prefetcht2 		128(%%rbx)                 		

   vbroadcastss	16(%%rax), %%zmm0     // next A4    			
   vfmadd231ps		%%zmm2, %%zmm6, %%zmm12 		
   vfmadd231ps		%%zmm2, %%zmm7, %%zmm13 		

   prefetcht2 		192(%%rbx)                 		

   vbroadcastss	20(%%rax), %%zmm1     // next A5    			
   vfmadd231ps		%%zmm3, %%zmm6, %%zmm14 		
   vfmadd231ps		%%zmm3, %%zmm7, %%zmm15 		

   vbroadcastss	24(%%rax), %%zmm2     // next A6    			
   vfmadd231ps		%%zmm0, %%zmm6, %%zmm16 		
   vfmadd231ps		%%zmm0, %%zmm7, %%zmm17 		

   vbroadcastss	28(%%rax), %%zmm3     // next A7    			
   vfmadd231ps		%%zmm1, %%zmm6, %%zmm18 		
   vfmadd231ps		%%zmm1, %%zmm7, %%zmm19 		

   vbroadcastss	32(%%rax), %%zmm0     // next A8    			
   vfmadd231ps		%%zmm2, %%zmm6, %%zmm20 		
   vfmadd231ps		%%zmm2, %%zmm7, %%zmm21 		

   vbroadcastss	36(%%rax), %%zmm1     // next A9    			
   vfmadd231ps		%%zmm3, %%zmm6, %%zmm22 		
   vfmadd231ps		%%zmm3, %%zmm7, %%zmm23 		

   vbroadcastss	40(%%rax), %%zmm2     // next A10    			
   vfmadd231ps		%%zmm0, %%zmm6, %%zmm24 		
   vfmadd231ps		%%zmm0, %%zmm7, %%zmm25 		

   vbroadcastss	44(%%rax), %%zmm3     // next A11    			
   vfmadd231ps		%%zmm1, %%zmm6, %%zmm26 		       			
	addq  			$48, %%rax 	 // 下一组A(已读12个) 						
   vfmadd231ps		%%zmm1, %%zmm7, %%zmm27 		

   vbroadcastss	(%%rax), %%zmm0    	 // next next A0			
   vfmadd231ps		%%zmm2, %%zmm6, %%zmm28      		
   vfmadd231ps		%%zmm2, %%zmm7, %%zmm29 		

   vbroadcastss	4(%%rax), %%zmm1    	 // next next A1    			
   vfmadd231ps		%%zmm3, %%zmm6, %%zmm30 		
   vmovups 		%%zmm6, (%%rbp)   // pack B0 to Bc      			
   vfmadd231ps		%%zmm3, %%zmm7, %%zmm31 		
   vmovups 		%%zmm7, 64(%%rbp) // pack B1 to Bc      		
	addq  			$128, %%rbp 					

.endm

// ---------------------------------------------------------------

.macro    f32_kernel_m12n32_1                            
   vbroadcastss    8(%%rax), %%zmm2                         
   vfmadd231ps        %%zmm0, %%zmm4, %%zmm8                  
   vfmadd231ps        %%zmm0, %%zmm5, %%zmm9                  

   vbroadcastss    12(%%rax), %%zmm3                        

   vfmadd231ps        %%zmm1, %%zmm4, %%zmm10                 
   vfmadd231ps        %%zmm1, %%zmm5, %%zmm11                 

   prefetcht0         256(%%rax)                            

   vbroadcastss    16(%%rax), %%zmm0                        
   vfmadd231ps        %%zmm2, %%zmm4, %%zmm12                 
   vfmadd231ps        %%zmm2, %%zmm5, %%zmm13                 

   vbroadcastss    20(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm4, %%zmm14                 
   vfmadd231ps        %%zmm3, %%zmm5, %%zmm15                 

   vbroadcastss    24(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm4, %%zmm16                 
   vfmadd231ps        %%zmm0, %%zmm5, %%zmm17                 

   vbroadcastss    28(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm4, %%zmm18                 
   vfmadd231ps        %%zmm1, %%zmm5, %%zmm19                 

   vbroadcastss    32(%%rax), %%zmm0                        
   vfmadd231ps        %%zmm2, %%zmm4, %%zmm20                 
   vfmadd231ps        %%zmm2, %%zmm5, %%zmm21                 

    addq              $128, %%rbx                           

   vbroadcastss    36(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm4, %%zmm22                 
   vfmadd231ps        %%zmm3, %%zmm5, %%zmm23                 

   vbroadcastss    40(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm4, %%zmm24                 
   vfmadd231ps        %%zmm0, %%zmm5, %%zmm25                 

   vbroadcastss    44(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm4, %%zmm26                 
   vmovdqu16         (%%rbx), %%zmm6                        
    addq              $48, %%rax                            
   vfmadd231ps        %%zmm1, %%zmm5, %%zmm27                 

   vbroadcastss    (%%rax), %%zmm0                          
   vfmadd231ps        %%zmm2, %%zmm4, %%zmm28                 
   vmovdqu16         64(%%rbx), %%zmm7                      
   vfmadd231ps        %%zmm2, %%zmm5, %%zmm29                 

   vbroadcastss    4(%%rax), %%zmm1                         
   vfmadd231ps        %%zmm3, %%zmm4, %%zmm30                 
   vfmadd231ps        %%zmm3, %%zmm5, %%zmm31                 
.endm                                                       

.macro    f32_kernel_m12n32_2                            
   vbroadcastss    8(%%rax), %%zmm2                         
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm8                  
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm9                  

   vbroadcastss    12(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm10                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm11                 

   prefetcht0         256(%%rax)                            

   vbroadcastss    16(%%rax), %%zmm0                        
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm12                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm13                 

   vbroadcastss    20(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm14                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm15                 

   vbroadcastss    24(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm16                 
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm17                 

   vbroadcastss    28(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm18                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm19                 

   vbroadcastss    32(%%rax), %%zmm0                        
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm20                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm21                 

   addq              $128, %%rbx                            

   vbroadcastss    36(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm22                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm23                 

   vbroadcastss    40(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm24                 
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm25                 

   vbroadcastss    44(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm26                 
   vmovdqu16         (%%rbx), %%zmm4                        
    addq              $48, %%rax                            
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm27                 

   vbroadcastss    (%%rax), %%zmm0                          
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm28                 
   vmovdqu16         64(%%rbx), %%zmm5                      
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm29                 

   vbroadcastss    4(%%rax), %%zmm1                         
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm30                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm31                 
.endm                                                       

.macro    f32_kernel_m12n32_end                          
   vbroadcastss    8(%%rax), %%zmm2                         
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm8                  
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm9                  
   vbroadcastss    12(%%rax), %%zmm3                        

   vfmadd231ps        %%zmm1, %%zmm6, %%zmm10                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm11                 

   prefetcht0         256(%%rax)                            

   vbroadcastss    16(%%rax), %%zmm0                        
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm12                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm13                 

   vbroadcastss    20(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm14                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm15                 

   vbroadcastss    24(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm16                 
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm17                 

   vbroadcastss    28(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm18                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm19                 

   vbroadcastss    32(%%rax), %%zmm0                        
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm20                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm21                 

   vbroadcastss    36(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm22                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm23                 

   vbroadcastss    40(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm24                 
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm25                 

   vbroadcastss    44(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm26                 
   addq               $48, %%rax                            
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm27                 

   vfmadd231ps        %%zmm2, %%zmm6, %%zmm28                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm29                 

   vfmadd231ps        %%zmm3, %%zmm6, %%zmm30                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm31                 
.endm                                                       

.macro    f32_save_c_m12n32                                
   vmovups         %%zmm8, (%%r10)                          
   vmovups         %%zmm9, 64(%%r10)                        
   vmovups         %%zmm10, (%%r11)                         
   vmovups         %%zmm11, 64(%%r11)                       
   vmovups         %%zmm12, (%%r12)                         
   vmovups         %%zmm13, 64(%%r12)                       
   vmovups         %%zmm14, (%%r13)                         
   vmovups         %%zmm15, 64(%%r13)                       

   leaq  (%%r13, %%r8, 4), %%r10                             // C0
   leaq     (%%r10, %%r8, 4), %%r11                          // C1
   leaq     (%%r11, %%r8, 4), %%r12                          // C2
   leaq     (%%r12, %%r8, 4), %%r13                          // C3

   vmovups         %%zmm16, (%%r10)                         
   vmovups         %%zmm17, 64(%%r10)                       
   vmovups         %%zmm18, (%%r11)                         
   vmovups         %%zmm19, 64(%%r11)                       
   vmovups         %%zmm20, (%%r12)                         
   vmovups         %%zmm21, 64(%%r12)                       
   vmovups         %%zmm22, (%%r13)                         
   vmovups         %%zmm23, 64(%%r13)                       

   leaq  (%%r13, %%r8, 4), %%r10                             // C0
   leaq     (%%r10, %%r8, 4), %%r11                          // C1
   leaq     (%%r11, %%r8, 4), %%r12                          // C2
   leaq     (%%r12, %%r8, 4), %%r13                          // C3

   vmovups         %%zmm24, (%%r10)                         
   vmovups         %%zmm25, 64(%%r10)                       
   vmovups         %%zmm26, (%%r11)                         
   vmovups         %%zmm27, 64(%%r11)                       
   subq             $12, %%rdi                             
   vmovups         %%zmm28, (%%r12)                         
   vmovups         %%zmm29, 64(%%r12)                       
   vmovups         %%zmm30, (%%r13)                         
   vmovups         %%zmm31, 64(%%r13)                       

   leaq      (%%r13, %%r8, 4), %%rcx                        // C0
.endm                                                       

.macro    f32_save_c_m12n32_2                              
   vmovups         %%zmm8, (%%r10)                          
   vmovups         %%zmm9, 64(%%r10)                        
   vmovups         %%zmm10, 128(%%r10)                         
   vmovups         %%zmm11, 192(%%r10)                       
   vmovups         %%zmm12, 256(%%r10)                         
   vmovups         %%zmm13, 320(%%r10)                       
   vmovups         %%zmm14, 384(%%r10)                         
   vmovups         %%zmm15, 448(%%r10)                       

   addq            $512, %%r10 

   vmovups         %%zmm16, (%%r10)                          
   vmovups         %%zmm17, 64(%%r10)                        
   vmovups         %%zmm18, 128(%%r10)                         
   vmovups         %%zmm19, 192(%%r10)                       
   vmovups         %%zmm20, 256(%%r10)                         
   vmovups         %%zmm21, 320(%%r10)                       
   vmovups         %%zmm22, 384(%%r10)                         
   vmovups         %%zmm23, 448(%%r10)                      

   addq            $512, %%r10 

   vmovups         %%zmm24, (%%r10)                          
   vmovups         %%zmm25, 64(%%r10)                        
   vmovups         %%zmm26, 128(%%r10)                         
   vmovups         %%zmm27, 192(%%r10)                       
   vmovups         %%zmm28, 256(%%r10)                         
   vmovups         %%zmm29, 320(%%r10)                       
   vmovups         %%zmm30, 384(%%r10)                         
   vmovups         %%zmm31, 448(%%r10)                      

   addq            $512, %%r10                        
   subq            $12, %%rdi                              
.endm                                                       

//-----------------------------------------------------------------

.macro    f32_kernel_m8n32_1                             
   vbroadcastss    8(%%rax), %%zmm2                         
   vfmadd231ps        %%zmm0, %%zmm4, %%zmm8                  
   vfmadd231ps        %%zmm0, %%zmm5, %%zmm9                  

   vbroadcastss    12(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm4, %%zmm10                 
   vfmadd231ps        %%zmm1, %%zmm5, %%zmm11                 

   prefetcht0      256(%%rax)                               
   addq             $128, %%rbx                             

   vbroadcastss    16(%%rax), %%zmm0                        
   vfmadd231ps        %%zmm2, %%zmm4, %%zmm12                 
   vfmadd231ps        %%zmm2, %%zmm5, %%zmm13                 
   vmovdqu16        (%%rbx), %%zmm6                         

   vbroadcastss    20(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm4, %%zmm14                 
   vfmadd231ps        %%zmm3, %%zmm5, %%zmm15                 

   vbroadcastss    24(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm4, %%zmm16                 
   vfmadd231ps        %%zmm0, %%zmm5, %%zmm17                 
   vmovdqu16        64(%%rbx), %%zmm7                       

   vbroadcastss    28(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm4, %%zmm18                 
   vfmadd231ps        %%zmm1, %%zmm5, %%zmm19                 

   addq              $32, %%rax                             
   vbroadcastss     (%%rax), %%zmm0                         
   vfmadd231ps        %%zmm2, %%zmm4, %%zmm20                 
   vfmadd231ps        %%zmm2, %%zmm5, %%zmm21                 

   vbroadcastss     4(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm4, %%zmm22                 
   vfmadd231ps        %%zmm3, %%zmm5, %%zmm23                 
.endm                                                       

.macro    f32_kernel_m8n32_2                             
   vbroadcastss    8(%%rax), %%zmm2                         
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm8                  
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm9                  

   vbroadcastss    12(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm10                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm11                 

   prefetcht0         256(%%rax)                            
   addq              $128, %%rbx                            

   vbroadcastss    16(%%rax), %%zmm0                        
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm12                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm13                 

   vbroadcastss    20(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm14                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm15                 

   vbroadcastss    24(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm16                 
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm17                 
   vmovdqu16       (%%rbx), %%zmm4                          

   vbroadcastss    28(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm18                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm19                 
   vmovdqu16       64(%%rbx), %%zmm5                        

   addq             $32, %%rax                              

   vbroadcastss    (%%rax), %%zmm0                          
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm20                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm21                 

   vbroadcastss    4(%%rax), %%zmm1                         
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm22                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm23                 
.endm                                                       

.macro    f32_kernel_m8n32_end                           
   vbroadcastss    8(%%rax), %%zmm2                         
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm8                  
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm9                  

   vbroadcastss    12(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm10                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm11                 

   prefetcht0         256(%%rax)                            

   vbroadcastss    16(%%rax), %%zmm0                        
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm12                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm13                 

   vbroadcastss    20(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm14                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm15                 

   vbroadcastss    24(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm16                 
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm17                 

   vbroadcastss    28(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm18                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm19                 

   addq             $32, %%rax                              

   vfmadd231ps        %%zmm2, %%zmm6, %%zmm20                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm21                 

   vfmadd231ps        %%zmm3, %%zmm6, %%zmm22                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm23                 
.endm                                                       

.macro    f32_save_c_m8n32                                 
   vmovups         %%zmm8, (%%r10)                          
   vmovups         %%zmm9, 64(%%r10)                        
   vmovups         %%zmm10, (%%r11)                         
   vmovups         %%zmm11, 64(%%r11)                       
   vmovups         %%zmm12, (%%r12)                         
   vmovups         %%zmm13, 64(%%r12)                       
   vmovups         %%zmm14, (%%r13)                         
   vmovups         %%zmm15, 64(%%r13)                       

   leaq     (%%r13, %%r8, 4), %%r10                          // C0
   leaq     (%%r10, %%r8, 4), %%r11                          // C1
   leaq     (%%r11, %%r8, 4), %%r12                          // C2
   leaq     (%%r12, %%r8, 4), %%r13                          // C3

   vmovups         %%zmm16, (%%r10)                         
   vmovups         %%zmm17, 64(%%r10)                       
   vmovups         %%zmm18, (%%r11)                         
   vmovups         %%zmm19, 64(%%r11)                       
   vmovups         %%zmm20, (%%r12)                         
   vmovups         %%zmm21, 64(%%r12)                       
   vmovups         %%zmm22, (%%r13)                         
   vmovups         %%zmm23, 64(%%r13)                       

   subq            $8, %%rdi                                
   leaq      (%%r13, %%r8, 4), %%rcx                         // C0
.endm                                                       

.macro    f32_save_c_m8n32_2                               
   vmovups         %%zmm8, (%%r10)                          
   vmovups         %%zmm9, 64(%%r10)                        
   vmovups         %%zmm10, 128(%%r10)                         
   vmovups         %%zmm11, 192(%%r10)                       
   vmovups         %%zmm12, 256(%%r10)                         
   vmovups         %%zmm13, 320(%%r10)                       
   vmovups         %%zmm14, 384(%%r10)                         
   vmovups         %%zmm15, 448(%%r10)                       

   addq            $512, %%r10 

   vmovups         %%zmm16, (%%r10)                          
   vmovups         %%zmm17, 64(%%r10)                        
   vmovups         %%zmm18, 128(%%r10)                         
   vmovups         %%zmm19, 192(%%r10)                       
   vmovups         %%zmm20, 256(%%r10)                         
   vmovups         %%zmm21, 320(%%r10)                       
   vmovups         %%zmm22, 384(%%r10)                         
   vmovups         %%zmm23, 448(%%r10)                      

   addq            $512, %%r10                         
   subq            $8, %%rdi                               
.endm                                                       

//-----------------------------------------------------------------

.macro    f32_kernel_m4n32_1                             
   vbroadcastss    8(%%rax), %%zmm2                         
   vfmadd231ps        %%zmm0, %%zmm4, %%zmm8                  
   vfmadd231ps        %%zmm0, %%zmm5, %%zmm9                  
   addq             $128, %%rbx                             
   vmovdqu16        (%%rbx), %%zmm6                         

   vbroadcastss    12(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm4, %%zmm10                 
   vfmadd231ps        %%zmm1, %%zmm5, %%zmm11                 
   vmovdqu16        64(%%rbx), %%zmm7                       

   prefetcht0      256(%%rax)                               
   addq              $16, %%rax                             

   vbroadcastss     (%%rax), %%zmm0                         
   vfmadd231ps        %%zmm2, %%zmm4, %%zmm12                 
   vfmadd231ps        %%zmm2, %%zmm5, %%zmm13                 

   vbroadcastss     4(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm4, %%zmm14                 
   vfmadd231ps        %%zmm3, %%zmm5, %%zmm15                 
.endm                                                       

.macro    f32_kernel_m4n32_2                             
   vbroadcastss     8(%%rax), %%zmm2                        
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm8                  
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm9                  
   addq             $128, %%rbx                             
   vmovdqu16        (%%rbx), %%zmm4                         

   vbroadcastss     12(%%rax), %%zmm3                       
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm10                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm11                 
   vmovdqu16        64(%%rbx), %%zmm5                       

   prefetcht0         256(%%rax)                            
   addq             $16, %%rax                              

   vbroadcastss     (%%rax), %%zmm0                         
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm12                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm13                 

   vbroadcastss     4(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm14                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm15                 
.endm                                                       

.macro    f32_kernel_m4n32_end                           
   vbroadcastss    8(%%rax), %%zmm2                         
   vfmadd231ps        %%zmm0, %%zmm6, %%zmm8                  
   vfmadd231ps        %%zmm0, %%zmm7, %%zmm9                  

   vbroadcastss    12(%%rax), %%zmm3                        
   vfmadd231ps        %%zmm1, %%zmm6, %%zmm10                 
   vfmadd231ps        %%zmm1, %%zmm7, %%zmm11                 

   prefetcht0         256(%%rax)                            

   addq             $16, %%rax                              
   vbroadcastss     (%%rax), %%zmm0                         
   vfmadd231ps        %%zmm2, %%zmm6, %%zmm12                 
   vfmadd231ps        %%zmm2, %%zmm7, %%zmm13                 

   vbroadcastss     4(%%rax), %%zmm1                        
   vfmadd231ps        %%zmm3, %%zmm6, %%zmm14                 
   vfmadd231ps        %%zmm3, %%zmm7, %%zmm15                 
.endm                                                       

.macro    f32_save_c_m4n32                                 
   vmovups         %%zmm8, (%%r10)                          
   vmovups         %%zmm9, 64(%%r10)                        
   vmovups         %%zmm10, (%%r11)                         
   vmovups         %%zmm11, 64(%%r11)                       
   vmovups         %%zmm12, (%%r12)                         
   vmovups         %%zmm13, 64(%%r12)                       
   vmovups         %%zmm14, (%%r13)                         
   vmovups         %%zmm15, 64(%%r13)                       

   subq            $4, %%rdi                                
   leaq      (%%r13, %%r8, 4), %%rcx                         // C0
.endm                                                       

.macro    f32_save_c_m4n32_2                               
   vmovups         %%zmm8, (%%r10)                          
   vmovups         %%zmm9, 64(%%r10)                        
   vmovups         %%zmm10, 128(%%r10)                         
   vmovups         %%zmm11, 192(%%r10)                       
   vmovups         %%zmm12, 256(%%r10)                         
   vmovups         %%zmm13, 320(%%r10)                       
   vmovups         %%zmm14, 384(%%r10)                         
   vmovups         %%zmm15, 448(%%r10)                       

   addq            $512, %%r10                              
   subq            $4, %%rdi                                 
.endm                                                       

//-----------------------------------------------------------------
//-----------------------------------------------------------------

GEMM_F32_N32:                                              
   mov     %[C], %%rcx                                      
   mov     %[Cc], %%r10                                     
   mov     %[A], %%rax                                      
   mov     %[B], %%rbx                                      

   prefetcht0         (%%rax)                               

   mov     %[K], %%rdx                                      
   mov     %[LN], %%r8                                      
   mov     %[Bc], %%r14                                     
   mov     %[M], %%rdi                                      

   mov     %[LK], %%r15                                     
   mov     %%rax, %%r9                                      

   prefetcht0         (%%rbx)                               
   mov     %%rdx, %%rsi                                     

   mov    %[is_start_gemm], %%r12                           
   test   $1, %%r12                                         
   jz     F32_BEGIN_M12N32                                 

//-----------------------------------------------------------------

F32_BEGIN_PACK_N32:
   mov     %%rsi, %%rdx                                      // K                       
   mov     %%r14, %%rbp                                      // Bc

   vmovups (%%rbx), %%zmm4                                                         
   vmovups 64(%%rbx), %%zmm5
   
   vpxorq         %%zmm8, %%zmm8, %%zmm8                    
   vpxorq         %%zmm9, %%zmm9, %%zmm9                    
   vpxorq         %%zmm10, %%zmm10, %%zmm10                 
   vpxorq         %%zmm11, %%zmm11, %%zmm11                 
   vpxorq         %%zmm12, %%zmm12, %%zmm12                 
   vpxorq         %%zmm13, %%zmm13, %%zmm13                 
   vpxorq         %%zmm14, %%zmm14, %%zmm14                 
   vpxorq         %%zmm15, %%zmm15, %%zmm15                 
   vpxorq         %%zmm16, %%zmm16, %%zmm16                 
   vpxorq         %%zmm17, %%zmm17, %%zmm17                 
   vpxorq         %%zmm18, %%zmm18, %%zmm18                 
   vpxorq         %%zmm19, %%zmm19, %%zmm19
   vbroadcastss	(%%rax), %%zmm0 // A0
   vbroadcastss	4(%%rax), %%zmm1// A1                
   vpxorq         %%zmm20, %%zmm20, %%zmm20                 
   vpxorq         %%zmm21, %%zmm21, %%zmm21                 
   vpxorq         %%zmm22, %%zmm22, %%zmm22                 
   vpxorq         %%zmm23, %%zmm23, %%zmm23                 
   vpxorq         %%zmm24, %%zmm24, %%zmm24                 
   vpxorq         %%zmm25, %%zmm25, %%zmm25                 
   vpxorq         %%zmm26, %%zmm26, %%zmm26                 
   vpxorq         %%zmm27, %%zmm27, %%zmm27                 
   vpxorq         %%zmm28, %%zmm28, %%zmm28                 
   vpxorq         %%zmm29, %%zmm29, %%zmm29                 
   vpxorq         %%zmm30, %%zmm30, %%zmm30                 
   vpxorq         %%zmm31, %%zmm31, %%zmm31                 
   cmp     $8, %%rdx                                       
   jb      F32_PACK_MAIN_M12N32K1                          
   subq    $8, %%rdx                                       

F32_PACK_MAIN_M12N32K8:                                   
   f32_kernel_m12n32_pack_1                                
   f32_kernel_m12n32_pack_2                                
   f32_kernel_m12n32_pack_1                              
   f32_kernel_m12n32_pack_2                              
   f32_kernel_m12n32_pack_1                              
   f32_kernel_m12n32_pack_2                              
   f32_kernel_m12n32_pack_1
   cmp     $0, %%rdx                                        
   je      F32_PACK_MAIN_END_1
   f32_kernel_m12n32_pack_2
   cmp     $8, %%rdx                                       
   jb      F32_PACK_MAIN_M12N32K1                          
   subq    $8, %%rdx                                       
   jmp     F32_PACK_MAIN_M12N32K8                         

F32_PACK_MAIN_M12N32K1:
   cmp     $1, %%rdx                                        
   je      F32_PACK_MAIN_END_2
   f32_kernel_m12n32_pack_1                                    
   subq    $1, %%rdx
   cmp     $1, %%rdx
   je      F32_PACK_MAIN_END_1
   f32_kernel_m12n32_pack_2      
   subq    $1, %%rdx                                                              
   jmp     F32_PACK_MAIN_M12N32K1                      

F32_PACK_MAIN_END_1:
   f32_kernel_m12n32_pack_2_end
   jmp     F32_BEGIN_SAVE_M12N32

F32_PACK_MAIN_END_2:
   f32_kernel_m12n32_pack_1_end
   jmp     F32_BEGIN_SAVE_M12N32

//-----------------------------------------------------------------

F32_BEGIN_M12N32:                                          
   cmpq    $12, %%rdi                                       
   jb      F32_BEGIN_M8N32                                 

   mov     %%r14, %%rbx                                      // Bc
   mov     %%rsi, %%rdx                                      // K
   vmovups        (%%rbx), %%zmm4                            // B0-15
   vmovups     64(%%rbx), %%zmm5                             // B16-31
   vpxorq         %%zmm8, %%zmm8, %%zmm8                    
   vpxorq         %%zmm9, %%zmm9, %%zmm9                    
   vpxorq         %%zmm10, %%zmm10, %%zmm10                 
   vpxorq         %%zmm11, %%zmm11, %%zmm11                 
   vpxorq         %%zmm12, %%zmm12, %%zmm12                 
   vpxorq         %%zmm13, %%zmm13, %%zmm13                 
   vpxorq         %%zmm14, %%zmm14, %%zmm14                 
   vpxorq         %%zmm15, %%zmm15, %%zmm15                 
   vpxorq         %%zmm16, %%zmm16, %%zmm16                 
   vpxorq         %%zmm17, %%zmm17, %%zmm17                 
   vpxorq         %%zmm18, %%zmm18, %%zmm18                 
   vpxorq         %%zmm19, %%zmm19, %%zmm19                 
   vbroadcastss    (%%rax), %%zmm0                           // A0
   vbroadcastss    4(%%rax), %%zmm1                          // A1
   vpxorq         %%zmm20, %%zmm20, %%zmm20                 
   vpxorq         %%zmm21, %%zmm21, %%zmm21                 
   vpxorq         %%zmm22, %%zmm22, %%zmm22                 
   vpxorq         %%zmm23, %%zmm23, %%zmm23                 
   vpxorq         %%zmm24, %%zmm24, %%zmm24                 
   vpxorq         %%zmm25, %%zmm25, %%zmm25                 
   vpxorq         %%zmm26, %%zmm26, %%zmm26                 
   vpxorq         %%zmm27, %%zmm27, %%zmm27                 
   vpxorq         %%zmm28, %%zmm28, %%zmm28                 
   vpxorq         %%zmm29, %%zmm29, %%zmm29                 
   vpxorq         %%zmm30, %%zmm30, %%zmm30                 
   vpxorq         %%zmm31, %%zmm31, %%zmm31                 
   cmp     $8, %%rdx                                       
   jb      F32_MAIN_M12N32K1                               
   subq    $8, %%rdx                                       

F32_MAIN_K_M12N32K8:                                       // loop K+=4
   f32_kernel_m12n32_1                                   
   f32_kernel_m12n32_2                                   
   f32_kernel_m12n32_1                                   
   f32_kernel_m12n32_2                                   
   f32_kernel_m12n32_1                                   
   f32_kernel_m12n32_2                                   
   f32_kernel_m12n32_1                                   
   f32_kernel_m12n32_2                                   
   cmp     $0, %%rdx                                        
   je      F32_BEGIN_SAVE_M12N32                           
   cmp     $8, %%rdx                                       
   jb      F32_MAIN_M12N32K1                               
   subq    $8, %%rdx                                         
   jmp     F32_MAIN_K_M12N32K8                              

F32_MAIN_M12N32K1:                                         
   f32_kernel_m12n32_1                                   
   subq    $1, %%rdx                                        
   cmp     $0, %%rdx                                        
   je      F32_BEGIN_SAVE_M12N32                           
   f32_kernel_m12n32_2                                   
   subq    $1, %%rdx                                        
   cmp     $0, %%rdx                                        
   je      F32_BEGIN_SAVE_M12N32                           
   jmp     F32_MAIN_M12N32K1                               

F32_BEGIN_SAVE_M12N32:                                     
   mov    %[is_end_gemm], %%r13                             
   test      $1, %%r13                                      
   jz       F32_SAVE_C_M12N32_2                            
   mov      %%rcx, %%r10                                     // C0
   leaq     (%%r10, %%r8, 4), %%r11                          // C1
   leaq     (%%r11, %%r8, 4), %%r12                          // C2
   leaq     (%%r12, %%r8, 4), %%r13                          // C3

F32_SAVE_C_M12N32:                                         
   f32_save_c_m12n32                                       
   imul     $48, %%r15, %%r11                                // temp use %%r11
   add      %%r11, %%r9                                     
   movq     %%r9, %%rax                                     
   jmp     F32_BEGIN_M12N32                                

F32_SAVE_C_M12N32_2:                                       
   f32_save_c_m12n32_2                                     
   imul     $48, %%r15, %%r11                                // temp use %%r11
   add      %%r11, %%r9                                     
   movq     %%r9, %%rax                                     
   jmp     F32_BEGIN_M12N32                                

//-----------------------------------------------------------------

F32_BEGIN_M8N32:                                           
   cmpq    $8, %%rdi                                        
   jb      F32_BEGIN_M4N32                                 

   mov     %%r14, %%rbx                                      // Bc
   mov     %%rsi, %%rdx                                      // K
   vmovups        (%%rbx), %%zmm4                            // B0-15
   vmovups     64(%%rbx), %%zmm5                             // B16-31
   vpxorq         %%zmm8, %%zmm8, %%zmm8                    
   vpxorq         %%zmm9, %%zmm9, %%zmm9                    
   vpxorq         %%zmm10, %%zmm10, %%zmm10                 
   vpxorq         %%zmm11, %%zmm11, %%zmm11                 
   vpxorq         %%zmm12, %%zmm12, %%zmm12                 
   vpxorq         %%zmm13, %%zmm13, %%zmm13                 
   vpxorq         %%zmm14, %%zmm14, %%zmm14                 
   vpxorq         %%zmm15, %%zmm15, %%zmm15                 
   vbroadcastss    (%%rax), %%zmm0                           // A0
   vbroadcastss    4(%%rax), %%zmm1                          // A1
   vpxorq         %%zmm16, %%zmm16, %%zmm16                 
   vpxorq         %%zmm17, %%zmm17, %%zmm17                 
   vpxorq         %%zmm18, %%zmm18, %%zmm18                 
   vpxorq         %%zmm19, %%zmm19, %%zmm19                 
   vpxorq         %%zmm20, %%zmm20, %%zmm20                 
   vpxorq         %%zmm21, %%zmm21, %%zmm21                 
   vpxorq         %%zmm22, %%zmm22, %%zmm22                 
   vpxorq         %%zmm23, %%zmm23, %%zmm23                 
   cmpq    $8, %%rdx                                       
   jb      F32_MAIN_M8N32K1                                
   subq    $8, %%rdx                                       

F32_MAIN_K_M8N32K8:                                       
   f32_kernel_m8n32_1                                    
   f32_kernel_m8n32_2                                    
   f32_kernel_m8n32_1                                    
   f32_kernel_m8n32_2                                    
   f32_kernel_m8n32_1                                    
   f32_kernel_m8n32_2                                    
   f32_kernel_m8n32_1                                    
   f32_kernel_m8n32_2                                    
   cmp     $0, %%rdx                                        
   je      F32_BEGIN_SAVE_M8N32                            
   cmpq    $8, %%rdx                                       
   jb      F32_MAIN_M8N32K1                                
   subq  $8, %%rdx                                         
   jmp   F32_MAIN_K_M8N32K8                               

F32_MAIN_M8N32K1:                                          
   f32_kernel_m8n32_1                                    
   subq    $1, %%rdx                                        
   cmp     $0, %%rdx                                        
   je      F32_BEGIN_SAVE_M8N32                            
   f32_kernel_m8n32_2                                    
   subq    $1, %%rdx                                        
   cmp     $0, %%rdx                                        
   je      F32_BEGIN_SAVE_M8N32                            
   jmp     F32_MAIN_M8N32K1                                

F32_BEGIN_SAVE_M8N32:                                      
   mov    %[is_end_gemm], %%r13                             
   test      $1, %%r13                                      
   jz       F32_SAVE_C_M8N32_2                             
   mov      %%rcx, %%r10                                     // C0
   leaq     (%%r10, %%r8, 4), %%r11                          // C1
   leaq     (%%r11, %%r8, 4), %%r12                          // C2
   leaq     (%%r12, %%r8, 4), %%r13                          // C3

F32_SAVE_C_M8N32:                                          
   f32_save_c_m8n32                                        
   imul     $32, %%r15, %%r11                                // temp use %%r11
   add      %%r11, %%r9                                     
   movq     %%r9, %%rax                                     
   jmp      F32_BEGIN_M8N32                                

F32_SAVE_C_M8N32_2:                                        
   f32_save_c_m8n32_2                                      
   imul     $32, %%r15, %%r11                                // temp use %%r11
   add      %%r11, %%r9                                     
   movq     %%r9, %%rax                                     
   jmp      F32_BEGIN_M8N32                                

//-----------------------------------------------------------------

F32_BEGIN_M4N32:                                           
   cmpq    $0, %%rdi                                        
   je      F32_END_N32                                     
   mov     %%r14, %%rbx                                      // Bc
   mov     %%rsi, %%rdx                                      // K
   vmovups        (%%rbx), %%zmm4                            // B0-15
   vmovups     64(%%rbx), %%zmm5                             // B16-31
   vbroadcastss    (%%rax), %%zmm0                           // A0
   vbroadcastss    4(%%rax), %%zmm1                          // A1
   vpxorq         %%zmm8, %%zmm8, %%zmm8                    
   vpxorq         %%zmm9, %%zmm9, %%zmm9                    
   vpxorq         %%zmm10, %%zmm10, %%zmm10                 
   vpxorq         %%zmm11, %%zmm11, %%zmm11                 
   vpxorq         %%zmm12, %%zmm12, %%zmm12                 
   vpxorq         %%zmm13, %%zmm13, %%zmm13                 
   vpxorq         %%zmm14, %%zmm14, %%zmm14                 
   vpxorq         %%zmm15, %%zmm15, %%zmm15                 
   cmpq    $8, %%rdx                                       
   jb      F32_MAIN_M4N32K1                                
   subq  $8, %%rdx                                         

F32_MAIN_K_M4N32K8:                                        // loop K+=4
   f32_kernel_m4n32_1                                    
   f32_kernel_m4n32_2                                    
   f32_kernel_m4n32_1                                    
   f32_kernel_m4n32_2                                    
   f32_kernel_m4n32_1                                    
   f32_kernel_m4n32_2                                    
   f32_kernel_m4n32_1                                    
   f32_kernel_m4n32_2                                    
   cmp     $0, %%rdx                                        
   je      F32_BEGIN_SAVE_M4N32                            
   cmpq    $8, %%rdx                                       
   jb      F32_MAIN_M4N32K1                                
   subq  $8, %%rdx                                         
   jmp   F32_MAIN_K_M4N32K8                               

F32_MAIN_M4N32K1:                                          
   f32_kernel_m4n32_1                                    
   subq    $1, %%rdx                                        
   cmp     $0, %%rdx                                        
   je      F32_BEGIN_SAVE_M4N32                            
   f32_kernel_m4n32_2                                    
   subq    $1, %%rdx                                        
   cmp     $0, %%rdx                                        
   je      F32_BEGIN_SAVE_M4N32                            
   jmp     F32_MAIN_M4N32K1                                

F32_BEGIN_SAVE_M4N32:                                      
   mov    %[is_end_gemm], %%r13                             
   test     $1, %%r13                                       
   jz       F32_SAVE_C_M4N32_2                             
   mov      %%rcx, %%r10                                     // C0
   leaq     (%%r10, %%r8, 4), %%r11                          // C1
   leaq     (%%r11, %%r8, 4), %%r12                          // C2
   leaq     (%%r12, %%r8, 4), %%r13                          // C3

F32_SAVE_C_M4N32:                                          
   cmpq     $3, %%rdi                                       
   je       F32_SAVE_C_M3N32                               
   cmpq     $2, %%rdi                                       
   je       F32_SAVE_C_M2N32                               
   cmpq     $1, %%rdi                                       
   je       F32_SAVE_C_M1N32                               
   f32_save_c_m4n32                                        
   imul     $16, %%r15, %%r11                                 // temp use %%r11
   add      %%r11, %%r9                                     
   movq     %%r9, %%rax                                     
   jmp      F32_BEGIN_M4N32                                

F32_SAVE_C_M3N32:                                          
   vmovups         %%zmm12, (%%r12)                         
   vmovups         %%zmm13, 64(%%r12)                       

F32_SAVE_C_M2N32:                                          
   vmovups         %%zmm10, (%%r11)                         
   vmovups         %%zmm11, 64(%%r11)                       

F32_SAVE_C_M1N32:                                          
   vmovups         %%zmm8, (%%r10)                          
   vmovups         %%zmm9, 64(%%r10)                        
   jmp      F32_END_N32                                    

F32_SAVE_C_M4N32_2:                                        
   cmpq     $3, %%rdi                                       
   je       F32_SAVE_C_M3N32_2                             
   cmpq     $2, %%rdi                                       
   je       F32_SAVE_C_M2N32_2                             
   cmpq     $1, %%rdi                                       
   je       F32_SAVE_C_M1N32_2                             
   f32_save_c_m4n32_2                                      
   imul     $16, %%r15, %%r11                                 // temp use %%r11
   add      %%r11, %%r9                                     
   movq     %%r9, %%rax                                     
   jmp      F32_BEGIN_M4N32                                

F32_SAVE_C_M3N32_2:                                        
   vmovups         %%zmm12, 256(%%r10)                         
   vmovups         %%zmm13, 320(%%r10)

F32_SAVE_C_M2N32_2:                                        
   vmovups         %%zmm10, 128(%%r10)                         
   vmovups         %%zmm11, 192(%%r10)                       

F32_SAVE_C_M1N32_2:                                        
   vmovups         %%zmm8, (%%r10)                          
   vmovups         %%zmm9, 64(%%r10)

F32_END_N32:                                               