
a.out:     file format elf64-x86-64


Disassembly of section .init:

0000000000001000 <_init>:
    1000:	f3 0f 1e fa          	endbr64
    1004:	48 83 ec 08          	sub    $0x8,%rsp
    1008:	48 8b 05 e9 6f 00 00 	mov    0x6fe9(%rip),%rax        # 7ff8 <__gmon_start__@Base>
    100f:	48 85 c0             	test   %rax,%rax
    1012:	74 02                	je     1016 <_init+0x16>
    1014:	ff d0                	call   *%rax
    1016:	48 83 c4 08          	add    $0x8,%rsp
    101a:	c3                   	ret

Disassembly of section .plt:

0000000000001020 <.plt>:
    1020:	ff 35 0a 6f 00 00    	push   0x6f0a(%rip)        # 7f30 <_GLOBAL_OFFSET_TABLE_+0x8>
    1026:	ff 25 0c 6f 00 00    	jmp    *0x6f0c(%rip)        # 7f38 <_GLOBAL_OFFSET_TABLE_+0x10>
    102c:	0f 1f 40 00          	nopl   0x0(%rax)
    1030:	f3 0f 1e fa          	endbr64
    1034:	68 00 00 00 00       	push   $0x0
    1039:	e9 e2 ff ff ff       	jmp    1020 <_init+0x20>
    103e:	66 90                	xchg   %ax,%ax
    1040:	f3 0f 1e fa          	endbr64
    1044:	68 01 00 00 00       	push   $0x1
    1049:	e9 d2 ff ff ff       	jmp    1020 <_init+0x20>
    104e:	66 90                	xchg   %ax,%ax
    1050:	f3 0f 1e fa          	endbr64
    1054:	68 02 00 00 00       	push   $0x2
    1059:	e9 c2 ff ff ff       	jmp    1020 <_init+0x20>
    105e:	66 90                	xchg   %ax,%ax
    1060:	f3 0f 1e fa          	endbr64
    1064:	68 03 00 00 00       	push   $0x3
    1069:	e9 b2 ff ff ff       	jmp    1020 <_init+0x20>
    106e:	66 90                	xchg   %ax,%ax
    1070:	f3 0f 1e fa          	endbr64
    1074:	68 04 00 00 00       	push   $0x4
    1079:	e9 a2 ff ff ff       	jmp    1020 <_init+0x20>
    107e:	66 90                	xchg   %ax,%ax
    1080:	f3 0f 1e fa          	endbr64
    1084:	68 05 00 00 00       	push   $0x5
    1089:	e9 92 ff ff ff       	jmp    1020 <_init+0x20>
    108e:	66 90                	xchg   %ax,%ax
    1090:	f3 0f 1e fa          	endbr64
    1094:	68 06 00 00 00       	push   $0x6
    1099:	e9 82 ff ff ff       	jmp    1020 <_init+0x20>
    109e:	66 90                	xchg   %ax,%ax
    10a0:	f3 0f 1e fa          	endbr64
    10a4:	68 07 00 00 00       	push   $0x7
    10a9:	e9 72 ff ff ff       	jmp    1020 <_init+0x20>
    10ae:	66 90                	xchg   %ax,%ax
    10b0:	f3 0f 1e fa          	endbr64
    10b4:	68 08 00 00 00       	push   $0x8
    10b9:	e9 62 ff ff ff       	jmp    1020 <_init+0x20>
    10be:	66 90                	xchg   %ax,%ax
    10c0:	f3 0f 1e fa          	endbr64
    10c4:	68 09 00 00 00       	push   $0x9
    10c9:	e9 52 ff ff ff       	jmp    1020 <_init+0x20>
    10ce:	66 90                	xchg   %ax,%ax
    10d0:	f3 0f 1e fa          	endbr64
    10d4:	68 0a 00 00 00       	push   $0xa
    10d9:	e9 42 ff ff ff       	jmp    1020 <_init+0x20>
    10de:	66 90                	xchg   %ax,%ax
    10e0:	f3 0f 1e fa          	endbr64
    10e4:	68 0b 00 00 00       	push   $0xb
    10e9:	e9 32 ff ff ff       	jmp    1020 <_init+0x20>
    10ee:	66 90                	xchg   %ax,%ax
    10f0:	f3 0f 1e fa          	endbr64
    10f4:	68 0c 00 00 00       	push   $0xc
    10f9:	e9 22 ff ff ff       	jmp    1020 <_init+0x20>
    10fe:	66 90                	xchg   %ax,%ax
    1100:	f3 0f 1e fa          	endbr64
    1104:	68 0d 00 00 00       	push   $0xd
    1109:	e9 12 ff ff ff       	jmp    1020 <_init+0x20>
    110e:	66 90                	xchg   %ax,%ax
    1110:	f3 0f 1e fa          	endbr64
    1114:	68 0e 00 00 00       	push   $0xe
    1119:	e9 02 ff ff ff       	jmp    1020 <_init+0x20>
    111e:	66 90                	xchg   %ax,%ax
    1120:	f3 0f 1e fa          	endbr64
    1124:	68 0f 00 00 00       	push   $0xf
    1129:	e9 f2 fe ff ff       	jmp    1020 <_init+0x20>
    112e:	66 90                	xchg   %ax,%ax
    1130:	f3 0f 1e fa          	endbr64
    1134:	68 10 00 00 00       	push   $0x10
    1139:	e9 e2 fe ff ff       	jmp    1020 <_init+0x20>
    113e:	66 90                	xchg   %ax,%ax
    1140:	f3 0f 1e fa          	endbr64
    1144:	68 11 00 00 00       	push   $0x11
    1149:	e9 d2 fe ff ff       	jmp    1020 <_init+0x20>
    114e:	66 90                	xchg   %ax,%ax
    1150:	f3 0f 1e fa          	endbr64
    1154:	68 12 00 00 00       	push   $0x12
    1159:	e9 c2 fe ff ff       	jmp    1020 <_init+0x20>
    115e:	66 90                	xchg   %ax,%ax

Disassembly of section .plt.got:

0000000000001160 <__cxa_finalize@plt>:
    1160:	f3 0f 1e fa          	endbr64
    1164:	ff 25 86 6e 00 00    	jmp    *0x6e86(%rip)        # 7ff0 <__cxa_finalize@GLIBC_2.2.5>
    116a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

Disassembly of section .plt.sec:

0000000000001170 <__fprintf_chk@plt>:
    1170:	f3 0f 1e fa          	endbr64
    1174:	ff 25 c6 6d 00 00    	jmp    *0x6dc6(%rip)        # 7f40 <__fprintf_chk@GLIBC_2.3.4>
    117a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001180 <GOMP_barrier@plt>:
    1180:	f3 0f 1e fa          	endbr64
    1184:	ff 25 be 6d 00 00    	jmp    *0x6dbe(%rip)        # 7f48 <GOMP_barrier@GOMP_1.0>
    118a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001190 <__stack_chk_fail@plt>:
    1190:	f3 0f 1e fa          	endbr64
    1194:	ff 25 b6 6d 00 00    	jmp    *0x6db6(%rip)        # 7f50 <__stack_chk_fail@GLIBC_2.4>
    119a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

00000000000011a0 <cblas_gemm_bf16bf16f32@plt>:
    11a0:	f3 0f 1e fa          	endbr64
    11a4:	ff 25 ae 6d 00 00    	jmp    *0x6dae(%rip)        # 7f58 <cblas_gemm_bf16bf16f32@Base>
    11aa:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

00000000000011b0 <omp_set_num_threads@plt>:
    11b0:	f3 0f 1e fa          	endbr64
    11b4:	ff 25 a6 6d 00 00    	jmp    *0x6da6(%rip)        # 7f60 <omp_set_num_threads@OMP_1.0>
    11ba:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

00000000000011c0 <__printf_chk@plt>:
    11c0:	f3 0f 1e fa          	endbr64
    11c4:	ff 25 9e 6d 00 00    	jmp    *0x6d9e(%rip)        # 7f68 <__printf_chk@GLIBC_2.3.4>
    11ca:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

00000000000011d0 <fwrite@plt>:
    11d0:	f3 0f 1e fa          	endbr64
    11d4:	ff 25 96 6d 00 00    	jmp    *0x6d96(%rip)        # 7f70 <fwrite@GLIBC_2.2.5>
    11da:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

00000000000011e0 <putchar@plt>:
    11e0:	f3 0f 1e fa          	endbr64
    11e4:	ff 25 8e 6d 00 00    	jmp    *0x6d8e(%rip)        # 7f78 <putchar@GLIBC_2.2.5>
    11ea:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

00000000000011f0 <posix_memalign@plt>:
    11f0:	f3 0f 1e fa          	endbr64
    11f4:	ff 25 86 6d 00 00    	jmp    *0x6d86(%rip)        # 7f80 <posix_memalign@GLIBC_2.2.5>
    11fa:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001200 <fopen@plt>:
    1200:	f3 0f 1e fa          	endbr64
    1204:	ff 25 7e 6d 00 00    	jmp    *0x6d7e(%rip)        # 7f88 <fopen@GLIBC_2.2.5>
    120a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001210 <memcpy@plt>:
    1210:	f3 0f 1e fa          	endbr64
    1214:	ff 25 76 6d 00 00    	jmp    *0x6d76(%rip)        # 7f90 <memcpy@GLIBC_2.14>
    121a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001220 <free@plt>:
    1220:	f3 0f 1e fa          	endbr64
    1224:	ff 25 6e 6d 00 00    	jmp    *0x6d6e(%rip)        # 7f98 <free@GLIBC_2.2.5>
    122a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001230 <omp_get_thread_num@plt>:
    1230:	f3 0f 1e fa          	endbr64
    1234:	ff 25 66 6d 00 00    	jmp    *0x6d66(%rip)        # 7fa0 <omp_get_thread_num@OMP_1.0>
    123a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001240 <gettimeofday@plt>:
    1240:	f3 0f 1e fa          	endbr64
    1244:	ff 25 5e 6d 00 00    	jmp    *0x6d5e(%rip)        # 7fa8 <gettimeofday@GLIBC_2.2.5>
    124a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001250 <exit@plt>:
    1250:	f3 0f 1e fa          	endbr64
    1254:	ff 25 56 6d 00 00    	jmp    *0x6d56(%rip)        # 7fb0 <exit@GLIBC_2.2.5>
    125a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001260 <malloc@plt>:
    1260:	f3 0f 1e fa          	endbr64
    1264:	ff 25 4e 6d 00 00    	jmp    *0x6d4e(%rip)        # 7fb8 <malloc@GLIBC_2.2.5>
    126a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001270 <GOMP_parallel@plt>:
    1270:	f3 0f 1e fa          	endbr64
    1274:	ff 25 46 6d 00 00    	jmp    *0x6d46(%rip)        # 7fc0 <GOMP_parallel@GOMP_4.0>
    127a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001280 <rand@plt>:
    1280:	f3 0f 1e fa          	endbr64
    1284:	ff 25 3e 6d 00 00    	jmp    *0x6d3e(%rip)        # 7fc8 <rand@GLIBC_2.2.5>
    128a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000001290 <puts@plt>:
    1290:	f3 0f 1e fa          	endbr64
    1294:	ff 25 36 6d 00 00    	jmp    *0x6d36(%rip)        # 7fd0 <puts@GLIBC_2.2.5>
    129a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

Disassembly of section .text:

00000000000012a0 <main>:
using namespace std;
#define PEAK_GFLOPS 3.8
#define NUM 1

int main()
{
    12a0:	f3 0f 1e fa          	endbr64
    12a4:	41 56                	push   %r14
	// mkl_set_num_threads(NUM);
	omp_set_num_threads(NUM);
    12a6:	bf 01 00 00 00       	mov    $0x1,%edi
{
    12ab:	41 55                	push   %r13
    12ad:	41 54                	push   %r12
    12af:	55                   	push   %rbp
    12b0:	53                   	push   %rbx
    12b1:	48 83 ec 30          	sub    $0x30,%rsp
    12b5:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    12bc:	00 00 
    12be:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    12c3:	31 c0                	xor    %eax,%eax
	omp_set_num_threads(NUM);
    12c5:	e8 e6 fe ff ff       	call   11b0 <omp_set_num_threads@plt>
	int loop = 10;
	double start, cost;
	double gflops;

	FILE *fp;
	if ((fp = fopen("./result.txt", "w")) == NULL)
    12ca:	48 8d 35 87 4d 00 00 	lea    0x4d87(%rip),%rsi        # 6058 <_IO_stdin_used+0x58>
    12d1:	48 8d 3d 82 4d 00 00 	lea    0x4d82(%rip),%rdi        # 605a <_IO_stdin_used+0x5a>

int flashgemm_thread_num = 1;

void flashgemm_set_thread_num(int num)
{
	flashgemm_thread_num = num;
    12d8:	c7 05 2e 6d 00 00 01 	movl   $0x1,0x6d2e(%rip)        # 8010 <flashgemm_thread_num>
    12df:	00 00 00 
    12e2:	e8 19 ff ff ff       	call   1200 <fopen@plt>
    12e7:	48 85 c0             	test   %rax,%rax
    12ea:	0f 84 41 02 00 00    	je     1531 <main+0x291>
		long K = 32; // K % (16 * 4)==0

		double ops = (double)M * N * K * 1.0e-09 * 2;

		void *ptrA, *ptrB;
		posix_memalign(&ptrA, 64, M * K * sizeof(uint16_t));
    12f0:	48 8d 7c 24 18       	lea    0x18(%rsp),%rdi
    12f5:	ba 00 03 00 00       	mov    $0x300,%edx
    12fa:	be 40 00 00 00       	mov    $0x40,%esi
    12ff:	49 89 c4             	mov    %rax,%r12
    1302:	e8 e9 fe ff ff       	call   11f0 <posix_memalign@plt>
    1307:	85 c0                	test   %eax,%eax
    1309:	75 05                	jne    1310 <main+0x70>
    130b:	4c 8b 74 24 18       	mov    0x18(%rsp),%r14
		posix_memalign(&ptrB, 64, N * K * sizeof(uint16_t));
    1310:	48 8d 7c 24 20       	lea    0x20(%rsp),%rdi
    1315:	ba 00 08 00 00       	mov    $0x800,%edx
    131a:	be 40 00 00 00       	mov    $0x40,%esi
    131f:	e8 cc fe ff ff       	call   11f0 <posix_memalign@plt>
    1324:	85 c0                	test   %eax,%eax
    1326:	75 05                	jne    132d <main+0x8d>
    1328:	4c 8b 6c 24 20       	mov    0x20(%rsp),%r13
		uint16_t *A = (uint16_t *)ptrA;
		uint16_t *B = (uint16_t *)ptrB;

		float *C = (float *)malloc(M * N * sizeof(float));
    132d:	bf 00 06 00 00       	mov    $0x600,%edi
    1332:	e8 29 ff ff ff       	call   1260 <malloc@plt>
		float *C_MKL = (float *)malloc(M * N * sizeof(float));
    1337:	bf 00 06 00 00       	mov    $0x600,%edi
		float *C = (float *)malloc(M * N * sizeof(float));
    133c:	48 89 c3             	mov    %rax,%rbx
		float *C_MKL = (float *)malloc(M * N * sizeof(float));
    133f:	e8 1c ff ff ff       	call   1260 <malloc@plt>
		// random_matrix_bf16(K, N, B);
		// random_matrix_bf16(M, K, A);
		// random_matrix_f32(M, N, C);
		// memcpy(C_MKL, C, M * N * sizeof(int32_t));

		regular_matrix_bf16(K, N, B);
    1344:	be 20 00 00 00       	mov    $0x20,%esi
    1349:	4c 89 ea             	mov    %r13,%rdx
    134c:	bf 20 00 00 00       	mov    $0x20,%edi
		float *C_MKL = (float *)malloc(M * N * sizeof(float));
    1351:	48 89 c5             	mov    %rax,%rbp
		regular_matrix_bf16(K, N, B);
    1354:	e8 d7 3d 00 00       	call   5130 <_Z19regular_matrix_bf16iiPt>
		regular_matrix_bf16(M, K, A);
    1359:	bf 0c 00 00 00       	mov    $0xc,%edi
    135e:	4c 89 f2             	mov    %r14,%rdx
    1361:	e8 ca 3d 00 00       	call   5130 <_Z19regular_matrix_bf16iiPt>
		regular_matrix_f32(M, N, C);
    1366:	48 89 da             	mov    %rbx,%rdx
    1369:	e8 42 3d 00 00       	call   50b0 <_Z18regular_matrix_f32iiPf>

__fortify_function void *
__NTH (memcpy (void *__restrict __dest, const void *__restrict __src,
	       size_t __len))
{
  return __builtin___memcpy_chk (__dest, __src, __len,
    136e:	b9 c0 00 00 00       	mov    $0xc0,%ecx
    1373:	48 89 ef             	mov    %rbp,%rdi
    1376:	48 89 de             	mov    %rbx,%rsi
    1379:	f3 48 a5             	rep movsq %ds:(%rsi),%es:(%rdi)
		// 	GEMM_BF16(C, A, B, M, N, K);
		// 	cost += dclock() - start;
		// }
		// cost = (dclock() - start) / loop;

		GEMM_BF16(C, A, B, M, N, K);
    137c:	41 b9 20 00 00 00    	mov    $0x20,%r9d
    1382:	4c 89 ea             	mov    %r13,%rdx
    1385:	4c 89 f6             	mov    %r14,%rsi
    1388:	41 b8 20 00 00 00    	mov    $0x20,%r8d
    138e:	b9 0c 00 00 00       	mov    $0xc,%ecx
    1393:	48 89 df             	mov    %rbx,%rdi
    1396:	c5 f8 77             	vzeroupper
    1399:	e8 42 39 00 00       	call   4ce0 <GEMM_BF16>
		cblas_gemm_bf16bf16f32(CblasRowMajor, CblasNoTrans, CblasNoTrans, 
    139e:	6a 20                	push   $0x20
    13a0:	c5 fa 10 05 60 4c 00 	vmovss 0x4c60(%rip),%xmm0        # 6008 <_IO_stdin_used+0x8>
    13a7:	00 
    13a8:	55                   	push   %rbp
    13a9:	b9 0c 00 00 00       	mov    $0xc,%ecx
    13ae:	ba 6f 00 00 00       	mov    $0x6f,%edx
    13b3:	be 6f 00 00 00       	mov    $0x6f,%esi
    13b8:	6a 20                	push   $0x20
    13ba:	c5 f0 57 c9          	vxorps %xmm1,%xmm1,%xmm1
    13be:	bf 65 00 00 00       	mov    $0x65,%edi
    13c3:	41 b9 20 00 00 00    	mov    $0x20,%r9d
    13c9:	41 55                	push   %r13
    13cb:	41 b8 20 00 00 00    	mov    $0x20,%r8d
    13d1:	6a 20                	push   $0x20
    13d3:	41 56                	push   %r14
    13d5:	e8 c6 fd ff ff       	call   11a0 <cblas_gemm_bf16bf16f32@plt>
}

__fortify_function int
printf (const char *__restrict __fmt, ...)
{
  return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
    13da:	48 83 c4 30          	add    $0x30,%rsp
    13de:	48 8d 3d 95 4c 00 00 	lea    0x4c95(%rip),%rdi        # 607a <_IO_stdin_used+0x7a>
    13e5:	e8 a6 fe ff ff       	call   1290 <puts@plt>
											 M, N, K, 1.0, A, K, B, N, 0.0, C_MKL, N);
		
		printf("C: \n");
		show_matrix_fp32(M, N, C);
    13ea:	48 89 da             	mov    %rbx,%rdx
    13ed:	be 20 00 00 00       	mov    $0x20,%esi
    13f2:	bf 0c 00 00 00       	mov    $0xc,%edi
    13f7:	e8 c4 3d 00 00       	call   51c0 <_Z16show_matrix_fp32llPf>
    13fc:	48 8d 3d 7b 4c 00 00 	lea    0x4c7b(%rip),%rdi        # 607e <_IO_stdin_used+0x7e>
    1403:	e8 88 fe ff ff       	call   1290 <puts@plt>
		printf("C_MKL: \n");
		show_matrix_fp32(M, N, C_MKL);
    1408:	48 89 ea             	mov    %rbp,%rdx
    140b:	be 20 00 00 00       	mov    $0x20,%esi
    1410:	bf 0c 00 00 00       	mov    $0xc,%edi
    1415:	e8 a6 3d 00 00       	call   51c0 <_Z16show_matrix_fp32llPf>

		if (Check_result(C, C_MKL, M, N))
    141a:	b9 20 00 00 00       	mov    $0x20,%ecx
    141f:	48 89 ee             	mov    %rbp,%rsi
    1422:	48 89 df             	mov    %rbx,%rdi
    1425:	ba 0c 00 00 00       	mov    $0xc,%edx
    142a:	e8 51 3f 00 00       	call   5380 <_Z12Check_resultPfS_ll>
    142f:	85 c0                	test   %eax,%eax
    1431:	0f 85 82 00 00 00    	jne    14b9 <main+0x219>
    1437:	b9 0c 00 00 00       	mov    $0xc,%ecx
    143c:	31 d2                	xor    %edx,%edx
    143e:	48 8d 35 8b 4c 00 00 	lea    0x4c8b(%rip),%rsi        # 60d0 <_IO_stdin_used+0xd0>
    1445:	31 c0                	xor    %eax,%eax
    1447:	bf 02 00 00 00       	mov    $0x2,%edi
    144c:	41 b9 20 00 00 00    	mov    $0x20,%r9d
    1452:	41 b8 20 00 00 00    	mov    $0x20,%r8d
    1458:	e8 63 fd ff ff       	call   11c0 <__printf_chk@plt>
  return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
    145d:	4c 89 e1             	mov    %r12,%rcx
    1460:	ba 08 00 00 00       	mov    $0x8,%edx
    1465:	be 01 00 00 00       	mov    $0x1,%esi
    146a:	48 8d 3d 1d 4c 00 00 	lea    0x4c1d(%rip),%rdi        # 608e <_IO_stdin_used+0x8e>
    1471:	e8 5a fd ff ff       	call   11d0 <fwrite@plt>
		}else{
			printf("bf16: id=%-3d M= %-8d N=%-8d K=%-8d error!!!\n", j, M, N, K);
			fprintf(fp, "error! \n");
		}

		free(ptrA);
    1476:	4c 89 f7             	mov    %r14,%rdi
    1479:	e8 a2 fd ff ff       	call   1220 <free@plt>
		free(ptrB);
    147e:	4c 89 ef             	mov    %r13,%rdi
    1481:	e8 9a fd ff ff       	call   1220 <free@plt>
		free(C);
    1486:	48 89 df             	mov    %rbx,%rdi
    1489:	e8 92 fd ff ff       	call   1220 <free@plt>
		free(C_MKL);
    148e:	48 89 ef             	mov    %rbp,%rdi
    1491:	e8 8a fd ff ff       	call   1220 <free@plt>
	}

	return 0;
}
    1496:	48 8b 44 24 28       	mov    0x28(%rsp),%rax
    149b:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    14a2:	00 00 
    14a4:	0f 85 82 00 00 00    	jne    152c <main+0x28c>
    14aa:	48 83 c4 30          	add    $0x30,%rsp
    14ae:	31 c0                	xor    %eax,%eax
    14b0:	5b                   	pop    %rbx
    14b1:	5d                   	pop    %rbp
    14b2:	41 5c                	pop    %r12
    14b4:	41 5d                	pop    %r13
    14b6:	41 5e                	pop    %r14
    14b8:	c3                   	ret
  return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
    14b9:	31 d2                	xor    %edx,%edx
    14bb:	b9 0c 00 00 00       	mov    $0xc,%ecx
						 j, M, N, K, ops / cost / ((PEAK_GFLOPS * 64 * 2)) * 100 / NUM);
    14c0:	c5 fb 10 05 48 4c 00 	vmovsd 0x4c48(%rip),%xmm0        # 6110 <_IO_stdin_used+0x110>
    14c7:	00 
    14c8:	c5 fb 5e 05 68 4c 00 	vdivsd 0x4c68(%rip),%xmm0,%xmm0        # 6138 <_IO_stdin_used+0x138>
    14cf:	00 
    14d0:	41 b9 20 00 00 00    	mov    $0x20,%r9d
    14d6:	c5 fb 5e 05 3a 4c 00 	vdivsd 0x4c3a(%rip),%xmm0,%xmm0        # 6118 <_IO_stdin_used+0x118>
    14dd:	00 
    14de:	41 b8 20 00 00 00    	mov    $0x20,%r8d
    14e4:	48 8d 35 ad 4b 00 00 	lea    0x4bad(%rip),%rsi        # 6098 <_IO_stdin_used+0x98>
			printf("bf16: id=%-3d M= %-8d N=%-8d K=%-8d effic= %.3lf \n",
    14eb:	c5 fb 59 05 2d 4c 00 	vmulsd 0x4c2d(%rip),%xmm0,%xmm0        # 6120 <_IO_stdin_used+0x120>
    14f2:	00 
    14f3:	bf 02 00 00 00       	mov    $0x2,%edi
    14f8:	b8 01 00 00 00       	mov    $0x1,%eax
    14fd:	c5 fb 11 44 24 08    	vmovsd %xmm0,0x8(%rsp)
    1503:	e8 b8 fc ff ff       	call   11c0 <__printf_chk@plt>
  return __fprintf_chk (__stream, __USE_FORTIFY_LEVEL - 1, __fmt,
    1508:	c5 fb 10 44 24 08    	vmovsd 0x8(%rsp),%xmm0
    150e:	be 02 00 00 00       	mov    $0x2,%esi
    1513:	4c 89 e7             	mov    %r12,%rdi
    1516:	48 8d 15 69 4b 00 00 	lea    0x4b69(%rip),%rdx        # 6086 <_IO_stdin_used+0x86>
    151d:	b8 01 00 00 00       	mov    $0x1,%eax
    1522:	e8 49 fc ff ff       	call   1170 <__fprintf_chk@plt>
			__va_arg_pack ());
    1527:	e9 4a ff ff ff       	jmp    1476 <main+0x1d6>
}
    152c:	e8 5f fc ff ff       	call   1190 <__stack_chk_fail@plt>
		puts("Fail to open file!");
    1531:	48 8d 3d 2f 4b 00 00 	lea    0x4b2f(%rip),%rdi        # 6067 <_IO_stdin_used+0x67>
    1538:	e8 53 fd ff ff       	call   1290 <puts@plt>
		exit(0);
    153d:	31 ff                	xor    %edi,%edi
    153f:	e8 0c fd ff ff       	call   1250 <exit@plt>
    1544:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    154b:	00 00 00 
    154e:	66 90                	xchg   %ax,%ax

0000000000001550 <_start>:
    1550:	f3 0f 1e fa          	endbr64
    1554:	31 ed                	xor    %ebp,%ebp
    1556:	49 89 d1             	mov    %rdx,%r9
    1559:	5e                   	pop    %rsi
    155a:	48 89 e2             	mov    %rsp,%rdx
    155d:	48 83 e4 f0          	and    $0xfffffffffffffff0,%rsp
    1561:	50                   	push   %rax
    1562:	54                   	push   %rsp
    1563:	45 31 c0             	xor    %r8d,%r8d
    1566:	31 c9                	xor    %ecx,%ecx
    1568:	48 8d 3d 31 fd ff ff 	lea    -0x2cf(%rip),%rdi        # 12a0 <main>
    156f:	ff 15 6b 6a 00 00    	call   *0x6a6b(%rip)        # 7fe0 <__libc_start_main@GLIBC_2.34>
    1575:	f4                   	hlt
    1576:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    157d:	00 00 00 

0000000000001580 <deregister_tm_clones>:
    1580:	48 8d 3d 91 6a 00 00 	lea    0x6a91(%rip),%rdi        # 8018 <__TMC_END__>
    1587:	48 8d 05 8a 6a 00 00 	lea    0x6a8a(%rip),%rax        # 8018 <__TMC_END__>
    158e:	48 39 f8             	cmp    %rdi,%rax
    1591:	74 15                	je     15a8 <deregister_tm_clones+0x28>
    1593:	48 8b 05 4e 6a 00 00 	mov    0x6a4e(%rip),%rax        # 7fe8 <_ITM_deregisterTMCloneTable@Base>
    159a:	48 85 c0             	test   %rax,%rax
    159d:	74 09                	je     15a8 <deregister_tm_clones+0x28>
    159f:	ff e0                	jmp    *%rax
    15a1:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    15a8:	c3                   	ret
    15a9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

00000000000015b0 <register_tm_clones>:
    15b0:	48 8d 3d 61 6a 00 00 	lea    0x6a61(%rip),%rdi        # 8018 <__TMC_END__>
    15b7:	48 8d 35 5a 6a 00 00 	lea    0x6a5a(%rip),%rsi        # 8018 <__TMC_END__>
    15be:	48 29 fe             	sub    %rdi,%rsi
    15c1:	48 89 f0             	mov    %rsi,%rax
    15c4:	48 c1 ee 3f          	shr    $0x3f,%rsi
    15c8:	48 c1 f8 03          	sar    $0x3,%rax
    15cc:	48 01 c6             	add    %rax,%rsi
    15cf:	48 d1 fe             	sar    $1,%rsi
    15d2:	74 14                	je     15e8 <register_tm_clones+0x38>
    15d4:	48 8b 05 fd 69 00 00 	mov    0x69fd(%rip),%rax        # 7fd8 <_ITM_registerTMCloneTable@Base>
    15db:	48 85 c0             	test   %rax,%rax
    15de:	74 08                	je     15e8 <register_tm_clones+0x38>
    15e0:	ff e0                	jmp    *%rax
    15e2:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
    15e8:	c3                   	ret
    15e9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

00000000000015f0 <__do_global_dtors_aux>:
    15f0:	f3 0f 1e fa          	endbr64
    15f4:	80 3d 1d 6a 00 00 00 	cmpb   $0x0,0x6a1d(%rip)        # 8018 <__TMC_END__>
    15fb:	75 2b                	jne    1628 <__do_global_dtors_aux+0x38>
    15fd:	55                   	push   %rbp
    15fe:	48 83 3d ea 69 00 00 	cmpq   $0x0,0x69ea(%rip)        # 7ff0 <__cxa_finalize@GLIBC_2.2.5>
    1605:	00 
    1606:	48 89 e5             	mov    %rsp,%rbp
    1609:	74 0c                	je     1617 <__do_global_dtors_aux+0x27>
    160b:	48 8b 3d f6 69 00 00 	mov    0x69f6(%rip),%rdi        # 8008 <__dso_handle>
    1612:	e8 49 fb ff ff       	call   1160 <__cxa_finalize@plt>
    1617:	e8 64 ff ff ff       	call   1580 <deregister_tm_clones>
    161c:	c6 05 f5 69 00 00 01 	movb   $0x1,0x69f5(%rip)        # 8018 <__TMC_END__>
    1623:	5d                   	pop    %rbp
    1624:	c3                   	ret
    1625:	0f 1f 00             	nopl   (%rax)
    1628:	c3                   	ret
    1629:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

0000000000001630 <frame_dummy>:
    1630:	f3 0f 1e fa          	endbr64
    1634:	e9 77 ff ff ff       	jmp    15b0 <register_tm_clones>
    1639:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

0000000000001640 <FLASHGEMM_NPACK>:
    1640:	41 57                	push   %r15
    1642:	41 56                	push   %r14
    1644:	41 55                	push   %r13
    1646:	41 54                	push   %r12
    1648:	55                   	push   %rbp
    1649:	53                   	push   %rbx
    164a:	48 83 ec 48          	sub    $0x48,%rsp
    164e:	48 89 7c 24 08       	mov    %rdi,0x8(%rsp)
    1653:	48 89 74 24 10       	mov    %rsi,0x10(%rsp)
    1658:	89 4c 24 18          	mov    %ecx,0x18(%rsp)
    165c:	44 89 44 24 1c       	mov    %r8d,0x1c(%rsp)
    1661:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    1668:	00 00 
    166a:	48 89 44 24 38       	mov    %rax,0x38(%rsp)
    166f:	31 c0                	xor    %eax,%eax
    1671:	83 fa 0c             	cmp    $0xc,%edx
    1674:	0f 84 86 06 00 00    	je     1d00 <NPACK_END+0x6c>
    167a:	89 d5                	mov    %edx,%ebp
    167c:	83 fa 07             	cmp    $0x7,%edx
    167f:	0f 8f 93 00 00 00    	jg     1718 <FLASHGEMM_NPACK+0xd8>
    1685:	83 fa 03             	cmp    $0x3,%edx
    1688:	0f 8f 19 04 00 00    	jg     1aa7 <NPACK_END_8+0x42>
#include <string.h>
    168e:	8b 5c 24 18          	mov    0x18(%rsp),%ebx
    1692:	4c 8b 74 24 08       	mov    0x8(%rsp),%r14
    1697:	4c 8b 7c 24 10       	mov    0x10(%rsp),%r15
#include <string.h>

static void NPACK_m1xk(float *A, float *Ac, int K, int LK)
{
    memcpy(Ac, A, K * 4);
    169c:	c1 e3 02             	shl    $0x2,%ebx
    169f:	4c 89 f6             	mov    %r14,%rsi
    16a2:	48 63 db             	movslq %ebx,%rbx
    16a5:	4c 89 ff             	mov    %r15,%rdi
    16a8:	48 89 da             	mov    %rbx,%rdx
    16ab:	e8 60 fb ff ff       	call   1210 <memcpy@plt>
    }
    if (M >= 1)
    {
        // printf("M = %d,pack m1\n",M);
        NPACK_m1xk(temp_A, temp_Ac, K, LK);
        temp_A = temp_A + 1 * LK;
    16b0:	4c 63 6c 24 1c       	movslq 0x1c(%rsp),%r13
        temp_Ac = temp_Ac + 1 * K;
    16b5:	4c 89 ff             	mov    %r15,%rdi
    16b8:	48 01 df             	add    %rbx,%rdi
        temp_A = temp_A + 1 * LK;
    16bb:	49 c1 e5 02          	shl    $0x2,%r13
    16bf:	4d 01 ee             	add    %r13,%r14
        M = M - 1;
    }
    if (M >= 1)
    16c2:	83 fd 01             	cmp    $0x1,%ebp
    16c5:	0f 84 0d 06 00 00    	je     1cd8 <NPACK_END+0x44>
    16cb:	4c 89 f6             	mov    %r14,%rsi
    16ce:	48 89 da             	mov    %rbx,%rdx
    16d1:	e8 3a fb ff ff       	call   1210 <memcpy@plt>
    {
        // printf("M = %d,pack m1\n",M);
        NPACK_m1xk(temp_A, temp_Ac, K, LK);
        temp_A = temp_A + 1 * LK;
    16d6:	4b 8d 34 2e          	lea    (%r14,%r13,1),%rsi
    16da:	48 89 c7             	mov    %rax,%rdi
        temp_Ac = temp_Ac + 1 * K;
    16dd:	48 01 df             	add    %rbx,%rdi
        M = M - 1;
    }
    if (M >= 1)
    16e0:	83 fd 02             	cmp    $0x2,%ebp
    16e3:	0f 84 ef 05 00 00    	je     1cd8 <NPACK_END+0x44>
    16e9:	48 8b 44 24 38       	mov    0x38(%rsp),%rax
    16ee:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    16f5:	00 00 
    16f7:	0f 85 cb 0a 00 00    	jne    21c8 <NPACK_END_12+0x17>
    {
        // printf("M = %d,pack m1\n",M);
        NPACK_m1xk(temp_A, temp_Ac, K, LK);
    }
}
    16fd:	48 83 c4 48          	add    $0x48,%rsp
    1701:	48 89 da             	mov    %rbx,%rdx
    1704:	5b                   	pop    %rbx
    1705:	5d                   	pop    %rbp
    1706:	41 5c                	pop    %r12
    1708:	41 5d                	pop    %r13
    170a:	41 5e                	pop    %r14
    170c:	41 5f                	pop    %r15
    170e:	e9 fd fa ff ff       	jmp    1210 <memcpy@plt>
    1713:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
        NPACK_m8xk(temp_A, temp_Ac, K, LK);
    1718:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    171d:	48 8b 54 24 10       	mov    0x10(%rsp),%rdx
    1722:	8b 5c 24 18          	mov    0x18(%rsp),%ebx
    1726:	8b 74 24 1c          	mov    0x1c(%rsp),%esi
    172a:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    172f:	48 89 54 24 30       	mov    %rdx,0x30(%rsp)
    1734:	89 5c 24 20          	mov    %ebx,0x20(%rsp)
    1738:	89 74 24 24          	mov    %esi,0x24(%rsp)
    asm volatile(
    173c:	44 8b 44 24 24       	mov    0x24(%rsp),%r8d
    1741:	44 8b 7c 24 24       	mov    0x24(%rsp),%r15d
    1746:	4c 8b 4c 24 30       	mov    0x30(%rsp),%r9
    174b:	44 8b 54 24 20       	mov    0x20(%rsp),%r10d
    1750:	4c 8b 5c 24 28       	mov    0x28(%rsp),%r11
    1755:	4c 8b 64 24 28       	mov    0x28(%rsp),%r12
    175a:	4c 8b 6c 24 28       	mov    0x28(%rsp),%r13
    175f:	4c 8b 74 24 28       	mov    0x28(%rsp),%r14
    1764:	48 8b 5c 24 28       	mov    0x28(%rsp),%rbx
    1769:	48 8b 4c 24 28       	mov    0x28(%rsp),%rcx
    176e:	48 8b 54 24 28       	mov    0x28(%rsp),%rdx
    1773:	48 8b 7c 24 28       	mov    0x28(%rsp),%rdi
    1778:	49 c1 ea 04          	shr    $0x4,%r10
    177c:	49 c1 e0 02          	shl    $0x2,%r8
    1780:	49 c1 e7 03          	shl    $0x3,%r15
    1784:	4d 01 c6             	add    %r8,%r14
    1787:	4c 01 c7             	add    %r8,%rdi
    178a:	4d 01 c4             	add    %r8,%r12
    178d:	4c 01 c1             	add    %r8,%rcx
    1790:	4d 01 fd             	add    %r15,%r13
    1793:	4c 01 fa             	add    %r15,%rdx
    1796:	49 c1 e0 02          	shl    $0x2,%r8
    179a:	4d 01 fe             	add    %r15,%r14
    179d:	4c 01 ff             	add    %r15,%rdi
    17a0:	4c 01 c3             	add    %r8,%rbx
    17a3:	4c 01 c1             	add    %r8,%rcx
    17a6:	4c 01 c2             	add    %r8,%rdx
    17a9:	4c 01 c7             	add    %r8,%rdi
    17ac:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    17b2:	62 d1 7c 48 10 1c 24 	vmovups (%r12),%zmm3
    17b9:	62 d1 7c 48 10 65 00 	vmovups 0x0(%r13),%zmm4
    17c0:	62 d1 7c 48 10 2e    	vmovups (%r14),%zmm5
    17c6:	62 f1 7c 48 10 33    	vmovups (%rbx),%zmm6
    17cc:	62 f1 7c 48 10 39    	vmovups (%rcx),%zmm7
    17d2:	62 71 7c 48 10 02    	vmovups (%rdx),%zmm8
    17d8:	62 71 7c 48 10 0f    	vmovups (%rdi),%zmm9
    17de:	eb 59                	jmp    1839 <NPACK_8>

00000000000017e0 <NPACK_Pre_8>:
    17e0:	49 83 c3 40          	add    $0x40,%r11
    17e4:	49 83 c4 40          	add    $0x40,%r12
    17e8:	49 83 c5 40          	add    $0x40,%r13
    17ec:	49 83 c6 40          	add    $0x40,%r14
    17f0:	48 83 c3 40          	add    $0x40,%rbx
    17f4:	48 83 c1 40          	add    $0x40,%rcx
    17f8:	48 83 c2 40          	add    $0x40,%rdx
    17fc:	48 83 c7 40          	add    $0x40,%rdi
    1800:	49 81 c1 00 02 00 00 	add    $0x200,%r9
    1807:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    180d:	62 d1 7c 48 10 1c 24 	vmovups (%r12),%zmm3
    1814:	62 d1 7c 48 10 65 00 	vmovups 0x0(%r13),%zmm4
    181b:	62 d1 7c 48 10 2e    	vmovups (%r14),%zmm5
    1821:	62 f1 7c 48 10 33    	vmovups (%rbx),%zmm6
    1827:	62 f1 7c 48 10 39    	vmovups (%rcx),%zmm7
    182d:	62 71 7c 48 10 02    	vmovups (%rdx),%zmm8
    1833:	62 71 7c 48 10 0f    	vmovups (%rdi),%zmm9

0000000000001839 <NPACK_8>:
    1839:	b8 aa 00 00 00       	mov    $0xaa,%eax
    183e:	41 b8 cc 00 00 00    	mov    $0xcc,%r8d
    1844:	41 bf 33 00 00 00    	mov    $0x33,%r15d
    184a:	c5 fb 92 c8          	kmovd  %eax,%k1
    184e:	c4 c1 7b 92 d0       	kmovd  %r8d,%k2
    1853:	c4 c1 7b 92 df       	kmovd  %r15d,%k3
    1858:	62 f1 6c 48 14 c3    	vunpcklps %zmm3,%zmm2,%zmm0
    185e:	62 f1 4c 48 14 cf    	vunpcklps %zmm7,%zmm6,%zmm1
    1864:	62 61 5c 48 14 d5    	vunpcklps %zmm5,%zmm4,%zmm26
    186a:	62 41 3c 48 14 d9    	vunpcklps %zmm9,%zmm8,%zmm27
    1870:	62 93 fd 49 00 c2 80 	vpermq $0x80,%zmm26,%zmm0{%k1}
    1877:	62 61 7c 48 10 e0    	vmovups %zmm0,%zmm28
    187d:	62 93 fd 49 00 cb 80 	vpermq $0x80,%zmm27,%zmm1{%k1}
    1884:	62 61 7c 48 10 e9    	vmovups %zmm1,%zmm29
    188a:	62 f3 fd 4a 00 c1 40 	vpermq $0x40,%zmm1,%zmm0{%k2}
    1891:	62 03 fd 4b 00 ec 0e 	vpermq $0xe,%zmm28,%zmm29{%k3}
    1898:	c4 c1 7c 11 01       	vmovups %ymm0,(%r9)
    189d:	62 93 fd 48 1b c6 01 	vextractf64x4 $0x1,%zmm0,%ymm30
    18a4:	62 41 7c 28 11 71 08 	vmovups %ymm30,0x100(%r9)
    18ab:	62 41 7c 28 11 69 04 	vmovups %ymm29,0x80(%r9)
    18b2:	62 03 fd 48 1b ef 01 	vextractf64x4 $0x1,%zmm29,%ymm31
    18b9:	62 41 7c 28 11 79 0c 	vmovups %ymm31,0x180(%r9)
    18c0:	b8 55 00 00 00       	mov    $0x55,%eax
    18c5:	41 b8 cc 00 00 00    	mov    $0xcc,%r8d
    18cb:	41 bf 33 00 00 00    	mov    $0x33,%r15d
    18d1:	c5 fb 92 c8          	kmovd  %eax,%k1
    18d5:	c4 c1 7b 92 d0       	kmovd  %r8d,%k2
    18da:	c4 c1 7b 92 df       	kmovd  %r15d,%k3
    18df:	62 f1 6c 48 14 c3    	vunpcklps %zmm3,%zmm2,%zmm0
    18e5:	62 f1 4c 48 14 cf    	vunpcklps %zmm7,%zmm6,%zmm1
    18eb:	62 61 5c 48 14 d5    	vunpcklps %zmm5,%zmm4,%zmm26
    18f1:	62 41 3c 48 14 d9    	vunpcklps %zmm9,%zmm8,%zmm27
    18f7:	62 63 fd 49 00 d0 31 	vpermq $0x31,%zmm0,%zmm26{%k1}
    18fe:	62 01 7c 48 10 e2    	vmovups %zmm26,%zmm28
    1904:	62 63 fd 49 00 d9 31 	vpermq $0x31,%zmm1,%zmm27{%k1}
    190b:	62 01 7c 48 10 eb    	vmovups %zmm27,%zmm29
    1911:	62 03 fd 4a 00 d3 40 	vpermq $0x40,%zmm27,%zmm26{%k2}
    1918:	62 03 fd 4b 00 ec 0e 	vpermq $0xe,%zmm28,%zmm29{%k3}
    191f:	62 41 7c 28 11 51 01 	vmovups %ymm26,0x20(%r9)
    1926:	62 03 fd 48 1b d6 01 	vextractf64x4 $0x1,%zmm26,%ymm30
    192d:	62 41 7c 28 11 71 09 	vmovups %ymm30,0x120(%r9)
    1934:	62 41 7c 28 11 69 05 	vmovups %ymm29,0xa0(%r9)
    193b:	62 03 fd 48 1b ef 01 	vextractf64x4 $0x1,%zmm29,%ymm31
    1942:	62 41 7c 28 11 79 0d 	vmovups %ymm31,0x1a0(%r9)
    1949:	b8 aa 00 00 00       	mov    $0xaa,%eax
    194e:	41 b8 cc 00 00 00    	mov    $0xcc,%r8d
    1954:	41 bf 33 00 00 00    	mov    $0x33,%r15d
    195a:	c5 fb 92 c8          	kmovd  %eax,%k1
    195e:	c4 c1 7b 92 d0       	kmovd  %r8d,%k2
    1963:	c4 c1 7b 92 df       	kmovd  %r15d,%k3
    1968:	62 f1 6c 48 15 c3    	vunpckhps %zmm3,%zmm2,%zmm0
    196e:	62 f1 4c 48 15 cf    	vunpckhps %zmm7,%zmm6,%zmm1
    1974:	62 61 5c 48 15 d5    	vunpckhps %zmm5,%zmm4,%zmm26
    197a:	62 41 3c 48 15 d9    	vunpckhps %zmm9,%zmm8,%zmm27
    1980:	62 93 fd 49 00 c2 80 	vpermq $0x80,%zmm26,%zmm0{%k1}
    1987:	62 61 7c 48 10 e0    	vmovups %zmm0,%zmm28
    198d:	62 93 fd 49 00 cb 80 	vpermq $0x80,%zmm27,%zmm1{%k1}
    1994:	62 61 7c 48 10 e9    	vmovups %zmm1,%zmm29
    199a:	62 f3 fd 4a 00 c1 40 	vpermq $0x40,%zmm1,%zmm0{%k2}
    19a1:	62 03 fd 4b 00 ec 0e 	vpermq $0xe,%zmm28,%zmm29{%k3}
    19a8:	c4 c1 7c 11 41 40    	vmovups %ymm0,0x40(%r9)
    19ae:	62 93 fd 48 1b c6 01 	vextractf64x4 $0x1,%zmm0,%ymm30
    19b5:	62 41 7c 28 11 71 0a 	vmovups %ymm30,0x140(%r9)
    19bc:	62 41 7c 28 11 69 06 	vmovups %ymm29,0xc0(%r9)
    19c3:	62 03 fd 48 1b ef 01 	vextractf64x4 $0x1,%zmm29,%ymm31
    19ca:	62 41 7c 28 11 79 0e 	vmovups %ymm31,0x1c0(%r9)
    19d1:	b8 55 00 00 00       	mov    $0x55,%eax
    19d6:	41 b8 cc 00 00 00    	mov    $0xcc,%r8d
    19dc:	41 bf 33 00 00 00    	mov    $0x33,%r15d
    19e2:	c5 fb 92 c8          	kmovd  %eax,%k1
    19e6:	c4 c1 7b 92 d0       	kmovd  %r8d,%k2
    19eb:	c4 c1 7b 92 df       	kmovd  %r15d,%k3
    19f0:	62 f1 6c 48 15 c3    	vunpckhps %zmm3,%zmm2,%zmm0
    19f6:	62 f1 4c 48 15 cf    	vunpckhps %zmm7,%zmm6,%zmm1
    19fc:	62 61 5c 48 15 d5    	vunpckhps %zmm5,%zmm4,%zmm26
    1a02:	62 41 3c 48 15 d9    	vunpckhps %zmm9,%zmm8,%zmm27
    1a08:	62 63 fd 49 00 d0 31 	vpermq $0x31,%zmm0,%zmm26{%k1}
    1a0f:	62 01 7c 48 10 e2    	vmovups %zmm26,%zmm28
    1a15:	62 63 fd 49 00 d9 31 	vpermq $0x31,%zmm1,%zmm27{%k1}
    1a1c:	62 01 7c 48 10 eb    	vmovups %zmm27,%zmm29
    1a22:	62 03 fd 4a 00 d3 40 	vpermq $0x40,%zmm27,%zmm26{%k2}
    1a29:	62 03 fd 4b 00 ec 0e 	vpermq $0xe,%zmm28,%zmm29{%k3}
    1a30:	62 41 7c 28 11 51 03 	vmovups %ymm26,0x60(%r9)
    1a37:	62 03 fd 48 1b d6 01 	vextractf64x4 $0x1,%zmm26,%ymm30
    1a3e:	62 41 7c 28 11 71 0b 	vmovups %ymm30,0x160(%r9)
    1a45:	49 83 ea 01          	sub    $0x1,%r10
    1a49:	62 41 7c 28 11 69 07 	vmovups %ymm29,0xe0(%r9)
    1a50:	62 03 fd 48 1b ef 01 	vextractf64x4 $0x1,%zmm29,%ymm31
    1a57:	62 41 7c 28 11 79 0f 	vmovups %ymm31,0x1e0(%r9)
    1a5e:	74 05                	je     1a65 <NPACK_END_8>
    1a60:	e9 7b fd ff ff       	jmp    17e0 <NPACK_Pre_8>

0000000000001a65 <NPACK_END_8>:
        temp_A = temp_A + 8 * LK;
    1a65:	8b 74 24 1c          	mov    0x1c(%rsp),%esi
    1a69:	48 8b 4c 24 08       	mov    0x8(%rsp),%rcx
        M = M - 8;
    1a6e:	83 ed 08             	sub    $0x8,%ebp
        temp_Ac = temp_Ac + 8 * K;
    1a71:	8b 5c 24 18          	mov    0x18(%rsp),%ebx
    1a75:	48 8b 54 24 10       	mov    0x10(%rsp),%rdx
        temp_A = temp_A + 8 * LK;
    1a7a:	8d 04 f5 00 00 00 00 	lea    0x0(,%rsi,8),%eax
    1a81:	48 98                	cltq
    1a83:	48 8d 04 81          	lea    (%rcx,%rax,4),%rax
    1a87:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
        temp_Ac = temp_Ac + 8 * K;
    1a8c:	8d 04 dd 00 00 00 00 	lea    0x0(,%rbx,8),%eax
    1a93:	48 98                	cltq
    1a95:	48 8d 04 82          	lea    (%rdx,%rax,4),%rax
    1a99:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    if (M >= 4)
    1a9e:	83 fd 03             	cmp    $0x3,%ebp
    1aa1:	0f 8e 26 02 00 00    	jle    1ccd <NPACK_END+0x39>
        NPACK_m4xk(temp_A, temp_Ac, K, LK);
    1aa7:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    1aac:	48 8b 54 24 10       	mov    0x10(%rsp),%rdx
    1ab1:	8b 5c 24 18          	mov    0x18(%rsp),%ebx
    1ab5:	8b 74 24 1c          	mov    0x1c(%rsp),%esi
    1ab9:	48 89 44 24 28       	mov    %rax,0x28(%rsp)
    1abe:	48 89 54 24 30       	mov    %rdx,0x30(%rsp)
    1ac3:	89 5c 24 20          	mov    %ebx,0x20(%rsp)
    1ac7:	89 74 24 24          	mov    %esi,0x24(%rsp)
    asm volatile(
    1acb:	44 8b 44 24 24       	mov    0x24(%rsp),%r8d
    1ad0:	44 8b 7c 24 24       	mov    0x24(%rsp),%r15d
    1ad5:	4c 8b 4c 24 30       	mov    0x30(%rsp),%r9
    1ada:	44 8b 54 24 20       	mov    0x20(%rsp),%r10d
    1adf:	4c 8b 5c 24 28       	mov    0x28(%rsp),%r11
    1ae4:	4c 8b 64 24 28       	mov    0x28(%rsp),%r12
    1ae9:	4c 8b 6c 24 28       	mov    0x28(%rsp),%r13
    1aee:	4c 8b 74 24 28       	mov    0x28(%rsp),%r14
    1af3:	49 c1 ea 04          	shr    $0x4,%r10
    1af7:	49 c1 e0 02          	shl    $0x2,%r8
    1afb:	49 c1 e7 03          	shl    $0x3,%r15
    1aff:	4d 01 c6             	add    %r8,%r14
    1b02:	4d 01 c4             	add    %r8,%r12
    1b05:	4d 01 fd             	add    %r15,%r13
    1b08:	4d 01 fe             	add    %r15,%r14
    1b0b:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    1b11:	62 d1 7c 48 10 1c 24 	vmovups (%r12),%zmm3
    1b18:	62 d1 7c 48 10 65 00 	vmovups 0x0(%r13),%zmm4
    1b1f:	62 d1 7c 48 10 2e    	vmovups (%r14),%zmm5
    1b25:	eb 31                	jmp    1b58 <NPACK>

0000000000001b27 <NPACK_Pre>:
    1b27:	49 83 c3 40          	add    $0x40,%r11
    1b2b:	49 83 c4 40          	add    $0x40,%r12
    1b2f:	49 83 c5 40          	add    $0x40,%r13
    1b33:	49 83 c6 40          	add    $0x40,%r14
    1b37:	49 81 c1 00 01 00 00 	add    $0x100,%r9
    1b3e:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    1b44:	62 d1 7c 48 10 1c 24 	vmovups (%r12),%zmm3
    1b4b:	62 d1 7c 48 10 65 00 	vmovups 0x0(%r13),%zmm4
    1b52:	62 d1 7c 48 10 2e    	vmovups (%r14),%zmm5

0000000000001b58 <NPACK>:
    1b58:	b8 aa 00 00 00       	mov    $0xaa,%eax
    1b5d:	c5 fb 92 c8          	kmovd  %eax,%k1
    1b61:	62 f1 6c 48 14 c3    	vunpcklps %zmm3,%zmm2,%zmm0
    1b67:	62 61 5c 48 14 d5    	vunpcklps %zmm5,%zmm4,%zmm26
    1b6d:	62 93 fd 49 00 c2 80 	vpermq $0x80,%zmm26,%zmm0{%k1}
    1b74:	c4 c1 78 11 01       	vmovups %xmm0,(%r9)
    1b79:	62 93 7d 48 19 c4 01 	vextractf32x4 $0x1,%zmm0,%xmm28
    1b80:	62 93 7d 48 19 c5 02 	vextractf32x4 $0x2,%zmm0,%xmm29
    1b87:	62 93 7d 48 19 c6 03 	vextractf32x4 $0x3,%zmm0,%xmm30
    1b8e:	62 41 7c 08 11 61 04 	vmovups %xmm28,0x40(%r9)
    1b95:	62 41 7c 08 11 69 08 	vmovups %xmm29,0x80(%r9)
    1b9c:	62 41 7c 08 11 71 0c 	vmovups %xmm30,0xc0(%r9)
    1ba3:	b8 55 00 00 00       	mov    $0x55,%eax
    1ba8:	c5 fb 92 c8          	kmovd  %eax,%k1
    1bac:	62 f1 6c 48 14 c3    	vunpcklps %zmm3,%zmm2,%zmm0
    1bb2:	62 61 5c 48 14 d5    	vunpcklps %zmm5,%zmm4,%zmm26
    1bb8:	62 63 fd 49 00 d0 31 	vpermq $0x31,%zmm0,%zmm26{%k1}
    1bbf:	62 41 7c 08 11 51 01 	vmovups %xmm26,0x10(%r9)
    1bc6:	62 03 7d 48 19 d4 01 	vextractf32x4 $0x1,%zmm26,%xmm28
    1bcd:	62 03 7d 48 19 d5 02 	vextractf32x4 $0x2,%zmm26,%xmm29
    1bd4:	62 03 7d 48 19 d6 03 	vextractf32x4 $0x3,%zmm26,%xmm30
    1bdb:	62 41 7c 08 11 61 05 	vmovups %xmm28,0x50(%r9)
    1be2:	62 41 7c 08 11 69 09 	vmovups %xmm29,0x90(%r9)
    1be9:	62 41 7c 08 11 71 0d 	vmovups %xmm30,0xd0(%r9)
    1bf0:	b8 aa 00 00 00       	mov    $0xaa,%eax
    1bf5:	c5 fb 92 c8          	kmovd  %eax,%k1
    1bf9:	62 f1 6c 48 15 c3    	vunpckhps %zmm3,%zmm2,%zmm0
    1bff:	62 61 5c 48 15 d5    	vunpckhps %zmm5,%zmm4,%zmm26
    1c05:	62 93 fd 49 00 c2 80 	vpermq $0x80,%zmm26,%zmm0{%k1}
    1c0c:	c4 c1 78 11 41 20    	vmovups %xmm0,0x20(%r9)
    1c12:	62 93 7d 48 19 c4 01 	vextractf32x4 $0x1,%zmm0,%xmm28
    1c19:	62 93 7d 48 19 c5 02 	vextractf32x4 $0x2,%zmm0,%xmm29
    1c20:	62 93 7d 48 19 c6 03 	vextractf32x4 $0x3,%zmm0,%xmm30
    1c27:	62 41 7c 08 11 61 06 	vmovups %xmm28,0x60(%r9)
    1c2e:	62 41 7c 08 11 69 0a 	vmovups %xmm29,0xa0(%r9)
    1c35:	62 41 7c 08 11 71 0e 	vmovups %xmm30,0xe0(%r9)
    1c3c:	b8 55 00 00 00       	mov    $0x55,%eax
    1c41:	c5 fb 92 c8          	kmovd  %eax,%k1
    1c45:	62 f1 6c 48 15 c3    	vunpckhps %zmm3,%zmm2,%zmm0
    1c4b:	62 61 5c 48 15 d5    	vunpckhps %zmm5,%zmm4,%zmm26
    1c51:	62 63 fd 49 00 d0 31 	vpermq $0x31,%zmm0,%zmm26{%k1}
    1c58:	62 41 7c 08 11 51 03 	vmovups %xmm26,0x30(%r9)
    1c5f:	62 03 7d 48 19 d4 01 	vextractf32x4 $0x1,%zmm26,%xmm28
    1c66:	62 03 7d 48 19 d5 02 	vextractf32x4 $0x2,%zmm26,%xmm29
    1c6d:	62 03 7d 48 19 d6 03 	vextractf32x4 $0x3,%zmm26,%xmm30
    1c74:	49 83 ea 01          	sub    $0x1,%r10
    1c78:	62 41 7c 08 11 61 07 	vmovups %xmm28,0x70(%r9)
    1c7f:	62 41 7c 08 11 69 0b 	vmovups %xmm29,0xb0(%r9)
    1c86:	62 41 7c 08 11 71 0f 	vmovups %xmm30,0xf0(%r9)
    1c8d:	74 05                	je     1c94 <NPACK_END>
    1c8f:	e9 93 fe ff ff       	jmp    1b27 <NPACK_Pre>

0000000000001c94 <NPACK_END>:
        temp_A = temp_A + 4 * LK;
    1c94:	8b 74 24 1c          	mov    0x1c(%rsp),%esi
    1c98:	48 8b 4c 24 08       	mov    0x8(%rsp),%rcx
        M = M - 4;
    1c9d:	83 ed 04             	sub    $0x4,%ebp
        temp_Ac = temp_Ac + 4 * K;
    1ca0:	8b 5c 24 18          	mov    0x18(%rsp),%ebx
    1ca4:	48 8b 54 24 10       	mov    0x10(%rsp),%rdx
        temp_A = temp_A + 4 * LK;
    1ca9:	8d 04 b5 00 00 00 00 	lea    0x0(,%rsi,4),%eax
    1cb0:	48 98                	cltq
    1cb2:	48 8d 04 81          	lea    (%rcx,%rax,4),%rax
    1cb6:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
        temp_Ac = temp_Ac + 4 * K;
    1cbb:	8d 04 9d 00 00 00 00 	lea    0x0(,%rbx,4),%eax
    1cc2:	48 98                	cltq
    1cc4:	48 8d 04 82          	lea    (%rdx,%rax,4),%rax
    1cc8:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    if (M >= 1)
    1ccd:	85 ed                	test   %ebp,%ebp
    1ccf:	0f 85 eb 04 00 00    	jne    21c0 <NPACK_END_12+0xf>
    1cd5:	c5 f8 77             	vzeroupper
}
    1cd8:	48 8b 44 24 38       	mov    0x38(%rsp),%rax
    1cdd:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    1ce4:	00 00 
    1ce6:	0f 85 dc 04 00 00    	jne    21c8 <NPACK_END_12+0x17>
    1cec:	48 83 c4 48          	add    $0x48,%rsp
    1cf0:	5b                   	pop    %rbx
    1cf1:	5d                   	pop    %rbp
    1cf2:	41 5c                	pop    %r12
    1cf4:	41 5d                	pop    %r13
    1cf6:	41 5e                	pop    %r14
    1cf8:	41 5f                	pop    %r15
    1cfa:	c3                   	ret
    1cfb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
        NPACK_m12xk(temp_A, temp_Ac, K, LK);
    1d00:	48 89 7c 24 28       	mov    %rdi,0x28(%rsp)
    1d05:	48 89 74 24 30       	mov    %rsi,0x30(%rsp)
    1d0a:	89 4c 24 20          	mov    %ecx,0x20(%rsp)
    1d0e:	44 89 44 24 24       	mov    %r8d,0x24(%rsp)
    asm volatile(
    1d13:	44 8b 44 24 24       	mov    0x24(%rsp),%r8d
    1d18:	44 8b 7c 24 24       	mov    0x24(%rsp),%r15d
    1d1d:	4c 8b 4c 24 30       	mov    0x30(%rsp),%r9
    1d22:	44 8b 54 24 20       	mov    0x20(%rsp),%r10d
    1d27:	4c 8b 5c 24 28       	mov    0x28(%rsp),%r11
    1d2c:	4c 8b 64 24 28       	mov    0x28(%rsp),%r12
    1d31:	4c 8b 6c 24 28       	mov    0x28(%rsp),%r13
    1d36:	4c 8b 74 24 28       	mov    0x28(%rsp),%r14
    1d3b:	48 8b 5c 24 28       	mov    0x28(%rsp),%rbx
    1d40:	48 8b 4c 24 28       	mov    0x28(%rsp),%rcx
    1d45:	48 8b 54 24 28       	mov    0x28(%rsp),%rdx
    1d4a:	48 8b 7c 24 28       	mov    0x28(%rsp),%rdi
    1d4f:	49 c1 ea 04          	shr    $0x4,%r10
    1d53:	49 c1 e0 02          	shl    $0x2,%r8
    1d57:	49 c1 e7 03          	shl    $0x3,%r15
    1d5b:	4d 01 c6             	add    %r8,%r14
    1d5e:	4c 01 c7             	add    %r8,%rdi
    1d61:	4d 01 c4             	add    %r8,%r12
    1d64:	4c 01 c1             	add    %r8,%rcx
    1d67:	4d 01 fd             	add    %r15,%r13
    1d6a:	4c 01 fa             	add    %r15,%rdx
    1d6d:	49 c1 e0 02          	shl    $0x2,%r8
    1d71:	4d 01 fe             	add    %r15,%r14
    1d74:	4c 01 ff             	add    %r15,%rdi
    1d77:	4c 01 c3             	add    %r8,%rbx
    1d7a:	4c 01 c1             	add    %r8,%rcx
    1d7d:	4c 01 c2             	add    %r8,%rdx
    1d80:	4c 01 c7             	add    %r8,%rdi
    1d83:	49 d1 e7             	shl    $1,%r15
    1d86:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    1d8c:	62 d1 7c 48 10 1c 24 	vmovups (%r12),%zmm3
    1d93:	62 d1 7c 48 10 65 00 	vmovups 0x0(%r13),%zmm4
    1d9a:	62 d1 7c 48 10 2e    	vmovups (%r14),%zmm5
    1da0:	49 83 ef 40          	sub    $0x40,%r15
    1da4:	62 f1 7c 48 10 33    	vmovups (%rbx),%zmm6
    1daa:	62 f1 7c 48 10 39    	vmovups (%rcx),%zmm7
    1db0:	62 71 7c 48 10 02    	vmovups (%rdx),%zmm8
    1db6:	62 71 7c 48 10 0f    	vmovups (%rdi),%zmm9
    1dbc:	4c 89 fe             	mov    %r15,%rsi
    1dbf:	eb 55                	jmp    1e16 <NPACK_12>

0000000000001dc1 <NPACK_Pre_12>:
    1dc1:	49 83 c3 40          	add    $0x40,%r11
    1dc5:	49 83 c4 40          	add    $0x40,%r12
    1dc9:	49 83 c5 40          	add    $0x40,%r13
    1dcd:	49 83 c6 40          	add    $0x40,%r14
    1dd1:	48 29 f3             	sub    %rsi,%rbx
    1dd4:	48 29 f1             	sub    %rsi,%rcx
    1dd7:	48 29 f2             	sub    %rsi,%rdx
    1dda:	48 29 f7             	sub    %rsi,%rdi
    1ddd:	49 81 c1 00 03 00 00 	add    $0x300,%r9
    1de4:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    1dea:	62 d1 7c 48 10 1c 24 	vmovups (%r12),%zmm3
    1df1:	62 d1 7c 48 10 65 00 	vmovups 0x0(%r13),%zmm4
    1df8:	62 d1 7c 48 10 2e    	vmovups (%r14),%zmm5
    1dfe:	62 f1 7c 48 10 33    	vmovups (%rbx),%zmm6
    1e04:	62 f1 7c 48 10 39    	vmovups (%rcx),%zmm7
    1e0a:	62 71 7c 48 10 02    	vmovups (%rdx),%zmm8
    1e10:	62 71 7c 48 10 0f    	vmovups (%rdi),%zmm9

0000000000001e16 <NPACK_12>:
    1e16:	b8 aa 00 00 00       	mov    $0xaa,%eax
    1e1b:	41 bf cc 00 00 00    	mov    $0xcc,%r15d
    1e21:	c5 fb 92 c8          	kmovd  %eax,%k1
    1e25:	c4 c1 7b 92 d7       	kmovd  %r15d,%k2
    1e2a:	62 f1 6c 48 14 c3    	vunpcklps %zmm3,%zmm2,%zmm0
    1e30:	62 f1 4c 48 14 cf    	vunpcklps %zmm7,%zmm6,%zmm1
    1e36:	b8 33 00 00 00       	mov    $0x33,%eax
    1e3b:	62 61 5c 48 14 d5    	vunpcklps %zmm5,%zmm4,%zmm26
    1e41:	62 41 3c 48 14 d9    	vunpcklps %zmm9,%zmm8,%zmm27
    1e47:	c5 fb 92 d8          	kmovd  %eax,%k3
    1e4b:	62 93 fd 49 00 c2 80 	vpermq $0x80,%zmm26,%zmm0{%k1}
    1e52:	62 61 7c 48 10 e0    	vmovups %zmm0,%zmm28
    1e58:	62 93 fd 49 00 cb 80 	vpermq $0x80,%zmm27,%zmm1{%k1}
    1e5f:	62 61 7c 48 10 e9    	vmovups %zmm1,%zmm29
    1e65:	41 bf 33 00 00 00    	mov    $0x33,%r15d
    1e6b:	62 f3 fd 4a 00 c1 40 	vpermq $0x40,%zmm1,%zmm0{%k2}
    1e72:	62 03 fd 4b 00 ec 0e 	vpermq $0xe,%zmm28,%zmm29{%k3}
    1e79:	c4 c1 7c 11 01       	vmovups %ymm0,(%r9)
    1e7e:	62 93 fd 48 1b c6 01 	vextractf64x4 $0x1,%zmm0,%ymm30
    1e85:	62 41 7c 28 11 71 0c 	vmovups %ymm30,0x180(%r9)
    1e8c:	62 41 7c 28 11 69 06 	vmovups %ymm29,0xc0(%r9)
    1e93:	62 03 fd 48 1b ef 01 	vextractf64x4 $0x1,%zmm29,%ymm31
    1e9a:	62 41 7c 28 11 79 12 	vmovups %ymm31,0x240(%r9)
    1ea1:	b8 55 00 00 00       	mov    $0x55,%eax
    1ea6:	41 bf cc 00 00 00    	mov    $0xcc,%r15d
    1eac:	c5 fb 92 c8          	kmovd  %eax,%k1
    1eb0:	c4 c1 7b 92 d7       	kmovd  %r15d,%k2
    1eb5:	62 f1 6c 48 14 c3    	vunpcklps %zmm3,%zmm2,%zmm0
    1ebb:	62 f1 4c 48 14 cf    	vunpcklps %zmm7,%zmm6,%zmm1
    1ec1:	b8 33 00 00 00       	mov    $0x33,%eax
    1ec6:	62 61 5c 48 14 d5    	vunpcklps %zmm5,%zmm4,%zmm26
    1ecc:	62 41 3c 48 14 d9    	vunpcklps %zmm9,%zmm8,%zmm27
    1ed2:	c5 fb 92 d8          	kmovd  %eax,%k3
    1ed6:	62 63 fd 49 00 d0 31 	vpermq $0x31,%zmm0,%zmm26{%k1}
    1edd:	62 01 7c 48 10 e2    	vmovups %zmm26,%zmm28
    1ee3:	62 63 fd 49 00 d9 31 	vpermq $0x31,%zmm1,%zmm27{%k1}
    1eea:	62 01 7c 48 10 eb    	vmovups %zmm27,%zmm29
    1ef0:	62 03 fd 4a 00 d3 40 	vpermq $0x40,%zmm27,%zmm26{%k2}
    1ef7:	62 03 fd 4b 00 ec 0e 	vpermq $0xe,%zmm28,%zmm29{%k3}
    1efe:	62 41 7c 28 11 91 30 	vmovups %ymm26,0x30(%r9)
    1f05:	00 00 00 
    1f08:	62 03 fd 48 1b d6 01 	vextractf64x4 $0x1,%zmm26,%ymm30
    1f0f:	62 41 7c 28 11 b1 b0 	vmovups %ymm30,0x1b0(%r9)
    1f16:	01 00 00 
    1f19:	62 41 7c 28 11 a9 f0 	vmovups %ymm29,0xf0(%r9)
    1f20:	00 00 00 
    1f23:	62 03 fd 48 1b ef 01 	vextractf64x4 $0x1,%zmm29,%ymm31
    1f2a:	62 41 7c 28 11 b9 70 	vmovups %ymm31,0x270(%r9)
    1f31:	02 00 00 
    1f34:	b8 aa 00 00 00       	mov    $0xaa,%eax
    1f39:	41 bf cc 00 00 00    	mov    $0xcc,%r15d
    1f3f:	c5 fb 92 c8          	kmovd  %eax,%k1
    1f43:	c4 c1 7b 92 d7       	kmovd  %r15d,%k2
    1f48:	62 f1 6c 48 15 c3    	vunpckhps %zmm3,%zmm2,%zmm0
    1f4e:	62 f1 4c 48 15 cf    	vunpckhps %zmm7,%zmm6,%zmm1
    1f54:	b8 33 00 00 00       	mov    $0x33,%eax
    1f59:	62 61 5c 48 15 d5    	vunpckhps %zmm5,%zmm4,%zmm26
    1f5f:	62 41 3c 48 15 d9    	vunpckhps %zmm9,%zmm8,%zmm27
    1f65:	c5 fb 92 d8          	kmovd  %eax,%k3
    1f69:	62 93 fd 49 00 c2 80 	vpermq $0x80,%zmm26,%zmm0{%k1}
    1f70:	62 61 7c 48 10 e0    	vmovups %zmm0,%zmm28
    1f76:	62 93 fd 49 00 cb 80 	vpermq $0x80,%zmm27,%zmm1{%k1}
    1f7d:	62 61 7c 48 10 e9    	vmovups %zmm1,%zmm29
    1f83:	62 f3 fd 4a 00 c1 40 	vpermq $0x40,%zmm1,%zmm0{%k2}
    1f8a:	62 03 fd 4b 00 ec 0e 	vpermq $0xe,%zmm28,%zmm29{%k3}
    1f91:	c4 c1 7c 11 41 60    	vmovups %ymm0,0x60(%r9)
    1f97:	62 93 fd 48 1b c6 01 	vextractf64x4 $0x1,%zmm0,%ymm30
    1f9e:	62 41 7c 28 11 71 0f 	vmovups %ymm30,0x1e0(%r9)
    1fa5:	62 41 7c 28 11 69 09 	vmovups %ymm29,0x120(%r9)
    1fac:	62 03 fd 48 1b ef 01 	vextractf64x4 $0x1,%zmm29,%ymm31
    1fb3:	62 41 7c 28 11 79 15 	vmovups %ymm31,0x2a0(%r9)
    1fba:	b8 55 00 00 00       	mov    $0x55,%eax
    1fbf:	41 bf cc 00 00 00    	mov    $0xcc,%r15d
    1fc5:	c5 fb 92 c8          	kmovd  %eax,%k1
    1fc9:	c4 c1 7b 92 d7       	kmovd  %r15d,%k2
    1fce:	62 f1 6c 48 15 c3    	vunpckhps %zmm3,%zmm2,%zmm0
    1fd4:	62 f1 4c 48 15 cf    	vunpckhps %zmm7,%zmm6,%zmm1
    1fda:	b8 33 00 00 00       	mov    $0x33,%eax
    1fdf:	62 61 5c 48 15 d5    	vunpckhps %zmm5,%zmm4,%zmm26
    1fe5:	62 41 3c 48 15 d9    	vunpckhps %zmm9,%zmm8,%zmm27
    1feb:	c5 fb 92 d8          	kmovd  %eax,%k3
    1fef:	62 63 fd 49 00 d0 31 	vpermq $0x31,%zmm0,%zmm26{%k1}
    1ff6:	62 01 7c 48 10 e2    	vmovups %zmm26,%zmm28
    1ffc:	62 63 fd 49 00 d9 31 	vpermq $0x31,%zmm1,%zmm27{%k1}
    2003:	62 01 7c 48 10 eb    	vmovups %zmm27,%zmm29
    2009:	62 03 fd 4a 00 d3 40 	vpermq $0x40,%zmm27,%zmm26{%k2}
    2010:	62 03 fd 4b 00 ec 0e 	vpermq $0xe,%zmm28,%zmm29{%k3}
    2017:	62 41 7c 28 11 91 90 	vmovups %ymm26,0x90(%r9)
    201e:	00 00 00 
    2021:	62 03 fd 48 1b d6 01 	vextractf64x4 $0x1,%zmm26,%ymm30
    2028:	62 41 7c 28 11 b1 10 	vmovups %ymm30,0x210(%r9)
    202f:	02 00 00 
    2032:	62 41 7c 28 11 a9 50 	vmovups %ymm29,0x150(%r9)
    2039:	01 00 00 
    203c:	62 03 fd 48 1b ef 01 	vextractf64x4 $0x1,%zmm29,%ymm31
    2043:	62 41 7c 28 11 b9 d0 	vmovups %ymm31,0x2d0(%r9)
    204a:	02 00 00 
    204d:	4c 01 c3             	add    %r8,%rbx
    2050:	4c 01 c1             	add    %r8,%rcx
    2053:	4c 01 c2             	add    %r8,%rdx
    2056:	4c 01 c7             	add    %r8,%rdi
    2059:	62 f1 7c 48 10 13    	vmovups (%rbx),%zmm2
    205f:	62 f1 7c 48 10 19    	vmovups (%rcx),%zmm3
    2065:	62 f1 7c 48 10 22    	vmovups (%rdx),%zmm4
    206b:	62 f1 7c 48 10 2f    	vmovups (%rdi),%zmm5
    2071:	b8 aa 00 00 00       	mov    $0xaa,%eax
    2076:	c5 fb 92 c8          	kmovd  %eax,%k1
    207a:	62 f1 6c 48 14 c3    	vunpcklps %zmm3,%zmm2,%zmm0
    2080:	62 61 5c 48 14 d5    	vunpcklps %zmm5,%zmm4,%zmm26
    2086:	62 93 fd 49 00 c2 80 	vpermq $0x80,%zmm26,%zmm0{%k1}
    208d:	c4 c1 78 11 41 20    	vmovups %xmm0,0x20(%r9)
    2093:	62 93 7d 48 19 c4 01 	vextractf32x4 $0x1,%zmm0,%xmm28
    209a:	62 93 7d 48 19 c5 02 	vextractf32x4 $0x2,%zmm0,%xmm29
    20a1:	62 93 7d 48 19 c6 03 	vextractf32x4 $0x3,%zmm0,%xmm30
    20a8:	62 41 7c 08 11 61 0e 	vmovups %xmm28,0xe0(%r9)
    20af:	62 41 7c 08 11 69 1a 	vmovups %xmm29,0x1a0(%r9)
    20b6:	62 41 7c 08 11 71 26 	vmovups %xmm30,0x260(%r9)
    20bd:	b8 55 00 00 00       	mov    $0x55,%eax
    20c2:	c5 fb 92 c8          	kmovd  %eax,%k1
    20c6:	62 f1 6c 48 14 c3    	vunpcklps %zmm3,%zmm2,%zmm0
    20cc:	62 61 5c 48 14 d5    	vunpcklps %zmm5,%zmm4,%zmm26
    20d2:	62 63 fd 49 00 d0 31 	vpermq $0x31,%zmm0,%zmm26{%k1}
    20d9:	62 41 7c 08 11 51 05 	vmovups %xmm26,0x50(%r9)
    20e0:	62 03 7d 48 19 d4 01 	vextractf32x4 $0x1,%zmm26,%xmm28
    20e7:	62 03 7d 48 19 d5 02 	vextractf32x4 $0x2,%zmm26,%xmm29
    20ee:	62 03 7d 48 19 d6 03 	vextractf32x4 $0x3,%zmm26,%xmm30
    20f5:	62 41 7c 08 11 61 11 	vmovups %xmm28,0x110(%r9)
    20fc:	62 41 7c 08 11 69 1d 	vmovups %xmm29,0x1d0(%r9)
    2103:	62 41 7c 08 11 71 29 	vmovups %xmm30,0x290(%r9)
    210a:	b8 aa 00 00 00       	mov    $0xaa,%eax
    210f:	c5 fb 92 c8          	kmovd  %eax,%k1
    2113:	62 f1 6c 48 15 c3    	vunpckhps %zmm3,%zmm2,%zmm0
    2119:	62 61 5c 48 15 d5    	vunpckhps %zmm5,%zmm4,%zmm26
    211f:	62 93 fd 49 00 c2 80 	vpermq $0x80,%zmm26,%zmm0{%k1}
    2126:	c4 c1 78 11 81 80 00 	vmovups %xmm0,0x80(%r9)
    212d:	00 00 
    212f:	62 93 7d 48 19 c4 01 	vextractf32x4 $0x1,%zmm0,%xmm28
    2136:	62 93 7d 48 19 c5 02 	vextractf32x4 $0x2,%zmm0,%xmm29
    213d:	62 93 7d 48 19 c6 03 	vextractf32x4 $0x3,%zmm0,%xmm30
    2144:	62 41 7c 08 11 61 14 	vmovups %xmm28,0x140(%r9)
    214b:	62 41 7c 08 11 69 20 	vmovups %xmm29,0x200(%r9)
    2152:	62 41 7c 08 11 71 2c 	vmovups %xmm30,0x2c0(%r9)
    2159:	b8 55 00 00 00       	mov    $0x55,%eax
    215e:	c5 fb 92 c8          	kmovd  %eax,%k1
    2162:	62 f1 6c 48 15 c3    	vunpckhps %zmm3,%zmm2,%zmm0
    2168:	62 61 5c 48 15 d5    	vunpckhps %zmm5,%zmm4,%zmm26
    216e:	62 63 fd 49 00 d0 31 	vpermq $0x31,%zmm0,%zmm26{%k1}
    2175:	62 41 7c 08 11 51 0b 	vmovups %xmm26,0xb0(%r9)
    217c:	62 03 7d 48 19 d4 01 	vextractf32x4 $0x1,%zmm26,%xmm28
    2183:	62 03 7d 48 19 d5 02 	vextractf32x4 $0x2,%zmm26,%xmm29
    218a:	62 03 7d 48 19 d6 03 	vextractf32x4 $0x3,%zmm26,%xmm30
    2191:	49 83 ea 01          	sub    $0x1,%r10
    2195:	62 41 7c 08 11 61 17 	vmovups %xmm28,0x170(%r9)
    219c:	62 41 7c 08 11 69 23 	vmovups %xmm29,0x230(%r9)
    21a3:	62 41 7c 08 11 71 2f 	vmovups %xmm30,0x2f0(%r9)
    21aa:	74 05                	je     21b1 <NPACK_END_12>
    21ac:	e9 10 fc ff ff       	jmp    1dc1 <NPACK_Pre_12>

00000000000021b1 <NPACK_END_12>:
        return;
    21b1:	c5 f8 77             	vzeroupper
    21b4:	e9 1f fb ff ff       	jmp    1cd8 <NPACK_END+0x44>
    21b9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    21c0:	c5 f8 77             	vzeroupper
    21c3:	e9 c6 f4 ff ff       	jmp    168e <FLASHGEMM_NPACK+0x4e>
}
    21c8:	e8 c3 ef ff ff       	call   1190 <__stack_chk_fail@plt>
    21cd:	0f 1f 00             	nopl   (%rax)

00000000000021d0 <GEMM_BF16._omp_fn.0>:
	if (Edge_K > 0)
	{
		Num_blocks = Num_blocks0 + Num_M_block;
	}

#pragma omp parallel num_threads(NUM)
    21d0:	f3 0f 1e fa          	endbr64
    21d4:	41 57                	push   %r15
    21d6:	41 56                	push   %r14
    21d8:	41 55                	push   %r13
    21da:	41 54                	push   %r12
    21dc:	55                   	push   %rbp
    21dd:	53                   	push   %rbx
    21de:	48 89 fb             	mov    %rdi,%rbx
    21e1:	48 81 ec d8 00 00 00 	sub    $0xd8,%rsp
    21e8:	8b 57 50             	mov    0x50(%rdi),%edx
    21eb:	44 8b 6f 54          	mov    0x54(%rdi),%r13d
    21ef:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    21f6:	00 00 
    21f8:	48 89 84 24 c8 00 00 	mov    %rax,0xc8(%rsp)
    21ff:	00 
    2200:	8b 47 58             	mov    0x58(%rdi),%eax
    2203:	44 8b 77 4c          	mov    0x4c(%rdi),%r14d
    2207:	89 54 24 08          	mov    %edx,0x8(%rsp)
    220b:	89 44 24 30          	mov    %eax,0x30(%rsp)
    220f:	48 8b 47 38          	mov    0x38(%rdi),%rax
    2213:	48 89 44 24 60       	mov    %rax,0x60(%rsp)
    2218:	48 8b 47 30          	mov    0x30(%rdi),%rax
    221c:	48 89 44 24 18       	mov    %rax,0x18(%rsp)
    2221:	48 8b 47 28          	mov    0x28(%rdi),%rax
    2225:	48 89 44 24 10       	mov    %rax,0x10(%rsp)
    222a:	8b 47 48             	mov    0x48(%rdi),%eax
    222d:	89 44 24 28          	mov    %eax,0x28(%rsp)
    2231:	48 8b 47 20          	mov    0x20(%rdi),%rax
    2235:	48 89 44 24 38       	mov    %rax,0x38(%rsp)
    223a:	48 8b 47 18          	mov    0x18(%rdi),%rax
    223e:	48 89 44 24 40       	mov    %rax,0x40(%rsp)
    2243:	48 8b 47 10          	mov    0x10(%rdi),%rax
    2247:	48 89 44 24 20       	mov    %rax,0x20(%rsp)
    224c:	48 8b 47 08          	mov    0x8(%rdi),%rax
    2250:	48 89 44 24 68       	mov    %rax,0x68(%rsp)
    2255:	48 8b 07             	mov    (%rdi),%rax
    2258:	48 89 44 24 70       	mov    %rax,0x70(%rsp)
	{
		long i, j, k, ii, jj, kk, mc, nc, kc, mr, nr;
		int size_block_m;
		int id = omp_get_thread_num();
    225d:	e8 ce ef ff ff       	call   1230 <omp_get_thread_num@plt>
		uint16_t *temp_Bc = Bc + id * GEMM_K * 32;
    2262:	48 8b 73 40          	mov    0x40(%rbx),%rsi

		for (i = id; i < Num_blocks; i = i + NUM)
    2266:	4c 63 43 5c          	movslq 0x5c(%rbx),%r8
		uint16_t *temp_Bc = Bc + id * GEMM_K * 32;
    226a:	89 c1                	mov    %eax,%ecx
		for (i = id; i < Num_blocks; i = i + NUM)
    226c:	48 98                	cltq
    226e:	8b 54 24 08          	mov    0x8(%rsp),%edx
		uint16_t *temp_Bc = Bc + id * GEMM_K * 32;
    2272:	c1 e1 0f             	shl    $0xf,%ecx
		for (i = id; i < Num_blocks; i = i + NUM)
    2275:	4c 39 c0             	cmp    %r8,%rax
    2278:	48 89 44 24 50       	mov    %rax,0x50(%rsp)
		uint16_t *temp_Bc = Bc + id * GEMM_K * 32;
    227d:	48 63 c9             	movslq %ecx,%rcx
    2280:	48 8d 3c 4e          	lea    (%rsi,%rcx,2),%rdi
    2284:	48 89 7c 24 78       	mov    %rdi,0x78(%rsp)
		for (i = id; i < Num_blocks; i = i + NUM)
    2289:	0f 8d 0e 01 00 00    	jge    239d <GEMM_BF16._omp_fn.0+0x1cd>
    228f:	49 89 c7             	mov    %rax,%r15
				FLASHGEMM_NPACK(AA, AAc, size_block_m, Edge_K, K / 2);
			}
			else
			{
				AAc = Ac + start_K * M + start_M * GEMM_K / 2; // note
				FLASHGEMM_NPACK(AA, AAc, size_block_m, GEMM_K / 2, K / 2);
    2292:	48 8b 44 24 38       	mov    0x38(%rsp),%rax
			int start_M = (i % Num_M_block) * 12;
    2297:	48 63 da             	movslq %edx,%rbx
				FLASHGEMM_NPACK(AA, AAc, size_block_m, GEMM_K / 2, K / 2);
    229a:	49 89 c4             	mov    %rax,%r12
    229d:	49 c1 ec 3f          	shr    $0x3f,%r12
    22a1:	49 01 c4             	add    %rax,%r12
			if (Edge_M > 0 && (i % Num_M_block) == (Num_M_block - 1))
    22a4:	8d 42 ff             	lea    -0x1(%rdx),%eax
				FLASHGEMM_NPACK(AA, AAc, size_block_m, GEMM_K / 2, K / 2);
    22a7:	49 d1 fc             	sar    $1,%r12
			if (Edge_M > 0 && (i % Num_M_block) == (Num_M_block - 1))
    22aa:	89 44 24 48          	mov    %eax,0x48(%rsp)
				FLASHGEMM_NPACK(AA, AAc, size_block_m, GEMM_K / 2, K / 2);
    22ae:	44 89 e7             	mov    %r12d,%edi
		for (i = id; i < Num_blocks; i = i + NUM)
    22b1:	4c 63 64 24 28       	movslq 0x28(%rsp),%r12
			if (Edge_M > 0 && (i % Num_M_block) == (Num_M_block - 1))
    22b6:	48 89 5c 24 28       	mov    %rbx,0x28(%rsp)
    22bb:	4c 89 fb             	mov    %r15,%rbx
    22be:	4d 89 c7             	mov    %r8,%r15
    22c1:	41 89 f8             	mov    %edi,%r8d
    22c4:	eb 61                	jmp    2327 <GEMM_BF16._omp_fn.0+0x157>
    22c6:	66 2e 0f 1f 84 00 00 	cs nopw 0x0(%rax,%rax,1)
    22cd:	00 00 00 
    22d0:	48 63 74 24 48       	movslq 0x48(%rsp),%rsi
			size_block_m = 12;
    22d5:	48 39 f2             	cmp    %rsi,%rdx
    22d8:	ba 0c 00 00 00       	mov    $0xc,%edx
    22dd:	41 0f 44 d5          	cmove  %r13d,%edx
				AAc = Ac + start_K * M + start_M * GEMM_K / 2; // note
    22e1:	48 8b 74 24 20       	mov    0x20(%rsp),%rsi
    22e6:	48 0f af c6          	imul   %rsi,%rax
			if (Edge_K > 0 && i >= Num_blocks0)
    22ea:	45 85 f6             	test   %r14d,%r14d
    22ed:	7e 0a                	jle    22f9 <GEMM_BF16._omp_fn.0+0x129>
    22ef:	48 63 74 24 30       	movslq 0x30(%rsp),%rsi
    22f4:	48 39 de             	cmp    %rbx,%rsi
    22f7:	7e 77                	jle    2370 <GEMM_BF16._omp_fn.0+0x1a0>
				AAc = Ac + start_K * M + start_M * GEMM_K / 2; // note
    22f9:	c1 e1 09             	shl    $0x9,%ecx
		for (i = id; i < Num_blocks; i = i + NUM)
    22fc:	4c 01 e3             	add    %r12,%rbx
				FLASHGEMM_NPACK(AA, AAc, size_block_m, GEMM_K / 2, K / 2);
    22ff:	44 89 44 24 08       	mov    %r8d,0x8(%rsp)
				AAc = Ac + start_K * M + start_M * GEMM_K / 2; // note
    2304:	48 63 c9             	movslq %ecx,%rcx
    2307:	48 01 c1             	add    %rax,%rcx
    230a:	48 8b 44 24 60       	mov    0x60(%rsp),%rax
    230f:	48 8d 34 88          	lea    (%rax,%rcx,4),%rsi
				FLASHGEMM_NPACK(AA, AAc, size_block_m, GEMM_K / 2, K / 2);
    2313:	b9 00 02 00 00       	mov    $0x200,%ecx
    2318:	e8 23 f3 ff ff       	call   1640 <FLASHGEMM_NPACK>
    231d:	44 8b 44 24 08       	mov    0x8(%rsp),%r8d
		for (i = id; i < Num_blocks; i = i + NUM)
    2322:	4c 39 fb             	cmp    %r15,%rbx
    2325:	7d 76                	jge    239d <GEMM_BF16._omp_fn.0+0x1cd>
			int start_M = (i % Num_M_block) * 12;
    2327:	48 89 d8             	mov    %rbx,%rax
			float *AA = A + start_M * K / 2 + start_K;
    232a:	48 8b 7c 24 38       	mov    0x38(%rsp),%rdi
    232f:	48 99                	cqto
    2331:	48 f7 7c 24 28       	idivq  0x28(%rsp)
			int start_M = (i % Num_M_block) * 12;
    2336:	8d 0c 52             	lea    (%rdx,%rdx,2),%ecx
			int start_K = (i / Num_M_block) * GEMM_K / 2; // TODO
    2339:	c1 e0 09             	shl    $0x9,%eax
			int start_M = (i % Num_M_block) * 12;
    233c:	c1 e1 02             	shl    $0x2,%ecx
			float *AA = A + start_M * K / 2 + start_K;
    233f:	48 98                	cltq
    2341:	48 63 f1             	movslq %ecx,%rsi
    2344:	48 0f af f7          	imul   %rdi,%rsi
    2348:	48 8b 7c 24 18       	mov    0x18(%rsp),%rdi
    234d:	48 d1 fe             	sar    $1,%rsi
    2350:	48 01 c6             	add    %rax,%rsi
    2353:	48 8d 3c b7          	lea    (%rdi,%rsi,4),%rdi
			if (Edge_M > 0 && (i % Num_M_block) == (Num_M_block - 1))
    2357:	45 85 ed             	test   %r13d,%r13d
    235a:	0f 8f 70 ff ff ff    	jg     22d0 <GEMM_BF16._omp_fn.0+0x100>
			size_block_m = 12;
    2360:	ba 0c 00 00 00       	mov    $0xc,%edx
    2365:	e9 77 ff ff ff       	jmp    22e1 <GEMM_BF16._omp_fn.0+0x111>
    236a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
				AAc = Ac + start_K * M + start_M * Edge_K; // note
    2370:	41 0f af ce          	imul   %r14d,%ecx
		for (i = id; i < Num_blocks; i = i + NUM)
    2374:	4c 01 e3             	add    %r12,%rbx
				FLASHGEMM_NPACK(AA, AAc, size_block_m, Edge_K, K / 2);
    2377:	44 89 44 24 08       	mov    %r8d,0x8(%rsp)
				AAc = Ac + start_K * M + start_M * Edge_K; // note
    237c:	48 63 c9             	movslq %ecx,%rcx
    237f:	48 01 c8             	add    %rcx,%rax
    2382:	48 8b 4c 24 60       	mov    0x60(%rsp),%rcx
    2387:	48 8d 34 81          	lea    (%rcx,%rax,4),%rsi
				FLASHGEMM_NPACK(AA, AAc, size_block_m, Edge_K, K / 2);
    238b:	44 89 f1             	mov    %r14d,%ecx
    238e:	e8 ad f2 ff ff       	call   1640 <FLASHGEMM_NPACK>
    2393:	44 8b 44 24 08       	mov    0x8(%rsp),%r8d
		for (i = id; i < Num_blocks; i = i + NUM)
    2398:	4c 39 fb             	cmp    %r15,%rbx
    239b:	7c 8a                	jl     2327 <GEMM_BF16._omp_fn.0+0x157>
			}
		}

#pragma omp barrier
    239d:	e8 de ed ff ff       	call   1180 <GOMP_barrier@plt>

		for (kk = 0; kk < K; kk = kk + kc)
    23a2:	48 83 7c 24 38 00    	cmpq   $0x0,0x38(%rsp)
    23a8:	0f 8e ed 28 00 00    	jle    4c9b <BF16_END_N32+0x28>
			for (j = 0; j < Nb; j = j + nr)
			{
				nr = 32;
				if (Nb - j < 32)
					nr = Nb - j;
				float *temp_C = C + id * Nb + j;
    23ae:	48 8b 44 24 50       	mov    0x50(%rsp),%rax
    23b3:	48 8b 5c 24 10       	mov    0x10(%rsp),%rbx
		for (kk = 0; kk < K; kk = kk + kc)
    23b8:	31 c9                	xor    %ecx,%ecx
				float *temp_C = C + id * Nb + j;
    23ba:	48 0f af c3          	imul   %rbx,%rax
    23be:	48 89 44 24 48       	mov    %rax,0x48(%rsp)
    23c3:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)
			if (K - kk < GEMM_K)
    23c8:	48 8b 74 24 38       	mov    0x38(%rsp),%rsi
    23cd:	b8 00 04 00 00       	mov    $0x400,%eax
			uint16_t *temp_A = (uint16_t *)Ac + kk * M;
    23d2:	48 8b 7c 24 60       	mov    0x60(%rsp),%rdi
			if (K - kk < GEMM_K)
    23d7:	48 29 ce             	sub    %rcx,%rsi
    23da:	48 39 c6             	cmp    %rax,%rsi
    23dd:	48 0f 4f f0          	cmovg  %rax,%rsi
			uint16_t *temp_A = (uint16_t *)Ac + kk * M;
    23e1:	48 8b 44 24 20       	mov    0x20(%rsp),%rax
    23e6:	48 0f af c1          	imul   %rcx,%rax
			for (j = 0; j < Nb; j = j + nr)
    23ea:	48 83 7c 24 10 00    	cmpq   $0x0,0x10(%rsp)
			uint16_t *temp_A = (uint16_t *)Ac + kk * M;
    23f0:	48 8d 3c 47          	lea    (%rdi,%rax,2),%rdi
			for (j = 0; j < Nb; j = j + nr)
    23f4:	0f 8e 90 28 00 00    	jle    4c8a <BF16_END_N32+0x17>
				uint16_t *temp_B = B_bf16 + kk * N + id * Nb + j;
    23fa:	48 8b 44 24 40       	mov    0x40(%rsp),%rax
    23ff:	48 8b 5c 24 48       	mov    0x48(%rsp),%rbx
			for (j = 0; j < Nb; j = j + nr)
    2404:	48 89 7c 24 58       	mov    %rdi,0x58(%rsp)
    2409:	48 c7 44 24 08 00 00 	movq   $0x0,0x8(%rsp)
    2410:	00 00 
				uint16_t *temp_B = B_bf16 + kk * N + id * Nb + j;
    2412:	48 0f af c1          	imul   %rcx,%rax
			for (j = 0; j < Nb; j = j + nr)
    2416:	48 89 4c 24 28       	mov    %rcx,0x28(%rsp)
    241b:	48 89 74 24 30       	mov    %rsi,0x30(%rsp)
				uint16_t *temp_B = B_bf16 + kk * N + id * Nb + j;
    2420:	48 01 d8             	add    %rbx,%rax
    2423:	48 89 44 24 50       	mov    %rax,0x50(%rsp)
    2428:	eb 20                	jmp    244a <GEMM_BF16._omp_fn.0+0x27a>
    242a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
			for (j = 0; j < Nb; j = j + nr)
    2430:	48 8b 5c 24 18       	mov    0x18(%rsp),%rbx
    2435:	48 01 5c 24 08       	add    %rbx,0x8(%rsp)
    243a:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    243f:	48 39 44 24 10       	cmp    %rax,0x10(%rsp)
    2444:	0f 8e 36 28 00 00    	jle    4c80 <BF16_END_N32+0xd>
				if (Nb - j < 32)
    244a:	48 8b 44 24 10       	mov    0x10(%rsp),%rax
    244f:	48 8b 7c 24 08       	mov    0x8(%rsp),%rdi
    2454:	ba 20 00 00 00       	mov    $0x20,%edx
    2459:	48 29 f8             	sub    %rdi,%rax
    245c:	48 39 d0             	cmp    %rdx,%rax
    245f:	48 0f 4e d0          	cmovle %rax,%rdx
    2463:	48 89 54 24 18       	mov    %rdx,0x18(%rsp)
				if (nr == 32)
    2468:	48 83 f8 1f          	cmp    $0x1f,%rax
    246c:	7e c2                	jle    2430 <GEMM_BF16._omp_fn.0+0x260>
				float *temp_C = C + id * Nb + j;
    246e:	48 8b 74 24 08       	mov    0x8(%rsp),%rsi
    2473:	48 8b 44 24 48       	mov    0x48(%rsp),%rax
    2478:	48 8b 7c 24 70       	mov    0x70(%rsp),%rdi
				uint16_t *temp_B = B_bf16 + kk * N + id * Nb + j;
    247d:	48 8b 5c 24 68       	mov    0x68(%rsp),%rbx
				float *temp_C = C + id * Nb + j;
    2482:	48 01 f0             	add    %rsi,%rax
    2485:	48 8d 04 87          	lea    (%rdi,%rax,4),%rax
    2489:	48 89 84 24 80 00 00 	mov    %rax,0x80(%rsp)
    2490:	00 
    2491:	48 8b 44 24 58       	mov    0x58(%rsp),%rax
    2496:	48 89 84 24 88 00 00 	mov    %rax,0x88(%rsp)
    249d:	00 
				uint16_t *temp_B = B_bf16 + kk * N + id * Nb + j;
    249e:	48 8b 44 24 50       	mov    0x50(%rsp),%rax
    24a3:	48 01 f0             	add    %rsi,%rax
    24a6:	48 8d 04 43          	lea    (%rbx,%rax,2),%rax
    24aa:	48 89 84 24 90 00 00 	mov    %rax,0x90(%rsp)
    24b1:	00 
    24b2:	48 8b 44 24 20       	mov    0x20(%rsp),%rax
    24b7:	48 89 84 24 98 00 00 	mov    %rax,0x98(%rsp)
    24be:	00 
    24bf:	48 8b 44 24 10       	mov    0x10(%rsp),%rax
    24c4:	48 89 84 24 a0 00 00 	mov    %rax,0xa0(%rsp)
    24cb:	00 
    24cc:	48 8b 44 24 30       	mov    0x30(%rsp),%rax
    24d1:	48 89 84 24 a8 00 00 	mov    %rax,0xa8(%rsp)
    24d8:	00 
    24d9:	48 8b 44 24 40       	mov    0x40(%rsp),%rax
    24de:	48 89 84 24 b0 00 00 	mov    %rax,0xb0(%rsp)
    24e5:	00 
    24e6:	48 8b 44 24 78       	mov    0x78(%rsp),%rax
    24eb:	48 89 84 24 b8 00 00 	mov    %rax,0xb8(%rsp)
    24f2:	00 
    24f3:	48 8b 44 24 28       	mov    0x28(%rsp),%rax
    24f8:	48 89 84 24 c0 00 00 	mov    %rax,0xc0(%rsp)
    24ff:	00 

0000000000002500 <GEMM_BF16_N32>:
#include <stdint.h>

static void FLASHGEMM_BF16_KERNELm12xn32xk2(float *C, uint16_t *A, uint16_t *B, long M, long N, long K, long LN, uint16_t *Bc, long k_tag) // edge case m4n32k2
{
	asm volatile(
    2500:	48 8b 8c 24 80 00 00 	mov    0x80(%rsp),%rcx
    2507:	00 
    2508:	48 8b 84 24 88 00 00 	mov    0x88(%rsp),%rax
    250f:	00 
    2510:	48 8b 9c 24 90 00 00 	mov    0x90(%rsp),%rbx
    2517:	00 
    2518:	0f 18 08             	prefetcht0 (%rax)
    251b:	48 8b 94 24 a8 00 00 	mov    0xa8(%rsp),%rdx
    2522:	00 
    2523:	4c 8b 84 24 b0 00 00 	mov    0xb0(%rsp),%r8
    252a:	00 
    252b:	4c 8b b4 24 b8 00 00 	mov    0xb8(%rsp),%r14
    2532:	00 
    2533:	48 8b bc 24 98 00 00 	mov    0x98(%rsp),%rdi
    253a:	00 
    253b:	4c 8b bc 24 c0 00 00 	mov    0xc0(%rsp),%r15
    2542:	00 
    2543:	0f 18 0b             	prefetcht0 (%rbx)
    2546:	49 89 d9             	mov    %rbx,%r9
    2549:	48 89 d6             	mov    %rdx,%rsi

000000000000254c <BF16_BEGIN_PACK_N32>:
    254c:	4c 89 f5             	mov    %r14,%rbp
    254f:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    2555:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2559:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    255d:	62 f1 ff 48 6f 3b    	vmovdqu16 (%rbx),%zmm7
    2563:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2567:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    256b:	48 89 f2             	mov    %rsi,%rdx
    256e:	62 51 bd 48 ef c0    	vpxorq %zmm8,%zmm8,%zmm8
    2574:	62 51 b5 48 ef c9    	vpxorq %zmm9,%zmm9,%zmm9
    257a:	62 51 ad 48 ef d2    	vpxorq %zmm10,%zmm10,%zmm10
    2580:	62 51 a5 48 ef db    	vpxorq %zmm11,%zmm11,%zmm11
    2586:	62 51 9d 48 ef e4    	vpxorq %zmm12,%zmm12,%zmm12
    258c:	62 51 95 48 ef ed    	vpxorq %zmm13,%zmm13,%zmm13
    2592:	62 51 8d 48 ef f6    	vpxorq %zmm14,%zmm14,%zmm14
    2598:	62 51 85 48 ef ff    	vpxorq %zmm15,%zmm15,%zmm15
    259e:	62 a1 fd 40 ef c0    	vpxorq %zmm16,%zmm16,%zmm16
    25a4:	62 a1 f5 40 ef c9    	vpxorq %zmm17,%zmm17,%zmm17
    25aa:	62 a1 ed 40 ef d2    	vpxorq %zmm18,%zmm18,%zmm18
    25b0:	62 a1 e5 40 ef db    	vpxorq %zmm19,%zmm19,%zmm19
    25b6:	62 a1 dd 40 ef e4    	vpxorq %zmm20,%zmm20,%zmm20
    25bc:	62 a1 d5 40 ef ed    	vpxorq %zmm21,%zmm21,%zmm21
    25c2:	62 a1 cd 40 ef f6    	vpxorq %zmm22,%zmm22,%zmm22
    25c8:	62 a1 c5 40 ef ff    	vpxorq %zmm23,%zmm23,%zmm23
    25ce:	62 01 bd 40 ef c0    	vpxorq %zmm24,%zmm24,%zmm24
    25d4:	62 01 b5 40 ef c9    	vpxorq %zmm25,%zmm25,%zmm25
    25da:	62 01 ad 40 ef d2    	vpxorq %zmm26,%zmm26,%zmm26
    25e0:	62 01 a5 40 ef db    	vpxorq %zmm27,%zmm27,%zmm27
    25e6:	62 01 9d 40 ef e4    	vpxorq %zmm28,%zmm28,%zmm28
    25ec:	62 01 95 40 ef ed    	vpxorq %zmm29,%zmm29,%zmm29
    25f2:	62 01 8d 40 ef f6    	vpxorq %zmm30,%zmm30,%zmm30
    25f8:	62 01 85 40 ef ff    	vpxorq %zmm31,%zmm31,%zmm31
    25fe:	49 89 cd             	mov    %rcx,%r13
    2601:	48 83 ea 10          	sub    $0x10,%rdx

0000000000002605 <BF16_PACK_MAIN_M12N32>:
    2605:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    260b:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    2612:	62 f1 4d 48 61 e7    	vpunpcklwd %zmm7,%zmm6,%zmm4
    2618:	62 f1 4d 48 69 ef    	vpunpckhwd %zmm7,%zmm6,%zmm5
    261e:	62 f3 7d 48 39 e0 01 	vextracti32x4 $0x1,%zmm4,%xmm0
    2625:	62 f3 7d 48 39 e1 02 	vextracti32x4 $0x2,%zmm4,%xmm1
    262c:	62 f3 7d 48 39 e2 03 	vextracti32x4 $0x3,%zmm4,%xmm2
    2633:	62 f3 7d 48 39 eb 00 	vextracti32x4 $0x0,%zmm5,%xmm3
    263a:	62 f3 7d 48 39 ee 01 	vextracti32x4 $0x1,%zmm5,%xmm6
    2641:	62 f3 7d 48 39 ef 02 	vextracti32x4 $0x2,%zmm5,%xmm7
    2648:	62 f3 5d 48 38 e0 02 	vinserti32x4 $0x2,%xmm0,%zmm4,%zmm4
    264f:	62 f3 55 48 38 e9 00 	vinserti32x4 $0x0,%xmm1,%zmm5,%zmm5
    2656:	62 f3 55 48 38 ea 02 	vinserti32x4 $0x2,%xmm2,%zmm5,%zmm5
    265d:	62 f3 5d 48 38 e3 01 	vinserti32x4 $0x1,%xmm3,%zmm4,%zmm4
    2664:	62 f3 5d 48 38 e6 03 	vinserti32x4 $0x3,%xmm6,%zmm4,%zmm4
    266b:	62 f3 55 48 38 ef 01 	vinserti32x4 $0x1,%xmm7,%zmm5,%zmm5
    2672:	62 f1 7c 48 11 65 00 	vmovups %zmm4,0x0(%rbp)
    2679:	62 f1 7c 48 11 6d 01 	vmovups %zmm5,0x40(%rbp)
    2680:	48 81 c5 80 00 00 00 	add    $0x80,%rbp
    2687:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    268e:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    2694:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    269a:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    26a1:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    26a7:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    26ad:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    26b4:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    26bb:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    26c1:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    26c7:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    26ce:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    26d4:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    26da:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    26e1:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    26e7:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    26ed:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    26f4:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    26fa:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    2700:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    2706:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    270a:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    270e:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    2715:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    271b:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    2721:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    2728:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    272e:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    2734:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    273b:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    2741:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    2747:	62 f1 ff 48 6f 3b    	vmovdqu16 (%rbx),%zmm7
    274d:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2751:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    2755:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    275c:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    2762:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    2768:	48 83 c0 30          	add    $0x30,%rax
    276c:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    2772:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    2778:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    277e:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    2784:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    278a:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    2791:	62 f1 4d 48 61 e7    	vpunpcklwd %zmm7,%zmm6,%zmm4
    2797:	62 f1 4d 48 69 ef    	vpunpckhwd %zmm7,%zmm6,%zmm5
    279d:	62 f3 7d 48 39 e0 01 	vextracti32x4 $0x1,%zmm4,%xmm0
    27a4:	62 f3 7d 48 39 e1 02 	vextracti32x4 $0x2,%zmm4,%xmm1
    27ab:	62 f3 7d 48 39 e2 03 	vextracti32x4 $0x3,%zmm4,%xmm2
    27b2:	62 f3 7d 48 39 eb 00 	vextracti32x4 $0x0,%zmm5,%xmm3
    27b9:	62 f3 7d 48 39 ee 01 	vextracti32x4 $0x1,%zmm5,%xmm6
    27c0:	62 f3 7d 48 39 ef 02 	vextracti32x4 $0x2,%zmm5,%xmm7
    27c7:	62 f3 5d 48 38 e0 02 	vinserti32x4 $0x2,%xmm0,%zmm4,%zmm4
    27ce:	62 f3 55 48 38 e9 00 	vinserti32x4 $0x0,%xmm1,%zmm5,%zmm5
    27d5:	62 f3 55 48 38 ea 02 	vinserti32x4 $0x2,%xmm2,%zmm5,%zmm5
    27dc:	62 f3 5d 48 38 e3 01 	vinserti32x4 $0x1,%xmm3,%zmm4,%zmm4
    27e3:	62 f3 5d 48 38 e6 03 	vinserti32x4 $0x3,%xmm6,%zmm4,%zmm4
    27ea:	62 f3 55 48 38 ef 01 	vinserti32x4 $0x1,%xmm7,%zmm5,%zmm5
    27f1:	62 f1 7c 48 11 65 00 	vmovups %zmm4,0x0(%rbp)
    27f8:	62 f1 7c 48 11 6d 01 	vmovups %zmm5,0x40(%rbp)
    27ff:	48 81 c5 80 00 00 00 	add    $0x80,%rbp
    2806:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    280d:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    2813:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    2819:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    2820:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    2826:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    282c:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    2833:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    283a:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    2840:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    2846:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    284d:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    2853:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    2859:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    2860:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    2866:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    286c:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    2873:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    2879:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    287f:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    2885:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2889:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    288d:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    2894:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    289a:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    28a0:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    28a7:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    28ad:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    28b3:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    28ba:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    28c0:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    28c6:	62 f1 ff 48 6f 3b    	vmovdqu16 (%rbx),%zmm7
    28cc:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    28d0:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    28d4:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    28db:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    28e1:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    28e7:	48 83 c0 30          	add    $0x30,%rax
    28eb:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    28f1:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    28f7:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    28fd:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    2903:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    2909:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    2910:	62 f1 4d 48 61 e7    	vpunpcklwd %zmm7,%zmm6,%zmm4
    2916:	62 f1 4d 48 69 ef    	vpunpckhwd %zmm7,%zmm6,%zmm5
    291c:	62 f3 7d 48 39 e0 01 	vextracti32x4 $0x1,%zmm4,%xmm0
    2923:	62 f3 7d 48 39 e1 02 	vextracti32x4 $0x2,%zmm4,%xmm1
    292a:	62 f3 7d 48 39 e2 03 	vextracti32x4 $0x3,%zmm4,%xmm2
    2931:	62 f3 7d 48 39 eb 00 	vextracti32x4 $0x0,%zmm5,%xmm3
    2938:	62 f3 7d 48 39 ee 01 	vextracti32x4 $0x1,%zmm5,%xmm6
    293f:	62 f3 7d 48 39 ef 02 	vextracti32x4 $0x2,%zmm5,%xmm7
    2946:	62 f3 5d 48 38 e0 02 	vinserti32x4 $0x2,%xmm0,%zmm4,%zmm4
    294d:	62 f3 55 48 38 e9 00 	vinserti32x4 $0x0,%xmm1,%zmm5,%zmm5
    2954:	62 f3 55 48 38 ea 02 	vinserti32x4 $0x2,%xmm2,%zmm5,%zmm5
    295b:	62 f3 5d 48 38 e3 01 	vinserti32x4 $0x1,%xmm3,%zmm4,%zmm4
    2962:	62 f3 5d 48 38 e6 03 	vinserti32x4 $0x3,%xmm6,%zmm4,%zmm4
    2969:	62 f3 55 48 38 ef 01 	vinserti32x4 $0x1,%xmm7,%zmm5,%zmm5
    2970:	62 f1 7c 48 11 65 00 	vmovups %zmm4,0x0(%rbp)
    2977:	62 f1 7c 48 11 6d 01 	vmovups %zmm5,0x40(%rbp)
    297e:	48 81 c5 80 00 00 00 	add    $0x80,%rbp
    2985:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    298c:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    2992:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    2998:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    299f:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    29a5:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    29ab:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    29b2:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    29b9:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    29bf:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    29c5:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    29cc:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    29d2:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    29d8:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    29df:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    29e5:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    29eb:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    29f2:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    29f8:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    29fe:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    2a04:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2a08:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    2a0c:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    2a13:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    2a19:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    2a1f:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    2a26:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    2a2c:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    2a32:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    2a39:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    2a3f:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    2a45:	62 f1 ff 48 6f 3b    	vmovdqu16 (%rbx),%zmm7
    2a4b:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2a4f:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    2a53:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    2a5a:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    2a60:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    2a66:	48 83 c0 30          	add    $0x30,%rax
    2a6a:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    2a70:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    2a76:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    2a7c:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    2a82:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    2a88:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    2a8f:	62 f1 4d 48 61 e7    	vpunpcklwd %zmm7,%zmm6,%zmm4
    2a95:	62 f1 4d 48 69 ef    	vpunpckhwd %zmm7,%zmm6,%zmm5
    2a9b:	62 f3 7d 48 39 e0 01 	vextracti32x4 $0x1,%zmm4,%xmm0
    2aa2:	62 f3 7d 48 39 e1 02 	vextracti32x4 $0x2,%zmm4,%xmm1
    2aa9:	62 f3 7d 48 39 e2 03 	vextracti32x4 $0x3,%zmm4,%xmm2
    2ab0:	62 f3 7d 48 39 eb 00 	vextracti32x4 $0x0,%zmm5,%xmm3
    2ab7:	62 f3 7d 48 39 ee 01 	vextracti32x4 $0x1,%zmm5,%xmm6
    2abe:	62 f3 7d 48 39 ef 02 	vextracti32x4 $0x2,%zmm5,%xmm7
    2ac5:	62 f3 5d 48 38 e0 02 	vinserti32x4 $0x2,%xmm0,%zmm4,%zmm4
    2acc:	62 f3 55 48 38 e9 00 	vinserti32x4 $0x0,%xmm1,%zmm5,%zmm5
    2ad3:	62 f3 55 48 38 ea 02 	vinserti32x4 $0x2,%xmm2,%zmm5,%zmm5
    2ada:	62 f3 5d 48 38 e3 01 	vinserti32x4 $0x1,%xmm3,%zmm4,%zmm4
    2ae1:	62 f3 5d 48 38 e6 03 	vinserti32x4 $0x3,%xmm6,%zmm4,%zmm4
    2ae8:	62 f3 55 48 38 ef 01 	vinserti32x4 $0x1,%xmm7,%zmm5,%zmm5
    2aef:	62 f1 7c 48 11 65 00 	vmovups %zmm4,0x0(%rbp)
    2af6:	62 f1 7c 48 11 6d 01 	vmovups %zmm5,0x40(%rbp)
    2afd:	48 81 c5 80 00 00 00 	add    $0x80,%rbp
    2b04:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    2b0b:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    2b11:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    2b17:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    2b1e:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    2b24:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    2b2a:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    2b31:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    2b38:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    2b3e:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    2b44:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    2b4b:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    2b51:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    2b57:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    2b5e:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    2b64:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    2b6a:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    2b71:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    2b77:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    2b7d:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    2b83:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2b87:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    2b8b:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    2b92:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    2b98:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    2b9e:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    2ba5:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    2bab:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    2bb1:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    2bb8:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    2bbe:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    2bc4:	62 f1 ff 48 6f 3b    	vmovdqu16 (%rbx),%zmm7
    2bca:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2bce:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    2bd2:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    2bd9:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    2bdf:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    2be5:	48 83 c0 30          	add    $0x30,%rax
    2be9:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    2bef:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    2bf5:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    2bfb:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    2c01:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    2c07:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    2c0e:	62 f1 4d 48 61 e7    	vpunpcklwd %zmm7,%zmm6,%zmm4
    2c14:	62 f1 4d 48 69 ef    	vpunpckhwd %zmm7,%zmm6,%zmm5
    2c1a:	62 f3 7d 48 39 e0 01 	vextracti32x4 $0x1,%zmm4,%xmm0
    2c21:	62 f3 7d 48 39 e1 02 	vextracti32x4 $0x2,%zmm4,%xmm1
    2c28:	62 f3 7d 48 39 e2 03 	vextracti32x4 $0x3,%zmm4,%xmm2
    2c2f:	62 f3 7d 48 39 eb 00 	vextracti32x4 $0x0,%zmm5,%xmm3
    2c36:	62 f3 7d 48 39 ee 01 	vextracti32x4 $0x1,%zmm5,%xmm6
    2c3d:	62 f3 7d 48 39 ef 02 	vextracti32x4 $0x2,%zmm5,%xmm7
    2c44:	62 f3 5d 48 38 e0 02 	vinserti32x4 $0x2,%xmm0,%zmm4,%zmm4
    2c4b:	62 f3 55 48 38 e9 00 	vinserti32x4 $0x0,%xmm1,%zmm5,%zmm5
    2c52:	62 f3 55 48 38 ea 02 	vinserti32x4 $0x2,%xmm2,%zmm5,%zmm5
    2c59:	62 f3 5d 48 38 e3 01 	vinserti32x4 $0x1,%xmm3,%zmm4,%zmm4
    2c60:	62 f3 5d 48 38 e6 03 	vinserti32x4 $0x3,%xmm6,%zmm4,%zmm4
    2c67:	62 f3 55 48 38 ef 01 	vinserti32x4 $0x1,%xmm7,%zmm5,%zmm5
    2c6e:	62 f1 7c 48 11 65 00 	vmovups %zmm4,0x0(%rbp)
    2c75:	62 f1 7c 48 11 6d 01 	vmovups %zmm5,0x40(%rbp)
    2c7c:	48 81 c5 80 00 00 00 	add    $0x80,%rbp
    2c83:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    2c8a:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    2c90:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    2c96:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    2c9d:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    2ca3:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    2ca9:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    2cb0:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    2cb7:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    2cbd:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    2cc3:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    2cca:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    2cd0:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    2cd6:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    2cdd:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    2ce3:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    2ce9:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    2cf0:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    2cf6:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    2cfc:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    2d02:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2d06:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    2d0a:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    2d11:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    2d17:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    2d1d:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    2d24:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    2d2a:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    2d30:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    2d37:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    2d3d:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    2d43:	62 f1 ff 48 6f 3b    	vmovdqu16 (%rbx),%zmm7
    2d49:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2d4d:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    2d51:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    2d58:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    2d5e:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    2d64:	48 83 c0 30          	add    $0x30,%rax
    2d68:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    2d6e:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    2d74:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    2d7a:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    2d80:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    2d86:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    2d8d:	62 f1 4d 48 61 e7    	vpunpcklwd %zmm7,%zmm6,%zmm4
    2d93:	62 f1 4d 48 69 ef    	vpunpckhwd %zmm7,%zmm6,%zmm5
    2d99:	62 f3 7d 48 39 e0 01 	vextracti32x4 $0x1,%zmm4,%xmm0
    2da0:	62 f3 7d 48 39 e1 02 	vextracti32x4 $0x2,%zmm4,%xmm1
    2da7:	62 f3 7d 48 39 e2 03 	vextracti32x4 $0x3,%zmm4,%xmm2
    2dae:	62 f3 7d 48 39 eb 00 	vextracti32x4 $0x0,%zmm5,%xmm3
    2db5:	62 f3 7d 48 39 ee 01 	vextracti32x4 $0x1,%zmm5,%xmm6
    2dbc:	62 f3 7d 48 39 ef 02 	vextracti32x4 $0x2,%zmm5,%xmm7
    2dc3:	62 f3 5d 48 38 e0 02 	vinserti32x4 $0x2,%xmm0,%zmm4,%zmm4
    2dca:	62 f3 55 48 38 e9 00 	vinserti32x4 $0x0,%xmm1,%zmm5,%zmm5
    2dd1:	62 f3 55 48 38 ea 02 	vinserti32x4 $0x2,%xmm2,%zmm5,%zmm5
    2dd8:	62 f3 5d 48 38 e3 01 	vinserti32x4 $0x1,%xmm3,%zmm4,%zmm4
    2ddf:	62 f3 5d 48 38 e6 03 	vinserti32x4 $0x3,%xmm6,%zmm4,%zmm4
    2de6:	62 f3 55 48 38 ef 01 	vinserti32x4 $0x1,%xmm7,%zmm5,%zmm5
    2ded:	62 f1 7c 48 11 65 00 	vmovups %zmm4,0x0(%rbp)
    2df4:	62 f1 7c 48 11 6d 01 	vmovups %zmm5,0x40(%rbp)
    2dfb:	48 81 c5 80 00 00 00 	add    $0x80,%rbp
    2e02:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    2e09:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    2e0f:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    2e15:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    2e1c:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    2e22:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    2e28:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    2e2f:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    2e36:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    2e3c:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    2e42:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    2e49:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    2e4f:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    2e55:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    2e5c:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    2e62:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    2e68:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    2e6f:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    2e75:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    2e7b:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    2e81:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2e85:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    2e89:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    2e90:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    2e96:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    2e9c:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    2ea3:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    2ea9:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    2eaf:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    2eb6:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    2ebc:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    2ec2:	62 f1 ff 48 6f 3b    	vmovdqu16 (%rbx),%zmm7
    2ec8:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    2ecc:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    2ed0:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    2ed7:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    2edd:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    2ee3:	48 83 c0 30          	add    $0x30,%rax
    2ee7:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    2eed:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    2ef3:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    2ef9:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    2eff:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    2f05:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    2f0c:	62 f1 4d 48 61 e7    	vpunpcklwd %zmm7,%zmm6,%zmm4
    2f12:	62 f1 4d 48 69 ef    	vpunpckhwd %zmm7,%zmm6,%zmm5
    2f18:	62 f3 7d 48 39 e0 01 	vextracti32x4 $0x1,%zmm4,%xmm0
    2f1f:	62 f3 7d 48 39 e1 02 	vextracti32x4 $0x2,%zmm4,%xmm1
    2f26:	62 f3 7d 48 39 e2 03 	vextracti32x4 $0x3,%zmm4,%xmm2
    2f2d:	62 f3 7d 48 39 eb 00 	vextracti32x4 $0x0,%zmm5,%xmm3
    2f34:	62 f3 7d 48 39 ee 01 	vextracti32x4 $0x1,%zmm5,%xmm6
    2f3b:	62 f3 7d 48 39 ef 02 	vextracti32x4 $0x2,%zmm5,%xmm7
    2f42:	62 f3 5d 48 38 e0 02 	vinserti32x4 $0x2,%xmm0,%zmm4,%zmm4
    2f49:	62 f3 55 48 38 e9 00 	vinserti32x4 $0x0,%xmm1,%zmm5,%zmm5
    2f50:	62 f3 55 48 38 ea 02 	vinserti32x4 $0x2,%xmm2,%zmm5,%zmm5
    2f57:	62 f3 5d 48 38 e3 01 	vinserti32x4 $0x1,%xmm3,%zmm4,%zmm4
    2f5e:	62 f3 5d 48 38 e6 03 	vinserti32x4 $0x3,%xmm6,%zmm4,%zmm4
    2f65:	62 f3 55 48 38 ef 01 	vinserti32x4 $0x1,%xmm7,%zmm5,%zmm5
    2f6c:	62 f1 7c 48 11 65 00 	vmovups %zmm4,0x0(%rbp)
    2f73:	62 f1 7c 48 11 6d 01 	vmovups %zmm5,0x40(%rbp)
    2f7a:	48 81 c5 80 00 00 00 	add    $0x80,%rbp
    2f81:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    2f88:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    2f8e:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    2f94:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    2f9b:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    2fa1:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    2fa7:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    2fae:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    2fb5:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    2fbb:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    2fc1:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    2fc8:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    2fce:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    2fd4:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    2fdb:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    2fe1:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    2fe7:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    2fee:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    2ff4:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    2ffa:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    3000:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    3004:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    3008:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    300f:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    3015:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    301b:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    3022:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    3028:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    302e:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    3035:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    303b:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    3041:	62 f1 ff 48 6f 3b    	vmovdqu16 (%rbx),%zmm7
    3047:	0f 18 5b 40          	prefetcht2 0x40(%rbx)
    304b:	4a 8d 1c 43          	lea    (%rbx,%r8,2),%rbx
    304f:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    3056:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    305c:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    3062:	48 83 c0 30          	add    $0x30,%rax
    3066:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    306c:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    3072:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    3078:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    307e:	48 83 fa 00          	cmp    $0x0,%rdx
    3082:	74 26                	je     30aa <BF16_PACK_SAVEC_M12N32>
    3084:	48 83 ea 10          	sub    $0x10,%rdx
    3088:	48 81 fa c0 00 00 00 	cmp    $0xc0,%rdx
    308f:	76 05                	jbe    3096 <BF16_PACK_K_PREFETCH_C_M12N32>
    3091:	e9 6f f5 ff ff       	jmp    2605 <BF16_PACK_MAIN_M12N32>

0000000000003096 <BF16_PACK_K_PREFETCH_C_M12N32>:
    3096:	41 0f 18 5d 00       	prefetcht2 0x0(%r13)
    309b:	41 0f 18 5d 40       	prefetcht2 0x40(%r13)
    30a0:	4f 8d 6c 85 00       	lea    0x0(%r13,%r8,4),%r13
    30a5:	e9 5b f5 ff ff       	jmp    2605 <BF16_PACK_MAIN_M12N32>

00000000000030aa <BF16_PACK_SAVEC_M12N32>:
    30aa:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    30b0:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    30b7:	62 f1 4d 48 61 e7    	vpunpcklwd %zmm7,%zmm6,%zmm4
    30bd:	62 f1 4d 48 69 ef    	vpunpckhwd %zmm7,%zmm6,%zmm5
    30c3:	62 f3 7d 48 39 e0 01 	vextracti32x4 $0x1,%zmm4,%xmm0
    30ca:	62 f3 7d 48 39 e1 02 	vextracti32x4 $0x2,%zmm4,%xmm1
    30d1:	62 f3 7d 48 39 e2 03 	vextracti32x4 $0x3,%zmm4,%xmm2
    30d8:	62 f3 7d 48 39 eb 00 	vextracti32x4 $0x0,%zmm5,%xmm3
    30df:	62 f3 7d 48 39 ee 01 	vextracti32x4 $0x1,%zmm5,%xmm6
    30e6:	62 f3 7d 48 39 ef 02 	vextracti32x4 $0x2,%zmm5,%xmm7
    30ed:	62 f3 5d 48 38 e0 02 	vinserti32x4 $0x2,%xmm0,%zmm4,%zmm4
    30f4:	62 f3 55 48 38 e9 00 	vinserti32x4 $0x0,%xmm1,%zmm5,%zmm5
    30fb:	62 f3 55 48 38 ea 02 	vinserti32x4 $0x2,%xmm2,%zmm5,%zmm5
    3102:	62 f3 5d 48 38 e3 01 	vinserti32x4 $0x1,%xmm3,%zmm4,%zmm4
    3109:	62 f3 5d 48 38 e6 03 	vinserti32x4 $0x3,%xmm6,%zmm4,%zmm4
    3110:	62 f3 55 48 38 ef 01 	vinserti32x4 $0x1,%xmm7,%zmm5,%zmm5
    3117:	62 f1 7c 48 11 65 00 	vmovups %zmm4,0x0(%rbp)
    311e:	62 f1 7c 48 11 6d 01 	vmovups %zmm5,0x40(%rbp)
    3125:	48 81 c5 80 00 00 00 	add    $0x80,%rbp
    312c:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    3133:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    3139:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    313f:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    3146:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    314c:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    3152:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3159:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    3160:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    3166:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    316c:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    3173:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    3179:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    317f:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    3186:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    318c:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    3192:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    3199:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    319f:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    31a5:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    31ac:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    31b2:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    31b8:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    31bf:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    31c5:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    31cb:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    31d2:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    31d8:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    31de:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    31e5:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    31eb:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    31f1:	48 83 c0 30          	add    $0x30,%rax
    31f5:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    31fb:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    3201:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    3207:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    320d:	e9 02 0a 00 00       	jmp    3c14 <BF16_BEGIN_SAVE_M12N32>

0000000000003212 <BF16_BEGIN_M12>:
    3212:	48 83 ff 0c          	cmp    $0xc,%rdi
    3216:	0f 82 4c 0c 00 00    	jb     3e68 <BF16_BEGIN_M8>
    321c:	4c 89 f3             	mov    %r14,%rbx
    321f:	48 89 f2             	mov    %rsi,%rdx
    3222:	62 f1 7c 48 10 23    	vmovups (%rbx),%zmm4
    3228:	62 f1 7c 48 10 6b 01 	vmovups 0x40(%rbx),%zmm5
    322f:	62 51 bd 48 ef c0    	vpxorq %zmm8,%zmm8,%zmm8
    3235:	62 51 b5 48 ef c9    	vpxorq %zmm9,%zmm9,%zmm9
    323b:	62 51 ad 48 ef d2    	vpxorq %zmm10,%zmm10,%zmm10
    3241:	62 51 a5 48 ef db    	vpxorq %zmm11,%zmm11,%zmm11
    3247:	62 51 9d 48 ef e4    	vpxorq %zmm12,%zmm12,%zmm12
    324d:	62 51 95 48 ef ed    	vpxorq %zmm13,%zmm13,%zmm13
    3253:	62 51 8d 48 ef f6    	vpxorq %zmm14,%zmm14,%zmm14
    3259:	62 51 85 48 ef ff    	vpxorq %zmm15,%zmm15,%zmm15
    325f:	62 a1 fd 40 ef c0    	vpxorq %zmm16,%zmm16,%zmm16
    3265:	62 a1 f5 40 ef c9    	vpxorq %zmm17,%zmm17,%zmm17
    326b:	62 a1 ed 40 ef d2    	vpxorq %zmm18,%zmm18,%zmm18
    3271:	62 a1 e5 40 ef db    	vpxorq %zmm19,%zmm19,%zmm19
    3277:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    327d:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    3284:	62 a1 dd 40 ef e4    	vpxorq %zmm20,%zmm20,%zmm20
    328a:	62 a1 d5 40 ef ed    	vpxorq %zmm21,%zmm21,%zmm21
    3290:	62 a1 cd 40 ef f6    	vpxorq %zmm22,%zmm22,%zmm22
    3296:	62 a1 c5 40 ef ff    	vpxorq %zmm23,%zmm23,%zmm23
    329c:	62 01 bd 40 ef c0    	vpxorq %zmm24,%zmm24,%zmm24
    32a2:	62 01 b5 40 ef c9    	vpxorq %zmm25,%zmm25,%zmm25
    32a8:	62 01 ad 40 ef d2    	vpxorq %zmm26,%zmm26,%zmm26
    32ae:	62 01 a5 40 ef db    	vpxorq %zmm27,%zmm27,%zmm27
    32b4:	62 01 9d 40 ef e4    	vpxorq %zmm28,%zmm28,%zmm28
    32ba:	62 01 95 40 ef ed    	vpxorq %zmm29,%zmm29,%zmm29
    32c0:	62 01 8d 40 ef f6    	vpxorq %zmm30,%zmm30,%zmm30
    32c6:	62 01 85 40 ef ff    	vpxorq %zmm31,%zmm31,%zmm31
    32cc:	49 89 cd             	mov    %rcx,%r13
    32cf:	48 83 ea 10          	sub    $0x10,%rdx

00000000000032d3 <BF16_MAIN_K_M12N32>:
    32d3:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    32da:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    32e0:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    32e6:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    32ed:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    32f3:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    32f9:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3300:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    3307:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    330d:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    3313:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    331a:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    3320:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    3326:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    332d:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    3333:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    3339:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    3340:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    3346:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    334c:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    3353:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    3359:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    335f:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    3366:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    336d:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    3373:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    3379:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    337d:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    3384:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    338a:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    3390:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    3397:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    339d:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    33a3:	48 83 c0 30          	add    $0x30,%rax
    33a7:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    33ad:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    33b3:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    33b9:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    33c0:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    33c6:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    33cd:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    33d3:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    33d9:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    33e0:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    33e6:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    33ec:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    33f3:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    33f9:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    33ff:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3406:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    340d:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    3413:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    3419:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    3420:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    3426:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    342c:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    3433:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    3439:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    343f:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    3446:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    344c:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    3452:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    3459:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    345f:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    3465:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    346c:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    3473:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    3479:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23
    347f:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    3483:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    348a:	62 62 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm24
    3490:	62 62 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm25
    3496:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    349d:	62 62 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm26
    34a3:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    34a9:	48 83 c0 30          	add    $0x30,%rax
    34ad:	62 62 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm27
    34b3:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    34b9:	62 62 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm28
    34bf:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    34c6:	62 62 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm29
    34cc:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    34d3:	62 62 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm30
    34d9:	62 62 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm31
    34df:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    34e6:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    34ec:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    34f2:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    34f9:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    34ff:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    3505:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    350c:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    3513:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    3519:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    351f:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    3526:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    352c:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    3532:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    3539:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    353f:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    3545:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    354c:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    3552:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    3558:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    355f:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    3565:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    356b:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    3572:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    3579:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    357f:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    3585:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    3589:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    3590:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    3596:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    359c:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    35a3:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    35a9:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    35af:	48 83 c0 30          	add    $0x30,%rax
    35b3:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    35b9:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    35bf:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    35c5:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    35cc:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    35d2:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    35d9:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    35df:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    35e5:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    35ec:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    35f2:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    35f8:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    35ff:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    3605:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    360b:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3612:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    3619:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    361f:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    3625:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    362c:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    3632:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    3638:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    363f:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    3645:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    364b:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    3652:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    3658:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    365e:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    3665:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    366b:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    3671:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    3678:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    367f:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    3685:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23
    368b:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    368f:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    3696:	62 62 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm24
    369c:	62 62 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm25
    36a2:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    36a9:	62 62 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm26
    36af:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    36b5:	48 83 c0 30          	add    $0x30,%rax
    36b9:	62 62 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm27
    36bf:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    36c5:	62 62 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm28
    36cb:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    36d2:	62 62 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm29
    36d8:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    36df:	62 62 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm30
    36e5:	62 62 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm31
    36eb:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    36f2:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    36f8:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    36fe:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    3705:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    370b:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    3711:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3718:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    371f:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    3725:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    372b:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    3732:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    3738:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    373e:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    3745:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    374b:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    3751:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    3758:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    375e:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    3764:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    376b:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    3771:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    3777:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    377e:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    3785:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    378b:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    3791:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    3795:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    379c:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    37a2:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    37a8:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    37af:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    37b5:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    37bb:	48 83 c0 30          	add    $0x30,%rax
    37bf:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    37c5:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    37cb:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    37d1:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    37d8:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    37de:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    37e5:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    37eb:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    37f1:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    37f8:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    37fe:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    3804:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    380b:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    3811:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    3817:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    381e:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    3825:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    382b:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    3831:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    3838:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    383e:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    3844:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    384b:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    3851:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    3857:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    385e:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    3864:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    386a:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    3871:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    3877:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    387d:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    3884:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    388b:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    3891:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23
    3897:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    389b:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    38a2:	62 62 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm24
    38a8:	62 62 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm25
    38ae:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    38b5:	62 62 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm26
    38bb:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    38c1:	48 83 c0 30          	add    $0x30,%rax
    38c5:	62 62 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm27
    38cb:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    38d1:	62 62 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm28
    38d7:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    38de:	62 62 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm29
    38e4:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    38eb:	62 62 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm30
    38f1:	62 62 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm31
    38f7:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    38fe:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    3904:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    390a:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    3911:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    3917:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    391d:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3924:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    392b:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    3931:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    3937:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    393e:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    3944:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    394a:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    3951:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    3957:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    395d:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    3964:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    396a:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    3970:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    3977:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    397d:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    3983:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    398a:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    3991:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    3997:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    399d:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    39a1:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    39a8:	62 62 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm24
    39ae:	62 62 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm25
    39b4:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    39bb:	62 62 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm26
    39c1:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    39c7:	48 83 c0 30          	add    $0x30,%rax
    39cb:	62 62 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm27
    39d1:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    39d7:	62 62 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm28
    39dd:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    39e4:	62 62 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm29
    39ea:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    39f1:	62 62 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm30
    39f7:	62 62 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm31
    39fd:	48 83 fa 00          	cmp    $0x0,%rdx
    3a01:	0f 84 2c 01 00 00    	je     3b33 <BF16_MAIN_K_M12N32_EDGE>
    3a07:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    3a0e:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    3a14:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    3a1a:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    3a21:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    3a27:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    3a2d:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3a34:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    3a3b:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    3a41:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    3a47:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    3a4e:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    3a54:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    3a5a:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    3a61:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    3a67:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    3a6d:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    3a74:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    3a7a:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    3a80:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    3a87:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    3a8d:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    3a93:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    3a9a:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    3aa1:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    3aa7:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23
    3aad:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    3ab1:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    3ab8:	62 62 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm24
    3abe:	62 62 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm25
    3ac4:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    3acb:	62 62 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm26
    3ad1:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    3ad7:	48 83 c0 30          	add    $0x30,%rax
    3adb:	62 62 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm27
    3ae1:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    3ae7:	62 62 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm28
    3aed:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    3af4:	62 62 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm29
    3afa:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    3b01:	62 62 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm30
    3b07:	62 62 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm31
    3b0d:	48 83 ea 10          	sub    $0x10,%rdx
    3b11:	48 81 fa c0 00 00 00 	cmp    $0xc0,%rdx
    3b18:	76 05                	jbe    3b1f <BF16_K_PREFETCH_C_M12N32>
    3b1a:	e9 b4 f7 ff ff       	jmp    32d3 <BF16_MAIN_K_M12N32>

0000000000003b1f <BF16_K_PREFETCH_C_M12N32>:
    3b1f:	41 0f 18 5d 00       	prefetcht2 0x0(%r13)
    3b24:	41 0f 18 5d 40       	prefetcht2 0x40(%r13)
    3b29:	4f 8d 6c 85 00       	lea    0x0(%r13,%r8,4),%r13
    3b2e:	e9 a0 f7 ff ff       	jmp    32d3 <BF16_MAIN_K_M12N32>

0000000000003b33 <BF16_MAIN_K_M12N32_EDGE>:
    3b33:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    3b3a:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    3b40:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    3b46:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    3b4d:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    3b53:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    3b59:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3b60:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    3b67:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    3b6d:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    3b73:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    3b7a:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    3b80:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    3b86:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    3b8d:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    3b93:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    3b99:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    3ba0:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    3ba6:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    3bac:	62 f2 7d 48 18 40 08 	vbroadcastss 0x20(%rax),%zmm0
    3bb3:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    3bb9:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    3bbf:	62 f2 7d 48 18 48 09 	vbroadcastss 0x24(%rax),%zmm1
    3bc6:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    3bcc:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23
    3bd2:	62 f2 7d 48 18 50 0a 	vbroadcastss 0x28(%rax),%zmm2
    3bd9:	62 62 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm24
    3bdf:	62 62 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm25
    3be5:	62 f2 7d 48 18 58 0b 	vbroadcastss 0x2c(%rax),%zmm3
    3bec:	62 62 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm26
    3bf2:	48 83 c0 30          	add    $0x30,%rax
    3bf6:	62 62 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm27
    3bfc:	62 62 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm28
    3c02:	62 62 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm29
    3c08:	62 62 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm30
    3c0e:	62 62 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm31

0000000000003c14 <BF16_BEGIN_SAVE_M12N32>:
    3c14:	49 89 ca             	mov    %rcx,%r10
    3c17:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    3c1b:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    3c1f:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13
    3c23:	49 83 ff 00          	cmp    $0x0,%r15
    3c27:	0f 84 66 01 00 00    	je     3d93 <BF16_SAVE_C_M12N32>
    3c2d:	62 d1 7c 48 10 02    	vmovups (%r10),%zmm0
    3c33:	62 71 3c 48 58 c0    	vaddps %zmm0,%zmm8,%zmm8
    3c39:	62 d1 7c 48 10 4a 01 	vmovups 0x40(%r10),%zmm1
    3c40:	62 71 34 48 58 c9    	vaddps %zmm1,%zmm9,%zmm9
    3c46:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    3c4c:	62 71 2c 48 58 d2    	vaddps %zmm2,%zmm10,%zmm10
    3c52:	62 d1 7c 48 10 5b 01 	vmovups 0x40(%r11),%zmm3
    3c59:	62 71 24 48 58 db    	vaddps %zmm3,%zmm11,%zmm11
    3c5f:	62 d1 7c 48 10 24 24 	vmovups (%r12),%zmm4
    3c66:	62 71 1c 48 58 e4    	vaddps %zmm4,%zmm12,%zmm12
    3c6c:	62 d1 7c 48 10 6c 24 	vmovups 0x40(%r12),%zmm5
    3c73:	01 
    3c74:	62 71 14 48 58 ed    	vaddps %zmm5,%zmm13,%zmm13
    3c7a:	62 d1 7c 48 10 75 00 	vmovups 0x0(%r13),%zmm6
    3c81:	62 71 0c 48 58 f6    	vaddps %zmm6,%zmm14,%zmm14
    3c87:	62 d1 7c 48 10 7d 01 	vmovups 0x40(%r13),%zmm7
    3c8e:	62 71 04 48 58 ff    	vaddps %zmm7,%zmm15,%zmm15
    3c94:	4f 8d 54 85 00       	lea    0x0(%r13,%r8,4),%r10
    3c99:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    3c9d:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    3ca1:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13
    3ca5:	62 d1 7c 48 10 02    	vmovups (%r10),%zmm0
    3cab:	62 e1 7c 40 58 c0    	vaddps %zmm0,%zmm16,%zmm16
    3cb1:	62 d1 7c 48 10 4a 01 	vmovups 0x40(%r10),%zmm1
    3cb8:	62 e1 74 40 58 c9    	vaddps %zmm1,%zmm17,%zmm17
    3cbe:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    3cc4:	62 e1 6c 40 58 d2    	vaddps %zmm2,%zmm18,%zmm18
    3cca:	62 d1 7c 48 10 5b 01 	vmovups 0x40(%r11),%zmm3
    3cd1:	62 e1 64 40 58 db    	vaddps %zmm3,%zmm19,%zmm19
    3cd7:	62 d1 7c 48 10 24 24 	vmovups (%r12),%zmm4
    3cde:	62 e1 5c 40 58 e4    	vaddps %zmm4,%zmm20,%zmm20
    3ce4:	62 d1 7c 48 10 6c 24 	vmovups 0x40(%r12),%zmm5
    3ceb:	01 
    3cec:	62 e1 54 40 58 ed    	vaddps %zmm5,%zmm21,%zmm21
    3cf2:	62 d1 7c 48 10 75 00 	vmovups 0x0(%r13),%zmm6
    3cf9:	62 e1 4c 40 58 f6    	vaddps %zmm6,%zmm22,%zmm22
    3cff:	62 d1 7c 48 10 7d 01 	vmovups 0x40(%r13),%zmm7
    3d06:	62 e1 44 40 58 ff    	vaddps %zmm7,%zmm23,%zmm23
    3d0c:	4f 8d 54 85 00       	lea    0x0(%r13,%r8,4),%r10
    3d11:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    3d15:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    3d19:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13
    3d1d:	62 d1 7c 48 10 02    	vmovups (%r10),%zmm0
    3d23:	62 61 3c 40 58 c0    	vaddps %zmm0,%zmm24,%zmm24
    3d29:	62 d1 7c 48 10 4a 01 	vmovups 0x40(%r10),%zmm1
    3d30:	62 61 34 40 58 c9    	vaddps %zmm1,%zmm25,%zmm25
    3d36:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    3d3c:	62 61 2c 40 58 d2    	vaddps %zmm2,%zmm26,%zmm26
    3d42:	62 d1 7c 48 10 5b 01 	vmovups 0x40(%r11),%zmm3
    3d49:	62 61 24 40 58 db    	vaddps %zmm3,%zmm27,%zmm27
    3d4f:	62 d1 7c 48 10 24 24 	vmovups (%r12),%zmm4
    3d56:	62 61 1c 40 58 e4    	vaddps %zmm4,%zmm28,%zmm28
    3d5c:	62 d1 7c 48 10 6c 24 	vmovups 0x40(%r12),%zmm5
    3d63:	01 
    3d64:	62 61 14 40 58 ed    	vaddps %zmm5,%zmm29,%zmm29
    3d6a:	62 d1 7c 48 10 75 00 	vmovups 0x0(%r13),%zmm6
    3d71:	62 61 0c 40 58 f6    	vaddps %zmm6,%zmm30,%zmm30
    3d77:	62 d1 7c 48 10 7d 01 	vmovups 0x40(%r13),%zmm7
    3d7e:	62 61 04 40 58 ff    	vaddps %zmm7,%zmm31,%zmm31
    3d84:	49 89 ca             	mov    %rcx,%r10
    3d87:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    3d8b:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    3d8f:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13

0000000000003d93 <BF16_SAVE_C_M12N32>:
    3d93:	62 51 7c 48 11 02    	vmovups %zmm8,(%r10)
    3d99:	62 51 7c 48 11 4a 01 	vmovups %zmm9,0x40(%r10)
    3da0:	62 51 7c 48 11 13    	vmovups %zmm10,(%r11)
    3da6:	62 51 7c 48 11 5b 01 	vmovups %zmm11,0x40(%r11)
    3dad:	62 51 7c 48 11 24 24 	vmovups %zmm12,(%r12)
    3db4:	62 51 7c 48 11 6c 24 	vmovups %zmm13,0x40(%r12)
    3dbb:	01 
    3dbc:	62 51 7c 48 11 75 00 	vmovups %zmm14,0x0(%r13)
    3dc3:	62 51 7c 48 11 7d 01 	vmovups %zmm15,0x40(%r13)
    3dca:	4f 8d 54 85 00       	lea    0x0(%r13,%r8,4),%r10
    3dcf:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    3dd3:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    3dd7:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13
    3ddb:	62 c1 7c 48 11 02    	vmovups %zmm16,(%r10)
    3de1:	62 c1 7c 48 11 4a 01 	vmovups %zmm17,0x40(%r10)
    3de8:	62 c1 7c 48 11 13    	vmovups %zmm18,(%r11)
    3dee:	62 c1 7c 48 11 5b 01 	vmovups %zmm19,0x40(%r11)
    3df5:	62 c1 7c 48 11 24 24 	vmovups %zmm20,(%r12)
    3dfc:	62 c1 7c 48 11 6c 24 	vmovups %zmm21,0x40(%r12)
    3e03:	01 
    3e04:	62 c1 7c 48 11 75 00 	vmovups %zmm22,0x0(%r13)
    3e0b:	62 c1 7c 48 11 7d 01 	vmovups %zmm23,0x40(%r13)
    3e12:	4f 8d 54 85 00       	lea    0x0(%r13,%r8,4),%r10
    3e17:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    3e1b:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    3e1f:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13
    3e23:	62 41 7c 48 11 02    	vmovups %zmm24,(%r10)
    3e29:	62 41 7c 48 11 4a 01 	vmovups %zmm25,0x40(%r10)
    3e30:	62 41 7c 48 11 13    	vmovups %zmm26,(%r11)
    3e36:	62 41 7c 48 11 5b 01 	vmovups %zmm27,0x40(%r11)
    3e3d:	48 83 ef 0c          	sub    $0xc,%rdi
    3e41:	62 41 7c 48 11 24 24 	vmovups %zmm28,(%r12)
    3e48:	62 41 7c 48 11 6c 24 	vmovups %zmm29,0x40(%r12)
    3e4f:	01 
    3e50:	62 41 7c 48 11 75 00 	vmovups %zmm30,0x0(%r13)
    3e57:	62 41 7c 48 11 7d 01 	vmovups %zmm31,0x40(%r13)
    3e5e:	4b 8d 4c 85 00       	lea    0x0(%r13,%r8,4),%rcx
    3e63:	e9 aa f3 ff ff       	jmp    3212 <BF16_BEGIN_M12>

0000000000003e68 <BF16_BEGIN_M8>:
    3e68:	48 83 ff 08          	cmp    $0x8,%rdi
    3e6c:	0f 82 b0 08 00 00    	jb     4722 <BF16_BEGIN_M4>
    3e72:	4c 89 f3             	mov    %r14,%rbx
    3e75:	48 89 f2             	mov    %rsi,%rdx
    3e78:	62 f1 7c 48 10 23    	vmovups (%rbx),%zmm4
    3e7e:	62 f1 7c 48 10 6b 01 	vmovups 0x40(%rbx),%zmm5
    3e85:	62 51 bd 48 ef c0    	vpxorq %zmm8,%zmm8,%zmm8
    3e8b:	62 51 b5 48 ef c9    	vpxorq %zmm9,%zmm9,%zmm9
    3e91:	62 51 ad 48 ef d2    	vpxorq %zmm10,%zmm10,%zmm10
    3e97:	62 51 a5 48 ef db    	vpxorq %zmm11,%zmm11,%zmm11
    3e9d:	62 51 bd 48 ef c0    	vpxorq %zmm8,%zmm8,%zmm8
    3ea3:	62 51 95 48 ef ed    	vpxorq %zmm13,%zmm13,%zmm13
    3ea9:	62 51 8d 48 ef f6    	vpxorq %zmm14,%zmm14,%zmm14
    3eaf:	62 51 85 48 ef ff    	vpxorq %zmm15,%zmm15,%zmm15
    3eb5:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    3ebb:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    3ec2:	62 a1 fd 40 ef c0    	vpxorq %zmm16,%zmm16,%zmm16
    3ec8:	62 a1 f5 40 ef c9    	vpxorq %zmm17,%zmm17,%zmm17
    3ece:	62 a1 ed 40 ef d2    	vpxorq %zmm18,%zmm18,%zmm18
    3ed4:	62 a1 e5 40 ef db    	vpxorq %zmm19,%zmm19,%zmm19
    3eda:	62 a1 dd 40 ef e4    	vpxorq %zmm20,%zmm20,%zmm20
    3ee0:	62 a1 d5 40 ef ed    	vpxorq %zmm21,%zmm21,%zmm21
    3ee6:	62 a1 cd 40 ef f6    	vpxorq %zmm22,%zmm22,%zmm22
    3eec:	62 a1 c5 40 ef ff    	vpxorq %zmm23,%zmm23,%zmm23
    3ef2:	49 89 cd             	mov    %rcx,%r13
    3ef5:	48 83 ea 10          	sub    $0x10,%rdx

0000000000003ef9 <BF16_MAIN_K_M8N32>:
    3ef9:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    3f00:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    3f06:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    3f0c:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    3f13:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    3f19:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    3f1f:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3f26:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    3f2d:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    3f31:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    3f38:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    3f3e:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    3f44:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    3f4a:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    3f51:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    3f57:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    3f5d:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    3f64:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    3f6a:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    3f70:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    3f77:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    3f7e:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    3f84:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    3f8a:	48 83 c0 20          	add    $0x20,%rax
    3f8e:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    3f94:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    3f9a:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    3fa0:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    3fa7:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    3fad:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    3fb3:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    3fba:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    3fc0:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    3fc6:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    3fcd:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    3fd3:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    3fd9:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    3fe0:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    3fe7:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    3feb:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    3ff2:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    3ff8:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    3ffe:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    4005:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    400b:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    4011:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    4018:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    401e:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    4024:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    402a:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    4031:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    4037:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    403d:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    4044:	48 83 c0 20          	add    $0x20,%rax
    4048:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    404e:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    4054:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    405a:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    4061:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    4067:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23
    406d:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4074:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    407a:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    4080:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4087:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    408d:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    4093:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    409a:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    40a1:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    40a5:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    40ac:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    40b2:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    40b8:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    40be:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    40c5:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    40cb:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    40d1:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    40d8:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    40de:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    40e4:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    40eb:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    40f2:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    40f8:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    40fe:	48 83 c0 20          	add    $0x20,%rax
    4102:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    4108:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    410e:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    4114:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    411b:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    4121:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    4127:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    412e:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    4134:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    413a:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4141:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    4147:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    414d:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4154:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    415b:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    415f:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    4166:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    416c:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    4172:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    4179:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    417f:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    4185:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    418c:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    4192:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    4198:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    419e:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    41a5:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    41ab:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    41b1:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    41b8:	48 83 c0 20          	add    $0x20,%rax
    41bc:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    41c2:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    41c8:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    41ce:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    41d5:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    41db:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23
    41e1:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    41e8:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    41ee:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    41f4:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    41fb:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    4201:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    4207:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    420e:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    4215:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    4219:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    4220:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    4226:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    422c:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    4232:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    4239:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    423f:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    4245:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    424c:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    4252:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    4258:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    425f:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    4266:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    426c:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    4272:	48 83 c0 20          	add    $0x20,%rax
    4276:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    427c:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    4282:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    4288:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    428f:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    4295:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    429b:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    42a2:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    42a8:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    42ae:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    42b5:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    42bb:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    42c1:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    42c8:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    42cf:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    42d3:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    42da:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    42e0:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    42e6:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    42ed:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    42f3:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    42f9:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    4300:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    4306:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    430c:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    4312:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    4319:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    431f:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    4325:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    432c:	48 83 c0 20          	add    $0x20,%rax
    4330:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    4336:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    433c:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    4342:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    4349:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    434f:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23
    4355:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    435c:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    4362:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    4368:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    436f:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    4375:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    437b:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4382:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    4389:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    438d:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    4394:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    439a:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    43a0:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    43a6:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    43ad:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    43b3:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    43b9:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    43c0:	62 e2 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm16
    43c6:	62 e2 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm17
    43cc:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    43d3:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    43da:	62 e2 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm18
    43e0:	62 e2 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm19
    43e6:	48 83 c0 20          	add    $0x20,%rax
    43ea:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    43f0:	62 e2 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm20
    43f6:	62 e2 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm21
    43fc:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    4403:	62 e2 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm22
    4409:	62 e2 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm23
    440f:	48 83 fa 00          	cmp    $0x0,%rdx
    4413:	0f 84 e0 00 00 00    	je     44f9 <BF16_MAIN_K_M8N32_EDGE>
    4419:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4420:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    4426:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    442c:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4433:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    4439:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    443f:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4446:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    444d:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    4451:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    4458:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    445e:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    4464:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    446b:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    4471:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    4477:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    447e:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    4484:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    448a:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    4490:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    4497:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    449d:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    44a3:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    44aa:	48 83 c0 20          	add    $0x20,%rax
    44ae:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    44b4:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    44ba:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    44c0:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    44c7:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    44cd:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23
    44d3:	48 83 ea 10          	sub    $0x10,%rdx
    44d7:	48 81 fa 80 00 00 00 	cmp    $0x80,%rdx
    44de:	76 05                	jbe    44e5 <BF16_K_PREFETCH_C_M8N32>
    44e0:	e9 14 fa ff ff       	jmp    3ef9 <BF16_MAIN_K_M8N32>

00000000000044e5 <BF16_K_PREFETCH_C_M8N32>:
    44e5:	41 0f 18 5d 00       	prefetcht2 0x0(%r13)
    44ea:	41 0f 18 5d 40       	prefetcht2 0x40(%r13)
    44ef:	4f 8d 6c 85 00       	lea    0x0(%r13,%r8,4),%r13
    44f4:	e9 00 fa ff ff       	jmp    3ef9 <BF16_MAIN_K_M8N32>

00000000000044f9 <BF16_MAIN_K_M8N32_EDGE>:
    44f9:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4500:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    4506:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    450c:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4513:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    4519:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    451f:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4526:	62 f2 7d 48 18 40 04 	vbroadcastss 0x10(%rax),%zmm0
    452d:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    4533:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    4539:	62 f2 7d 48 18 48 05 	vbroadcastss 0x14(%rax),%zmm1
    4540:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    4546:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    454c:	62 f2 7d 48 18 50 06 	vbroadcastss 0x18(%rax),%zmm2
    4553:	62 e2 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm16
    4559:	62 e2 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm17
    455f:	62 f2 7d 48 18 58 07 	vbroadcastss 0x1c(%rax),%zmm3
    4566:	62 e2 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm18
    456c:	62 e2 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm19
    4572:	48 83 c0 20          	add    $0x20,%rax
    4576:	62 e2 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm20
    457c:	62 e2 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm21
    4582:	62 e2 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm22
    4588:	62 e2 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm23

000000000000458e <BF16_BEGIN_SAVE_M8N32>:
    458e:	49 89 ca             	mov    %rcx,%r10
    4591:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    4595:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    4599:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13
    459d:	49 83 ff 00          	cmp    $0x0,%r15
    45a1:	0f 84 ee 00 00 00    	je     4695 <BF16_SAVE_C_M8N32>
    45a7:	62 d1 7c 48 10 02    	vmovups (%r10),%zmm0
    45ad:	62 71 3c 48 58 c0    	vaddps %zmm0,%zmm8,%zmm8
    45b3:	62 d1 7c 48 10 4a 01 	vmovups 0x40(%r10),%zmm1
    45ba:	62 71 34 48 58 c9    	vaddps %zmm1,%zmm9,%zmm9
    45c0:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    45c6:	62 71 2c 48 58 d2    	vaddps %zmm2,%zmm10,%zmm10
    45cc:	62 d1 7c 48 10 5b 01 	vmovups 0x40(%r11),%zmm3
    45d3:	62 71 24 48 58 db    	vaddps %zmm3,%zmm11,%zmm11
    45d9:	62 d1 7c 48 10 24 24 	vmovups (%r12),%zmm4
    45e0:	62 71 1c 48 58 e4    	vaddps %zmm4,%zmm12,%zmm12
    45e6:	62 d1 7c 48 10 6c 24 	vmovups 0x40(%r12),%zmm5
    45ed:	01 
    45ee:	62 71 14 48 58 ed    	vaddps %zmm5,%zmm13,%zmm13
    45f4:	62 d1 7c 48 10 75 00 	vmovups 0x0(%r13),%zmm6
    45fb:	62 71 0c 48 58 f6    	vaddps %zmm6,%zmm14,%zmm14
    4601:	62 d1 7c 48 10 7d 01 	vmovups 0x40(%r13),%zmm7
    4608:	62 71 04 48 58 ff    	vaddps %zmm7,%zmm15,%zmm15
    460e:	4f 8d 54 85 00       	lea    0x0(%r13,%r8,4),%r10
    4613:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    4617:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    461b:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13
    461f:	62 d1 7c 48 10 02    	vmovups (%r10),%zmm0
    4625:	62 e1 7c 40 58 c0    	vaddps %zmm0,%zmm16,%zmm16
    462b:	62 d1 7c 48 10 4a 01 	vmovups 0x40(%r10),%zmm1
    4632:	62 e1 74 40 58 c9    	vaddps %zmm1,%zmm17,%zmm17
    4638:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    463e:	62 e1 6c 40 58 d2    	vaddps %zmm2,%zmm18,%zmm18
    4644:	62 d1 7c 48 10 5b 01 	vmovups 0x40(%r11),%zmm3
    464b:	62 e1 64 40 58 db    	vaddps %zmm3,%zmm19,%zmm19
    4651:	62 d1 7c 48 10 24 24 	vmovups (%r12),%zmm4
    4658:	62 e1 5c 40 58 e4    	vaddps %zmm4,%zmm20,%zmm20
    465e:	62 d1 7c 48 10 6c 24 	vmovups 0x40(%r12),%zmm5
    4665:	01 
    4666:	62 e1 54 40 58 ed    	vaddps %zmm5,%zmm21,%zmm21
    466c:	62 d1 7c 48 10 75 00 	vmovups 0x0(%r13),%zmm6
    4673:	62 e1 4c 40 58 f6    	vaddps %zmm6,%zmm22,%zmm22
    4679:	62 d1 7c 48 10 7d 01 	vmovups 0x40(%r13),%zmm7
    4680:	62 e1 44 40 58 ff    	vaddps %zmm7,%zmm23,%zmm23
    4686:	49 89 ca             	mov    %rcx,%r10
    4689:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    468d:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    4691:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13

0000000000004695 <BF16_SAVE_C_M8N32>:
    4695:	62 51 7c 48 11 02    	vmovups %zmm8,(%r10)
    469b:	62 51 7c 48 11 4a 01 	vmovups %zmm9,0x40(%r10)
    46a2:	62 51 7c 48 11 13    	vmovups %zmm10,(%r11)
    46a8:	62 51 7c 48 11 5b 01 	vmovups %zmm11,0x40(%r11)
    46af:	62 51 7c 48 11 24 24 	vmovups %zmm12,(%r12)
    46b6:	62 51 7c 48 11 6c 24 	vmovups %zmm13,0x40(%r12)
    46bd:	01 
    46be:	62 51 7c 48 11 75 00 	vmovups %zmm14,0x0(%r13)
    46c5:	62 51 7c 48 11 7d 01 	vmovups %zmm15,0x40(%r13)
    46cc:	4f 8d 54 85 00       	lea    0x0(%r13,%r8,4),%r10
    46d1:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    46d5:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    46d9:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13
    46dd:	62 c1 7c 48 11 02    	vmovups %zmm16,(%r10)
    46e3:	62 c1 7c 48 11 4a 01 	vmovups %zmm17,0x40(%r10)
    46ea:	62 c1 7c 48 11 13    	vmovups %zmm18,(%r11)
    46f0:	62 c1 7c 48 11 5b 01 	vmovups %zmm19,0x40(%r11)
    46f7:	62 c1 7c 48 11 24 24 	vmovups %zmm20,(%r12)
    46fe:	62 c1 7c 48 11 6c 24 	vmovups %zmm21,0x40(%r12)
    4705:	01 
    4706:	62 c1 7c 48 11 75 00 	vmovups %zmm22,0x0(%r13)
    470d:	62 c1 7c 48 11 7d 01 	vmovups %zmm23,0x40(%r13)
    4714:	48 83 ef 08          	sub    $0x8,%rdi
    4718:	4b 8d 4c 85 00       	lea    0x0(%r13,%r8,4),%rcx
    471d:	e9 51 05 00 00       	jmp    4c73 <BF16_END_N32>

0000000000004722 <BF16_BEGIN_M4>:
    4722:	48 83 ff 04          	cmp    $0x4,%rdi
    4726:	0f 82 47 05 00 00    	jb     4c73 <BF16_END_N32>
    472c:	4c 89 f3             	mov    %r14,%rbx
    472f:	48 89 f2             	mov    %rsi,%rdx
    4732:	62 f1 7c 48 10 23    	vmovups (%rbx),%zmm4
    4738:	62 f1 7c 48 10 6b 01 	vmovups 0x40(%rbx),%zmm5
    473f:	62 f1 dd 48 ef e4    	vpxorq %zmm4,%zmm4,%zmm4
    4745:	62 51 b5 48 ef c9    	vpxorq %zmm9,%zmm9,%zmm9
    474b:	62 51 ad 48 ef d2    	vpxorq %zmm10,%zmm10,%zmm10
    4751:	62 51 a5 48 ef db    	vpxorq %zmm11,%zmm11,%zmm11
    4757:	62 f1 dd 48 ef e4    	vpxorq %zmm4,%zmm4,%zmm4
    475d:	62 51 95 48 ef ed    	vpxorq %zmm13,%zmm13,%zmm13
    4763:	62 51 8d 48 ef f6    	vpxorq %zmm14,%zmm14,%zmm14
    4769:	62 51 85 48 ef ff    	vpxorq %zmm15,%zmm15,%zmm15
    476f:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    4775:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    477c:	62 a1 fd 40 ef c0    	vpxorq %zmm16,%zmm16,%zmm16
    4782:	62 a1 f5 40 ef c9    	vpxorq %zmm17,%zmm17,%zmm17
    4788:	62 a1 ed 40 ef d2    	vpxorq %zmm18,%zmm18,%zmm18
    478e:	62 a1 e5 40 ef db    	vpxorq %zmm19,%zmm19,%zmm19
    4794:	62 a1 dd 40 ef e4    	vpxorq %zmm20,%zmm20,%zmm20
    479a:	62 a1 d5 40 ef ed    	vpxorq %zmm21,%zmm21,%zmm21
    47a0:	62 a1 cd 40 ef f6    	vpxorq %zmm22,%zmm22,%zmm22
    47a6:	62 a1 c5 40 ef ff    	vpxorq %zmm23,%zmm23,%zmm23
    47ac:	49 89 cd             	mov    %rcx,%r13
    47af:	48 83 ea 10          	sub    $0x10,%rdx

00000000000047b3 <BF16_MAIN_K_M4N32>:
    47b3:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    47ba:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    47c0:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    47c6:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    47cd:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    47d1:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    47d7:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    47de:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    47e4:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    47ea:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    47f1:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    47f8:	48 83 c0 10          	add    $0x10,%rax
    47fc:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    4802:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    4808:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    480e:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    4815:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    481b:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    4821:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4828:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    482e:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    4834:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    483b:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    483f:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    4845:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    484c:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    4852:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    4858:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    485f:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4866:	48 83 c0 10          	add    $0x10,%rax
    486a:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    4870:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    4876:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    487c:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    4883:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    4889:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    488f:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4896:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    489c:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    48a2:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    48a9:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    48ad:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    48b3:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    48ba:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    48c0:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    48c6:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    48cd:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    48d4:	48 83 c0 10          	add    $0x10,%rax
    48d8:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    48de:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    48e4:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    48ea:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    48f1:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    48f7:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    48fd:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4904:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    490a:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    4910:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    4917:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    491b:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    4921:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4928:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    492e:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    4934:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    493b:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4942:	48 83 c0 10          	add    $0x10,%rax
    4946:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    494c:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    4952:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    4958:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    495f:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    4965:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    496b:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4972:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    4978:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    497e:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    4985:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    4989:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    498f:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4996:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    499c:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    49a2:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    49a9:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    49b0:	48 83 c0 10          	add    $0x10,%rax
    49b4:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    49ba:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    49c0:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    49c6:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    49cd:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    49d3:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    49d9:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    49e0:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    49e6:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    49ec:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    49f3:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    49f7:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    49fd:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4a04:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    4a0a:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    4a10:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    4a17:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4a1e:	48 83 c0 10          	add    $0x10,%rax
    4a22:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    4a28:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    4a2e:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    4a34:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    4a3b:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    4a41:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    4a47:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4a4e:	62 72 5e 48 52 c0    	vdpbf16ps %zmm0,%zmm4,%zmm8
    4a54:	62 72 56 48 52 c8    	vdpbf16ps %zmm0,%zmm5,%zmm9
    4a5a:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    4a61:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    4a65:	62 f1 ff 48 6f 33    	vmovdqu16 (%rbx),%zmm6
    4a6b:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4a72:	62 72 5e 48 52 d1    	vdpbf16ps %zmm1,%zmm4,%zmm10
    4a78:	62 72 56 48 52 d9    	vdpbf16ps %zmm1,%zmm5,%zmm11
    4a7e:	62 f1 ff 48 6f 7b 01 	vmovdqu16 0x40(%rbx),%zmm7
    4a85:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4a8c:	48 83 c0 10          	add    $0x10,%rax
    4a90:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    4a96:	62 72 5e 48 52 e2    	vdpbf16ps %zmm2,%zmm4,%zmm12
    4a9c:	62 72 56 48 52 ea    	vdpbf16ps %zmm2,%zmm5,%zmm13
    4aa2:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    4aa9:	62 72 5e 48 52 f3    	vdpbf16ps %zmm3,%zmm4,%zmm14
    4aaf:	62 72 56 48 52 fb    	vdpbf16ps %zmm3,%zmm5,%zmm15
    4ab5:	48 83 fa 00          	cmp    $0x0,%rdx
    4ab9:	0f 84 91 00 00 00    	je     4b50 <BF16_MAIN_K_M4N32_EDGE>
    4abf:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4ac6:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    4acc:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    4ad2:	48 81 c3 80 00 00 00 	add    $0x80,%rbx
    4ad9:	0f 18 4b 40          	prefetcht0 0x40(%rbx)
    4add:	62 f1 ff 48 6f 23    	vmovdqu16 (%rbx),%zmm4
    4ae3:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4aea:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    4af0:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    4af6:	62 f1 ff 48 6f 6b 01 	vmovdqu16 0x40(%rbx),%zmm5
    4afd:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4b04:	48 83 c0 10          	add    $0x10,%rax
    4b08:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    4b0e:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    4b14:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    4b1a:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    4b21:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    4b27:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15
    4b2d:	48 83 ea 10          	sub    $0x10,%rdx
    4b31:	48 83 fa 40          	cmp    $0x40,%rdx
    4b35:	76 05                	jbe    4b3c <BF16_K_PREFETCH_C_M4N32>
    4b37:	e9 77 fc ff ff       	jmp    47b3 <BF16_MAIN_K_M4N32>

0000000000004b3c <BF16_K_PREFETCH_C_M4N32>:
    4b3c:	41 0f 18 5d 00       	prefetcht2 0x0(%r13)
    4b41:	41 0f 18 5d 40       	prefetcht2 0x40(%r13)
    4b46:	4f 8d 6c 85 00       	lea    0x0(%r13,%r8,4),%r13
    4b4b:	e9 63 fc ff ff       	jmp    47b3 <BF16_MAIN_K_M4N32>

0000000000004b50 <BF16_MAIN_K_M4N32_EDGE>:
    4b50:	62 f2 7d 48 18 50 02 	vbroadcastss 0x8(%rax),%zmm2
    4b57:	62 72 4e 48 52 c0    	vdpbf16ps %zmm0,%zmm6,%zmm8
    4b5d:	62 72 46 48 52 c8    	vdpbf16ps %zmm0,%zmm7,%zmm9
    4b63:	62 f2 7d 48 18 58 03 	vbroadcastss 0xc(%rax),%zmm3
    4b6a:	62 72 4e 48 52 d1    	vdpbf16ps %zmm1,%zmm6,%zmm10
    4b70:	62 72 46 48 52 d9    	vdpbf16ps %zmm1,%zmm7,%zmm11
    4b76:	0f 18 88 00 01 00 00 	prefetcht0 0x100(%rax)
    4b7d:	48 83 c0 10          	add    $0x10,%rax
    4b81:	62 f2 7d 48 18 00    	vbroadcastss (%rax),%zmm0
    4b87:	62 72 4e 48 52 e2    	vdpbf16ps %zmm2,%zmm6,%zmm12
    4b8d:	62 72 46 48 52 ea    	vdpbf16ps %zmm2,%zmm7,%zmm13
    4b93:	62 f2 7d 48 18 48 01 	vbroadcastss 0x4(%rax),%zmm1
    4b9a:	62 72 4e 48 52 f3    	vdpbf16ps %zmm3,%zmm6,%zmm14
    4ba0:	62 72 46 48 52 fb    	vdpbf16ps %zmm3,%zmm7,%zmm15

0000000000004ba6 <BF16_BEGIN_SAVE_M4N32>:
    4ba6:	49 89 ca             	mov    %rcx,%r10
    4ba9:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    4bad:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    4bb1:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13
    4bb5:	49 83 ff 00          	cmp    $0x0,%r15
    4bb9:	74 76                	je     4c31 <BF16_SAVE_C_M4N32>
    4bbb:	62 d1 7c 48 10 02    	vmovups (%r10),%zmm0
    4bc1:	62 71 3c 48 58 c0    	vaddps %zmm0,%zmm8,%zmm8
    4bc7:	62 d1 7c 48 10 4a 01 	vmovups 0x40(%r10),%zmm1
    4bce:	62 71 34 48 58 c9    	vaddps %zmm1,%zmm9,%zmm9
    4bd4:	62 d1 7c 48 10 13    	vmovups (%r11),%zmm2
    4bda:	62 71 2c 48 58 d2    	vaddps %zmm2,%zmm10,%zmm10
    4be0:	62 d1 7c 48 10 5b 01 	vmovups 0x40(%r11),%zmm3
    4be7:	62 71 24 48 58 db    	vaddps %zmm3,%zmm11,%zmm11
    4bed:	62 d1 7c 48 10 24 24 	vmovups (%r12),%zmm4
    4bf4:	62 71 1c 48 58 e4    	vaddps %zmm4,%zmm12,%zmm12
    4bfa:	62 d1 7c 48 10 6c 24 	vmovups 0x40(%r12),%zmm5
    4c01:	01 
    4c02:	62 71 14 48 58 ed    	vaddps %zmm5,%zmm13,%zmm13
    4c08:	62 d1 7c 48 10 75 00 	vmovups 0x0(%r13),%zmm6
    4c0f:	62 71 0c 48 58 f6    	vaddps %zmm6,%zmm14,%zmm14
    4c15:	62 d1 7c 48 10 7d 01 	vmovups 0x40(%r13),%zmm7
    4c1c:	62 71 04 48 58 ff    	vaddps %zmm7,%zmm15,%zmm15
    4c22:	49 89 ca             	mov    %rcx,%r10
    4c25:	4f 8d 1c 82          	lea    (%r10,%r8,4),%r11
    4c29:	4f 8d 24 83          	lea    (%r11,%r8,4),%r12
    4c2d:	4f 8d 2c 84          	lea    (%r12,%r8,4),%r13

0000000000004c31 <BF16_SAVE_C_M4N32>:
    4c31:	62 51 7c 48 11 02    	vmovups %zmm8,(%r10)
    4c37:	62 51 7c 48 11 4a 01 	vmovups %zmm9,0x40(%r10)
    4c3e:	62 51 7c 48 11 13    	vmovups %zmm10,(%r11)
    4c44:	62 51 7c 48 11 5b 01 	vmovups %zmm11,0x40(%r11)
    4c4b:	62 51 7c 48 11 24 24 	vmovups %zmm12,(%r12)
    4c52:	62 51 7c 48 11 6c 24 	vmovups %zmm13,0x40(%r12)
    4c59:	01 
    4c5a:	62 51 7c 48 11 75 00 	vmovups %zmm14,0x0(%r13)
    4c61:	62 51 7c 48 11 7d 01 	vmovups %zmm15,0x40(%r13)
    4c68:	48 83 ef 04          	sub    $0x4,%rdi
    4c6c:	4b 8d 4c 85 00       	lea    0x0(%r13,%r8,4),%rcx
    4c71:	eb 00                	jmp    4c73 <BF16_END_N32>

0000000000004c73 <BF16_END_N32>:
    4c73:	e9 b8 d7 ff ff       	jmp    2430 <GEMM_BF16._omp_fn.0+0x260>
    4c78:	0f 1f 84 00 00 00 00 	nopl   0x0(%rax,%rax,1)
    4c7f:	00 
    4c80:	48 8b 4c 24 28       	mov    0x28(%rsp),%rcx
    4c85:	48 8b 74 24 30       	mov    0x30(%rsp),%rsi
		for (kk = 0; kk < K; kk = kk + kc)
    4c8a:	48 01 f1             	add    %rsi,%rcx
    4c8d:	48 39 4c 24 38       	cmp    %rcx,0x38(%rsp)
    4c92:	0f 8f 30 d7 ff ff    	jg     23c8 <GEMM_BF16._omp_fn.0+0x1f8>
    4c98:	c5 f8 77             	vzeroupper
#pragma omp parallel num_threads(NUM)
    4c9b:	48 8b 84 24 c8 00 00 	mov    0xc8(%rsp),%rax
    4ca2:	00 
    4ca3:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    4caa:	00 00 
    4cac:	75 12                	jne    4cc0 <BF16_END_N32+0x4d>
    4cae:	48 81 c4 d8 00 00 00 	add    $0xd8,%rsp
    4cb5:	5b                   	pop    %rbx
    4cb6:	5d                   	pop    %rbp
    4cb7:	41 5c                	pop    %r12
    4cb9:	41 5d                	pop    %r13
    4cbb:	41 5e                	pop    %r14
    4cbd:	41 5f                	pop    %r15
    4cbf:	c3                   	ret
    4cc0:	e8 cb c4 ff ff       	call   1190 <__stack_chk_fail@plt>
    4cc5:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    4ccc:	00 00 00 00 

0000000000004cd0 <flashgemm_set_thread_num>:
{
    4cd0:	f3 0f 1e fa          	endbr64
	flashgemm_thread_num = num;
    4cd4:	89 3d 36 33 00 00    	mov    %edi,0x3336(%rip)        # 8010 <flashgemm_thread_num>
}
    4cda:	c3                   	ret
    4cdb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000004ce0 <GEMM_BF16>:
{
    4ce0:	f3 0f 1e fa          	endbr64
    4ce4:	41 57                	push   %r15
    4ce6:	41 56                	push   %r14
    4ce8:	41 55                	push   %r13
    4cea:	4d 89 cd             	mov    %r9,%r13
    4ced:	41 54                	push   %r12
    4cef:	49 89 cc             	mov    %rcx,%r12
    4cf2:	55                   	push   %rbp
    4cf3:	53                   	push   %rbx
    4cf4:	4c 89 c3             	mov    %r8,%rbx
    4cf7:	48 81 ec a8 00 00 00 	sub    $0xa8,%rsp
    4cfe:	48 89 3c 24          	mov    %rdi,(%rsp)
	posix_memalign(&ptrA, 64, M * K * sizeof(uint16_t));
    4d02:	48 8d 7c 24 20       	lea    0x20(%rsp),%rdi
{
    4d07:	48 89 74 24 08       	mov    %rsi,0x8(%rsp)
	int NUM = flashgemm_thread_num;
    4d0c:	48 63 35 fd 32 00 00 	movslq 0x32fd(%rip),%rsi        # 8010 <flashgemm_thread_num>
{
    4d13:	48 89 54 24 10       	mov    %rdx,0x10(%rsp)
	int NUM = flashgemm_thread_num;
    4d18:	48 89 f5             	mov    %rsi,%rbp
{
    4d1b:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    4d22:	00 00 
    4d24:	48 89 84 24 98 00 00 	mov    %rax,0x98(%rsp)
    4d2b:	00 
    4d2c:	31 c0                	xor    %eax,%eax
	long Nb = N / NUM;
    4d2e:	4c 89 c0             	mov    %r8,%rax
    4d31:	48 99                	cqto
    4d33:	48 f7 fe             	idiv   %rsi
	posix_memalign(&ptrA, 64, M * K * sizeof(uint16_t));
    4d36:	48 89 ca             	mov    %rcx,%rdx
    4d39:	be 40 00 00 00       	mov    $0x40,%esi
    4d3e:	49 0f af d1          	imul   %r9,%rdx
    4d42:	48 01 d2             	add    %rdx,%rdx
	long Nb = N / NUM;
    4d45:	48 89 44 24 18       	mov    %rax,0x18(%rsp)
	posix_memalign(&ptrA, 64, M * K * sizeof(uint16_t));
    4d4a:	e8 a1 c4 ff ff       	call   11f0 <posix_memalign@plt>
    4d4f:	85 c0                	test   %eax,%eax
    4d51:	75 05                	jne    4d58 <GEMM_BF16+0x78>
    4d53:	4c 8b 74 24 20       	mov    0x20(%rsp),%r14
	posix_memalign(&ptrB, 64, NUM * GEMM_K * 32 * sizeof(uint16_t));
    4d58:	89 ea                	mov    %ebp,%edx
    4d5a:	48 8d 7c 24 28       	lea    0x28(%rsp),%rdi
    4d5f:	be 40 00 00 00       	mov    $0x40,%esi
    4d64:	c1 e2 0f             	shl    $0xf,%edx
    4d67:	48 63 d2             	movslq %edx,%rdx
    4d6a:	48 01 d2             	add    %rdx,%rdx
    4d6d:	e8 7e c4 ff ff       	call   11f0 <posix_memalign@plt>
    4d72:	85 c0                	test   %eax,%eax
    4d74:	75 05                	jne    4d7b <GEMM_BF16+0x9b>
    4d76:	4c 8b 7c 24 28       	mov    0x28(%rsp),%r15
	int Num_K_block = K / GEMM_K;
    4d7b:	4d 85 ed             	test   %r13,%r13
    4d7e:	4d 8d 85 ff 03 00 00 	lea    0x3ff(%r13),%r8
	int Edge_K = (K % GEMM_K) / 2;
    4d85:	4c 89 e8             	mov    %r13,%rax
	int Edge_M = M % 12;
    4d88:	4d 89 e3             	mov    %r12,%r11
	int Num_K_block = K / GEMM_K;
    4d8b:	4d 0f 49 c5          	cmovns %r13,%r8
	int Edge_K = (K % GEMM_K) / 2;
    4d8f:	48 c1 f8 3f          	sar    $0x3f,%rax
    4d93:	48 c1 e8 36          	shr    $0x36,%rax
    4d97:	49 8d 7c 05 00       	lea    0x0(%r13,%rax,1),%rdi
	int Num_K_block = K / GEMM_K;
    4d9c:	49 c1 f8 0a          	sar    $0xa,%r8
	int Edge_K = (K % GEMM_K) / 2;
    4da0:	81 e7 ff 03 00 00    	and    $0x3ff,%edi
    4da6:	48 29 c7             	sub    %rax,%rdi
	int Num_M_block = M / 12;
    4da9:	48 b8 ab aa aa aa aa 	movabs $0x2aaaaaaaaaaaaaab,%rax
    4db0:	aa aa 2a 
    4db3:	49 f7 ec             	imul   %r12
    4db6:	4c 89 e0             	mov    %r12,%rax
	int Edge_K = (K % GEMM_K) / 2;
    4db9:	48 89 fe             	mov    %rdi,%rsi
	int Num_M_block = M / 12;
    4dbc:	48 c1 f8 3f          	sar    $0x3f,%rax
	int Edge_K = (K % GEMM_K) / 2;
    4dc0:	48 c1 ee 3f          	shr    $0x3f,%rsi
    4dc4:	48 01 fe             	add    %rdi,%rsi
	int Num_M_block = M / 12;
    4dc7:	48 d1 fa             	sar    $1,%rdx
	int Edge_K = (K % GEMM_K) / 2;
    4dca:	48 d1 fe             	sar    $1,%rsi
	int Num_M_block = M / 12;
    4dcd:	48 29 c2             	sub    %rax,%rdx
	int Edge_M = M % 12;
    4dd0:	48 8d 04 52          	lea    (%rdx,%rdx,2),%rax
	int Num_M_block = M / 12;
    4dd4:	89 d1                	mov    %edx,%ecx
	int Edge_M = M % 12;
    4dd6:	48 c1 e0 02          	shl    $0x2,%rax
    4dda:	49 29 c3             	sub    %rax,%r11
	int Num_blocks0 = Num_K_block * Num_M_block;
    4ddd:	44 89 c0             	mov    %r8d,%eax
    4de0:	0f af c2             	imul   %edx,%eax
	int Edge_M = M % 12;
    4de3:	45 89 da             	mov    %r11d,%r10d
	if (Edge_M > 0)
    4de6:	4d 85 db             	test   %r11,%r11
    4de9:	7e 06                	jle    4df1 <GEMM_BF16+0x111>
		Num_blocks0 = Num_blocks0 + Num_K_block;
    4deb:	44 01 c0             	add    %r8d,%eax
		Num_M_block = Num_M_block + 1;
    4dee:	8d 4a 01             	lea    0x1(%rdx),%ecx
		Num_blocks = Num_blocks0 + Num_M_block;
    4df1:	48 83 ff 01          	cmp    $0x1,%rdi
    4df5:	8d 14 01             	lea    (%rcx,%rax,1),%edx
#pragma omp parallel num_threads(NUM)
    4df8:	89 84 24 88 00 00 00 	mov    %eax,0x88(%rsp)
    4dff:	c5 f9 6e c1          	vmovd  %ecx,%xmm0
		Num_blocks = Num_blocks0 + Num_M_block;
    4e03:	0f 4e d0             	cmovle %eax,%edx
#pragma omp parallel num_threads(NUM)
    4e06:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    4e0b:	31 c9                	xor    %ecx,%ecx
    4e0d:	c5 f9 6e dd          	vmovd  %ebp,%xmm3
    4e11:	c4 e3 61 22 ce 01    	vpinsrd $0x1,%esi,%xmm3,%xmm1
    4e17:	c4 c3 79 22 d2 01    	vpinsrd $0x1,%r10d,%xmm0,%xmm2
    4e1d:	4c 89 7c 24 70       	mov    %r15,0x70(%rsp)
    4e22:	48 89 44 24 60       	mov    %rax,0x60(%rsp)
    4e27:	48 8b 44 24 18       	mov    0x18(%rsp),%rax
    4e2c:	c5 f1 6c ca          	vpunpcklqdq %xmm2,%xmm1,%xmm1
    4e30:	48 8d 3d 99 d3 ff ff 	lea    -0x2c67(%rip),%rdi        # 21d0 <GEMM_BF16._omp_fn.0>
    4e37:	89 94 24 8c 00 00 00 	mov    %edx,0x8c(%rsp)
    4e3e:	48 8d 74 24 30       	lea    0x30(%rsp),%rsi
    4e43:	89 ea                	mov    %ebp,%edx
    4e45:	48 89 44 24 58       	mov    %rax,0x58(%rsp)
    4e4a:	48 8b 44 24 10       	mov    0x10(%rsp),%rax
    4e4f:	4c 89 74 24 68       	mov    %r14,0x68(%rsp)
    4e54:	48 89 44 24 38       	mov    %rax,0x38(%rsp)
    4e59:	48 8b 04 24          	mov    (%rsp),%rax
    4e5d:	4c 89 6c 24 50       	mov    %r13,0x50(%rsp)
    4e62:	48 89 44 24 30       	mov    %rax,0x30(%rsp)
    4e67:	48 89 5c 24 48       	mov    %rbx,0x48(%rsp)
    4e6c:	4c 89 64 24 40       	mov    %r12,0x40(%rsp)
    4e71:	c5 fa 7f 4c 24 78    	vmovdqu %xmm1,0x78(%rsp)
    4e77:	e8 f4 c3 ff ff       	call   1270 <GOMP_parallel@plt>
				}
			}
		}
	}

	free(ptrA);
    4e7c:	4c 89 f7             	mov    %r14,%rdi
    4e7f:	e8 9c c3 ff ff       	call   1220 <free@plt>
	free(ptrB);
    4e84:	48 8b 84 24 98 00 00 	mov    0x98(%rsp),%rax
    4e8b:	00 
    4e8c:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    4e93:	00 00 
    4e95:	75 19                	jne    4eb0 <GEMM_BF16+0x1d0>
}
    4e97:	48 81 c4 a8 00 00 00 	add    $0xa8,%rsp
	free(ptrB);
    4e9e:	4c 89 ff             	mov    %r15,%rdi
}
    4ea1:	5b                   	pop    %rbx
    4ea2:	5d                   	pop    %rbp
    4ea3:	41 5c                	pop    %r12
    4ea5:	41 5d                	pop    %r13
    4ea7:	41 5e                	pop    %r14
    4ea9:	41 5f                	pop    %r15
	free(ptrB);
    4eab:	e9 70 c3 ff ff       	jmp    1220 <free@plt>
    4eb0:	e8 db c2 ff ff       	call   1190 <__stack_chk_fail@plt>
    4eb5:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    4ebc:	00 00 00 00 

0000000000004ec0 <_Z13float_to_bf16f>:
#include <sys/time.h>

static double gtod_ref_time_sec = 0.0;

// floatBF16
uint16_t float_to_bf16(float value) {
    4ec0:	f3 0f 1e fa          	endbr64
    4ec4:	c5 f9 7e c0          	vmovd  %xmm0,%eax
    uint32_t *as_int = (uint32_t*)&value;
    uint16_t bf16_value = (uint16_t)(*as_int >> 16);
    4ec8:	c1 e8 10             	shr    $0x10,%eax
    return bf16_value;
}
    4ecb:	c3                   	ret
    4ecc:	0f 1f 40 00          	nopl   0x0(%rax)

0000000000004ed0 <_Z20generate_random_bf16v>:

// BF16
uint16_t generate_random_bf16() {
    4ed0:	f3 0f 1e fa          	endbr64
    4ed4:	48 83 ec 08          	sub    $0x8,%rsp
    float random_float = ((float)rand() / (float)RAND_MAX); // 01
    4ed8:	e8 a3 c3 ff ff       	call   1280 <rand@plt>
    4edd:	c5 f8 57 c0          	vxorps %xmm0,%xmm0,%xmm0
    4ee1:	c5 fa 2a c0          	vcvtsi2ss %eax,%xmm0,%xmm0
    4ee5:	c5 fa 59 0d 17 11 00 	vmulss 0x1117(%rip),%xmm0,%xmm1        # 6004 <_IO_stdin_used+0x4>
    4eec:	00 
    uint16_t bf16_value = float_to_bf16(random_float);
    return bf16_value;
}
    4eed:	48 83 c4 08          	add    $0x8,%rsp
    float random_float = ((float)rand() / (float)RAND_MAX); // 01
    4ef1:	c5 f9 7e c8          	vmovd  %xmm1,%eax
    uint16_t bf16_value = (uint16_t)(*as_int >> 16);
    4ef5:	c1 e8 10             	shr    $0x10,%eax
}
    4ef8:	c3                   	ret
    4ef9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

0000000000004f00 <_Z10print_bf16t>:

// BF16
void print_bf16(uint16_t bf16_value) {
    4f00:	f3 0f 1e fa          	endbr64
    // BF1632
    uint32_t float_value = bf16_value << 16;
    4f04:	0f b7 d7             	movzwl %di,%edx
    4f07:	c1 e7 10             	shl    $0x10,%edi
  return __printf_chk (__USE_FORTIFY_LEVEL - 1, __fmt, __va_arg_pack ());
    4f0a:	48 8d 35 fb 10 00 00 	lea    0x10fb(%rip),%rsi        # 600c <_IO_stdin_used+0xc>
    4f11:	b8 01 00 00 00       	mov    $0x1,%eax
    float *as_float = (float*)&float_value;
    printf("%-8.3f", bf16_value, *as_float);
    4f16:	c5 f9 6e cf          	vmovd  %edi,%xmm1
    4f1a:	bf 02 00 00 00       	mov    $0x2,%edi
    4f1f:	c5 f2 5a c1          	vcvtss2sd %xmm1,%xmm1,%xmm0
    4f23:	e9 98 c2 ff ff       	jmp    11c0 <__printf_chk@plt>
    4f28:	0f 1f 84 00 00 00 00 	nopl   0x0(%rax,%rax,1)
    4f2f:	00 

0000000000004f30 <_Z12print_bf16_xt>:
}

// BF16,16
void print_bf16_x(uint16_t bf16_value) {
    4f30:	f3 0f 1e fa          	endbr64
    // BF1632
    uint32_t float_value = bf16_value << 16;
    4f34:	0f b7 d7             	movzwl %di,%edx
    4f37:	c1 e7 10             	shl    $0x10,%edi
    4f3a:	48 8d 35 d2 10 00 00 	lea    0x10d2(%rip),%rsi        # 6013 <_IO_stdin_used+0x13>
    4f41:	b8 01 00 00 00       	mov    $0x1,%eax
    float *as_float = (float*)&float_value;
    printf("%-6x", bf16_value, *as_float);
    4f46:	c5 f9 6e cf          	vmovd  %edi,%xmm1
    4f4a:	bf 02 00 00 00       	mov    $0x2,%edi
    4f4f:	c5 f2 5a c1          	vcvtss2sd %xmm1,%xmm1,%xmm0
    4f53:	e9 68 c2 ff ff       	jmp    11c0 <__printf_chk@plt>
    4f58:	0f 1f 84 00 00 00 00 	nopl   0x0(%rax,%rax,1)
    4f5f:	00 

0000000000004f60 <_Z18random_matrix_bf16iiPt>:
}


void random_matrix_bf16(int m, int n, uint16_t *a)
{
    4f60:	f3 0f 1e fa          	endbr64
    4f64:	41 57                	push   %r15
    4f66:	41 56                	push   %r14
    4f68:	41 55                	push   %r13
    4f6a:	41 54                	push   %r12
    4f6c:	55                   	push   %rbp
    4f6d:	53                   	push   %rbx
    4f6e:	48 83 ec 18          	sub    $0x18,%rsp
    4f72:	89 7c 24 04          	mov    %edi,0x4(%rsp)
    int i, j;
    for (i = 0; i < m; i++)
    4f76:	85 ff                	test   %edi,%edi
    4f78:	7e 6c                	jle    4fe6 <_Z18random_matrix_bf16iiPt+0x86>
    4f7a:	41 89 f6             	mov    %esi,%r14d
    4f7d:	49 89 d5             	mov    %rdx,%r13
    4f80:	45 31 e4             	xor    %r12d,%r12d
    4f83:	31 ed                	xor    %ebp,%ebp
        for (j = 0; j < n; j++)
    4f85:	45 85 f6             	test   %r14d,%r14d
    4f88:	7e 6b                	jle    4ff5 <_Z18random_matrix_bf16iiPt+0x95>
    4f8a:	49 63 c6             	movslq %r14d,%rax
    4f8d:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
    4f92:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
    4f98:	48 8b 4c 24 08       	mov    0x8(%rsp),%rcx
    4f9d:	49 63 c4             	movslq %r12d,%rax
    4fa0:	4d 8d 7c 45 00       	lea    0x0(%r13,%rax,2),%r15
    4fa5:	48 01 c8             	add    %rcx,%rax
    4fa8:	49 8d 5c 45 00       	lea    0x0(%r13,%rax,2),%rbx
    4fad:	0f 1f 00             	nopl   (%rax)
    float random_float = ((float)rand() / (float)RAND_MAX); // 01
    4fb0:	e8 cb c2 ff ff       	call   1280 <rand@plt>
    4fb5:	c5 f0 57 c9          	vxorps %xmm1,%xmm1,%xmm1
        for (j = 0; j < n; j++)
    4fb9:	49 83 c7 02          	add    $0x2,%r15
    float random_float = ((float)rand() / (float)RAND_MAX); // 01
    4fbd:	c5 f2 2a c0          	vcvtsi2ss %eax,%xmm1,%xmm0
    4fc1:	c5 fa 59 15 3b 10 00 	vmulss 0x103b(%rip),%xmm0,%xmm2        # 6004 <_IO_stdin_used+0x4>
    4fc8:	00 
    4fc9:	c5 f9 7e d0          	vmovd  %xmm2,%eax
    uint16_t bf16_value = (uint16_t)(*as_int >> 16);
    4fcd:	c1 e8 10             	shr    $0x10,%eax
    4fd0:	66 41 89 47 fe       	mov    %ax,-0x2(%r15)
        for (j = 0; j < n; j++)
    4fd5:	49 39 df             	cmp    %rbx,%r15
    4fd8:	75 d6                	jne    4fb0 <_Z18random_matrix_bf16iiPt+0x50>
    for (i = 0; i < m; i++)
    4fda:	83 c5 01             	add    $0x1,%ebp
    4fdd:	45 01 f4             	add    %r14d,%r12d
    4fe0:	39 6c 24 04          	cmp    %ebp,0x4(%rsp)
    4fe4:	75 b2                	jne    4f98 <_Z18random_matrix_bf16iiPt+0x38>
            a[i * n + j] = (uint16_t)generate_random_bf16();
}
    4fe6:	48 83 c4 18          	add    $0x18,%rsp
    4fea:	5b                   	pop    %rbx
    4feb:	5d                   	pop    %rbp
    4fec:	41 5c                	pop    %r12
    4fee:	41 5d                	pop    %r13
    4ff0:	41 5e                	pop    %r14
    4ff2:	41 5f                	pop    %r15
    4ff4:	c3                   	ret
    for (i = 0; i < m; i++)
    4ff5:	83 c5 01             	add    $0x1,%ebp
    4ff8:	45 01 f4             	add    %r14d,%r12d
    4ffb:	39 6c 24 04          	cmp    %ebp,0x4(%rsp)
    4fff:	75 84                	jne    4f85 <_Z18random_matrix_bf16iiPt+0x25>
    5001:	eb e3                	jmp    4fe6 <_Z18random_matrix_bf16iiPt+0x86>
    5003:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    500a:	00 00 00 00 
    500e:	66 90                	xchg   %ax,%ax

0000000000005010 <_Z17random_matrix_f32iiPf>:

void random_matrix_f32(int m, int n, float *a)
{
    5010:	f3 0f 1e fa          	endbr64
    5014:	41 57                	push   %r15
    5016:	41 56                	push   %r14
    5018:	41 55                	push   %r13
    501a:	41 54                	push   %r12
    501c:	55                   	push   %rbp
    501d:	53                   	push   %rbx
    501e:	48 83 ec 18          	sub    $0x18,%rsp
    5022:	89 7c 24 04          	mov    %edi,0x4(%rsp)
    int i, j;
    for (i = 0; i < m; i++)
    5026:	85 ff                	test   %edi,%edi
    5028:	7e 5e                	jle    5088 <_Z17random_matrix_f32iiPf+0x78>
    502a:	41 89 f6             	mov    %esi,%r14d
    502d:	49 89 d5             	mov    %rdx,%r13
    5030:	45 31 e4             	xor    %r12d,%r12d
    5033:	31 ed                	xor    %ebp,%ebp
        for (j = 0; j < n; j++)
    5035:	45 85 f6             	test   %r14d,%r14d
    5038:	7e 5d                	jle    5097 <_Z17random_matrix_f32iiPf+0x87>
    503a:	49 63 c6             	movslq %r14d,%rax
    503d:	48 89 44 24 08       	mov    %rax,0x8(%rsp)
    5042:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)
    5048:	48 8b 4c 24 08       	mov    0x8(%rsp),%rcx
    504d:	49 63 c4             	movslq %r12d,%rax
    5050:	4d 8d 7c 85 00       	lea    0x0(%r13,%rax,4),%r15
    5055:	48 01 c8             	add    %rcx,%rax
    5058:	49 8d 5c 85 00       	lea    0x0(%r13,%rax,4),%rbx
    505d:	0f 1f 00             	nopl   (%rax)
            a[i * n + j] = (float)rand();
    5060:	e8 1b c2 ff ff       	call   1280 <rand@plt>
    5065:	c5 f0 57 c9          	vxorps %xmm1,%xmm1,%xmm1
        for (j = 0; j < n; j++)
    5069:	49 83 c7 04          	add    $0x4,%r15
            a[i * n + j] = (float)rand();
    506d:	c5 f2 2a c0          	vcvtsi2ss %eax,%xmm1,%xmm0
    5071:	c4 c1 7a 11 47 fc    	vmovss %xmm0,-0x4(%r15)
        for (j = 0; j < n; j++)
    5077:	49 39 df             	cmp    %rbx,%r15
    507a:	75 e4                	jne    5060 <_Z17random_matrix_f32iiPf+0x50>
    for (i = 0; i < m; i++)
    507c:	83 c5 01             	add    $0x1,%ebp
    507f:	45 01 f4             	add    %r14d,%r12d
    5082:	39 6c 24 04          	cmp    %ebp,0x4(%rsp)
    5086:	75 c0                	jne    5048 <_Z17random_matrix_f32iiPf+0x38>
}
    5088:	48 83 c4 18          	add    $0x18,%rsp
    508c:	5b                   	pop    %rbx
    508d:	5d                   	pop    %rbp
    508e:	41 5c                	pop    %r12
    5090:	41 5d                	pop    %r13
    5092:	41 5e                	pop    %r14
    5094:	41 5f                	pop    %r15
    5096:	c3                   	ret
    for (i = 0; i < m; i++)
    5097:	83 c5 01             	add    $0x1,%ebp
    509a:	45 01 f4             	add    %r14d,%r12d
    509d:	39 6c 24 04          	cmp    %ebp,0x4(%rsp)
    50a1:	75 92                	jne    5035 <_Z17random_matrix_f32iiPf+0x25>
    50a3:	eb e3                	jmp    5088 <_Z17random_matrix_f32iiPf+0x78>
    50a5:	66 66 2e 0f 1f 84 00 	data16 cs nopw 0x0(%rax,%rax,1)
    50ac:	00 00 00 00 

00000000000050b0 <_Z18regular_matrix_f32iiPf>:

void regular_matrix_f32(int m, int n, float *a)
{
    50b0:	f3 0f 1e fa          	endbr64
    int i, j;
    for (i = 0; i < m; i++)
    50b4:	85 ff                	test   %edi,%edi
    50b6:	7e 73                	jle    512b <_Z18regular_matrix_f32iiPf+0x7b>
    50b8:	45 31 c9             	xor    %r9d,%r9d
    50bb:	45 31 c0             	xor    %r8d,%r8d
        for (j = 0; j < n; j++)
    50be:	85 f6                	test   %esi,%esi
    50c0:	7e 5d                	jle    511f <_Z18regular_matrix_f32iiPf+0x6f>
    50c2:	c5 fa 10 05 3e 0f 00 	vmovss 0xf3e(%rip),%xmm0        # 6008 <_IO_stdin_used+0x8>
    50c9:	00 
    50ca:	4c 63 de             	movslq %esi,%r11
    50cd:	0f 1f 00             	nopl   (%rax)
    50d0:	49 63 c9             	movslq %r9d,%rcx
    50d3:	48 8d 04 8a          	lea    (%rdx,%rcx,4),%rax
    50d7:	4c 01 d9             	add    %r11,%rcx
    50da:	48 8d 0c 8a          	lea    (%rdx,%rcx,4),%rcx
    50de:	49 89 ca             	mov    %rcx,%r10
    50e1:	49 29 c2             	sub    %rax,%r10
    50e4:	41 83 e2 04          	and    $0x4,%r10d
    50e8:	74 16                	je     5100 <_Z18regular_matrix_f32iiPf+0x50>
            a[i * n + j] = (1.0);
    50ea:	c5 fa 11 00          	vmovss %xmm0,(%rax)
        for (j = 0; j < n; j++)
    50ee:	48 83 c0 04          	add    $0x4,%rax
    50f2:	48 39 c8             	cmp    %rcx,%rax
    50f5:	74 1b                	je     5112 <_Z18regular_matrix_f32iiPf+0x62>
    50f7:	66 0f 1f 84 00 00 00 	nopw   0x0(%rax,%rax,1)
    50fe:	00 00 
            a[i * n + j] = (1.0);
    5100:	c5 fa 11 00          	vmovss %xmm0,(%rax)
        for (j = 0; j < n; j++)
    5104:	48 83 c0 08          	add    $0x8,%rax
            a[i * n + j] = (1.0);
    5108:	c5 fa 11 40 fc       	vmovss %xmm0,-0x4(%rax)
        for (j = 0; j < n; j++)
    510d:	48 39 c8             	cmp    %rcx,%rax
    5110:	75 ee                	jne    5100 <_Z18regular_matrix_f32iiPf+0x50>
    for (i = 0; i < m; i++)
    5112:	41 83 c0 01          	add    $0x1,%r8d
    5116:	41 01 f1             	add    %esi,%r9d
    5119:	44 39 c7             	cmp    %r8d,%edi
    511c:	75 b2                	jne    50d0 <_Z18regular_matrix_f32iiPf+0x20>
    511e:	c3                   	ret
    511f:	41 83 c0 01          	add    $0x1,%r8d
    5123:	41 01 f1             	add    %esi,%r9d
    5126:	44 39 c7             	cmp    %r8d,%edi
    5129:	75 93                	jne    50be <_Z18regular_matrix_f32iiPf+0xe>
}
    512b:	c3                   	ret
    512c:	0f 1f 40 00          	nopl   0x0(%rax)

0000000000005130 <_Z19regular_matrix_bf16iiPt>:

void regular_matrix_bf16(int m, int n, uint16_t *a)
{
    5130:	f3 0f 1e fa          	endbr64
    int i, j;
    for (i = 0; i < m; i++)
    5134:	85 ff                	test   %edi,%edi
    5136:	0f 8e 7c 00 00 00    	jle    51b8 <_Z19regular_matrix_bf16iiPt+0x88>
    513c:	45 31 c9             	xor    %r9d,%r9d
    513f:	45 31 c0             	xor    %r8d,%r8d
        for (j = 0; j < n; j++)
    5142:	85 f6                	test   %esi,%esi
    5144:	7e 66                	jle    51ac <_Z19regular_matrix_bf16iiPt+0x7c>
    5146:	4c 63 de             	movslq %esi,%r11
    5149:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)
    5150:	49 63 c9             	movslq %r9d,%rcx
    5153:	48 8d 04 4a          	lea    (%rdx,%rcx,2),%rax
    5157:	4c 01 d9             	add    %r11,%rcx
    515a:	48 8d 0c 4a          	lea    (%rdx,%rcx,2),%rcx
    515e:	49 89 ca             	mov    %rcx,%r10
    5161:	49 29 c2             	sub    %rax,%r10
    5164:	41 83 e2 02          	and    $0x2,%r10d
    5168:	74 16                	je     5180 <_Z19regular_matrix_bf16iiPt+0x50>
            a[i * n + j] = float_to_bf16(1);
    516a:	41 ba 80 3f 00 00    	mov    $0x3f80,%r10d
        for (j = 0; j < n; j++)
    5170:	48 83 c0 02          	add    $0x2,%rax
            a[i * n + j] = float_to_bf16(1);
    5174:	66 44 89 50 fe       	mov    %r10w,-0x2(%rax)
        for (j = 0; j < n; j++)
    5179:	48 39 c1             	cmp    %rax,%rcx
    517c:	74 21                	je     519f <_Z19regular_matrix_bf16iiPt+0x6f>
    517e:	66 90                	xchg   %ax,%ax
            a[i * n + j] = float_to_bf16(1);
    5180:	41 ba 80 3f 00 00    	mov    $0x3f80,%r10d
        for (j = 0; j < n; j++)
    5186:	48 83 c0 04          	add    $0x4,%rax
            a[i * n + j] = float_to_bf16(1);
    518a:	66 44 89 50 fc       	mov    %r10w,-0x4(%rax)
    518f:	41 ba 80 3f 00 00    	mov    $0x3f80,%r10d
    5195:	66 44 89 50 fe       	mov    %r10w,-0x2(%rax)
        for (j = 0; j < n; j++)
    519a:	48 39 c1             	cmp    %rax,%rcx
    519d:	75 e1                	jne    5180 <_Z19regular_matrix_bf16iiPt+0x50>
    for (i = 0; i < m; i++)
    519f:	41 83 c0 01          	add    $0x1,%r8d
    51a3:	41 01 f1             	add    %esi,%r9d
    51a6:	44 39 c7             	cmp    %r8d,%edi
    51a9:	75 a5                	jne    5150 <_Z19regular_matrix_bf16iiPt+0x20>
    51ab:	c3                   	ret
    51ac:	41 83 c0 01          	add    $0x1,%r8d
    51b0:	41 01 f1             	add    %esi,%r9d
    51b3:	44 39 c7             	cmp    %r8d,%edi
    51b6:	75 8a                	jne    5142 <_Z19regular_matrix_bf16iiPt+0x12>
}
    51b8:	c3                   	ret
    51b9:	0f 1f 80 00 00 00 00 	nopl   0x0(%rax)

00000000000051c0 <_Z16show_matrix_fp32llPf>:

void show_matrix_fp32(long m, long n, float *a)
{
    51c0:	f3 0f 1e fa          	endbr64
    51c4:	41 57                	push   %r15
    51c6:	41 56                	push   %r14
    51c8:	41 55                	push   %r13
    51ca:	41 54                	push   %r12
    51cc:	55                   	push   %rbp
    51cd:	53                   	push   %rbx
    51ce:	48 83 ec 18          	sub    $0x18,%rsp
    51d2:	48 89 7c 24 08       	mov    %rdi,0x8(%rsp)
	long i, j;
	for (i = 0; i < m; i++){
    51d7:	48 85 ff             	test   %rdi,%rdi
    51da:	7e 61                	jle    523d <_Z16show_matrix_fp32llPf+0x7d>
    51dc:	48 89 f5             	mov    %rsi,%rbp
    51df:	48 89 d3             	mov    %rdx,%rbx
    51e2:	4c 8d 25 2f 0e 00 00 	lea    0xe2f(%rip),%r12        # 6018 <_IO_stdin_used+0x18>
    51e9:	45 31 ed             	xor    %r13d,%r13d
    51ec:	4c 8d 3c b5 00 00 00 	lea    0x0(,%rsi,4),%r15
    51f3:	00 
    51f4:	0f 1f 40 00          	nopl   0x0(%rax)
		for (j = 0; j < n; j++)
    51f8:	45 31 f6             	xor    %r14d,%r14d
    51fb:	48 85 ed             	test   %rbp,%rbp
    51fe:	7e 25                	jle    5225 <_Z16show_matrix_fp32llPf+0x65>
			printf("%-8.2f", a[i * n + j]);
    5200:	c5 f1 57 c9          	vxorpd %xmm1,%xmm1,%xmm1
    5204:	4c 89 e6             	mov    %r12,%rsi
    5207:	bf 02 00 00 00       	mov    $0x2,%edi
    520c:	b8 01 00 00 00       	mov    $0x1,%eax
    5211:	c4 a1 72 5a 04 b3    	vcvtss2sd (%rbx,%r14,4),%xmm1,%xmm0
    5217:	e8 a4 bf ff ff       	call   11c0 <__printf_chk@plt>
		for (j = 0; j < n; j++)
    521c:	49 83 c6 01          	add    $0x1,%r14
    5220:	4c 39 f5             	cmp    %r14,%rbp
    5223:	75 db                	jne    5200 <_Z16show_matrix_fp32llPf+0x40>
    5225:	bf 0a 00 00 00       	mov    $0xa,%edi
	for (i = 0; i < m; i++){
    522a:	49 83 c5 01          	add    $0x1,%r13
    522e:	4c 01 fb             	add    %r15,%rbx
    5231:	e8 aa bf ff ff       	call   11e0 <putchar@plt>
    5236:	4c 39 6c 24 08       	cmp    %r13,0x8(%rsp)
    523b:	75 bb                	jne    51f8 <_Z16show_matrix_fp32llPf+0x38>
		printf("\n");
	}
		
}
    523d:	48 83 c4 18          	add    $0x18,%rsp
    5241:	5b                   	pop    %rbx
    5242:	5d                   	pop    %rbp
    5243:	41 5c                	pop    %r12
    5245:	41 5d                	pop    %r13
    5247:	41 5e                	pop    %r14
    5249:	41 5f                	pop    %r15
    524b:	c3                   	ret
    524c:	0f 1f 40 00          	nopl   0x0(%rax)

0000000000005250 <_Z16show_matrix_bf16llPt>:

void show_matrix_bf16(long m, long n, uint16_t *a)
{
    5250:	f3 0f 1e fa          	endbr64
    5254:	41 57                	push   %r15
    5256:	41 56                	push   %r14
    5258:	41 55                	push   %r13
    525a:	41 54                	push   %r12
    525c:	55                   	push   %rbp
    525d:	53                   	push   %rbx
    525e:	48 83 ec 28          	sub    $0x28,%rsp
    5262:	48 89 7c 24 10       	mov    %rdi,0x10(%rsp)
    5267:	48 89 54 24 08       	mov    %rdx,0x8(%rsp)
	long i, j;
	for (i = 0; i < m; i++){
    526c:	48 85 ff             	test   %rdi,%rdi
    526f:	7e 7b                	jle    52ec <_Z16show_matrix_bf16llPt+0x9c>
    5271:	48 8d 04 36          	lea    (%rsi,%rsi,1),%rax
    5275:	49 89 f6             	mov    %rsi,%r14
    5278:	45 31 ed             	xor    %r13d,%r13d
    527b:	45 31 e4             	xor    %r12d,%r12d
    527e:	48 89 44 24 18       	mov    %rax,0x18(%rsp)
    5283:	48 8d 1c 02          	lea    (%rdx,%rax,1),%rbx
    5287:	48 8d 2d 85 0d 00 00 	lea    0xd85(%rip),%rbp        # 6013 <_IO_stdin_used+0x13>
    528e:	66 90                	xchg   %ax,%ax
		for (j = 0; j < n; j++)
    5290:	48 8b 44 24 08       	mov    0x8(%rsp),%rax
    5295:	4e 8d 3c 68          	lea    (%rax,%r13,2),%r15
    5299:	4d 85 f6             	test   %r14,%r14
    529c:	7e 2e                	jle    52cc <_Z16show_matrix_bf16llPt+0x7c>
    529e:	66 90                	xchg   %ax,%ax
    uint32_t float_value = bf16_value << 16;
    52a0:	41 0f b7 17          	movzwl (%r15),%edx
    52a4:	48 89 ee             	mov    %rbp,%rsi
    52a7:	bf 02 00 00 00       	mov    $0x2,%edi
		for (j = 0; j < n; j++)
    52ac:	49 83 c7 02          	add    $0x2,%r15
    uint32_t float_value = bf16_value << 16;
    52b0:	89 d0                	mov    %edx,%eax
    52b2:	c1 e0 10             	shl    $0x10,%eax
    52b5:	c5 f9 6e c0          	vmovd  %eax,%xmm0
    52b9:	b8 01 00 00 00       	mov    $0x1,%eax
    printf("%-6x", bf16_value, *as_float);
    52be:	c5 fa 5a c0          	vcvtss2sd %xmm0,%xmm0,%xmm0
    52c2:	e8 f9 be ff ff       	call   11c0 <__printf_chk@plt>
		for (j = 0; j < n; j++)
    52c7:	49 39 df             	cmp    %rbx,%r15
    52ca:	75 d4                	jne    52a0 <_Z16show_matrix_bf16llPt+0x50>
    52cc:	bf 0a 00 00 00       	mov    $0xa,%edi
	for (i = 0; i < m; i++){
    52d1:	49 83 c4 01          	add    $0x1,%r12
    52d5:	4d 01 f5             	add    %r14,%r13
    52d8:	e8 03 bf ff ff       	call   11e0 <putchar@plt>
    52dd:	48 8b 44 24 18       	mov    0x18(%rsp),%rax
    52e2:	48 01 c3             	add    %rax,%rbx
    52e5:	4c 39 64 24 10       	cmp    %r12,0x10(%rsp)
    52ea:	75 a4                	jne    5290 <_Z16show_matrix_bf16llPt+0x40>
			print_bf16_x(a[i * n + j]);
		printf("\n");
	}
		
}
    52ec:	48 83 c4 28          	add    $0x28,%rsp
    52f0:	5b                   	pop    %rbx
    52f1:	5d                   	pop    %rbp
    52f2:	41 5c                	pop    %r12
    52f4:	41 5d                	pop    %r13
    52f6:	41 5e                	pop    %r14
    52f8:	41 5f                	pop    %r15
    52fa:	c3                   	ret
    52fb:	0f 1f 44 00 00       	nopl   0x0(%rax,%rax,1)

0000000000005300 <_Z6dclockv>:

double dclock()
{
    5300:	f3 0f 1e fa          	endbr64
    5304:	48 83 ec 28          	sub    $0x28,%rsp
	double the_time, norm_sec;
	struct timeval tv;

	gettimeofday(&tv, NULL);
    5308:	31 f6                	xor    %esi,%esi
{
    530a:	64 48 8b 04 25 28 00 	mov    %fs:0x28,%rax
    5311:	00 00 
    5313:	48 89 44 24 18       	mov    %rax,0x18(%rsp)
    5318:	31 c0                	xor    %eax,%eax
	gettimeofday(&tv, NULL);
    531a:	48 89 e7             	mov    %rsp,%rdi
    531d:	e8 1e bf ff ff       	call   1240 <gettimeofday@plt>

	if (gtod_ref_time_sec == 0.0)
    5322:	c5 f1 57 c9          	vxorpd %xmm1,%xmm1,%xmm1
    5326:	c5 fb 10 15 f2 2c 00 	vmovsd 0x2cf2(%rip),%xmm2        # 8020 <_ZL17gtod_ref_time_sec>
    532d:	00 
    532e:	c5 f8 57 c0          	vxorps %xmm0,%xmm0,%xmm0
    5332:	c5 f9 2e d1          	vucomisd %xmm1,%xmm2
		gtod_ref_time_sec = (double)tv.tv_sec;
    5336:	c4 e1 fb 2a 0c 24    	vcvtsi2sdq (%rsp),%xmm0,%xmm1
	if (gtod_ref_time_sec == 0.0)
    533c:	7a 0e                	jp     534c <_Z6dclockv+0x4c>
    533e:	75 0c                	jne    534c <_Z6dclockv+0x4c>
		gtod_ref_time_sec = (double)tv.tv_sec;
    5340:	c5 fb 11 0d d8 2c 00 	vmovsd %xmm1,0x2cd8(%rip)        # 8020 <_ZL17gtod_ref_time_sec>
    5347:	00 
    5348:	c5 f3 10 d1          	vmovsd %xmm1,%xmm1,%xmm2

	norm_sec = (double)tv.tv_sec - gtod_ref_time_sec;

	the_time = norm_sec + tv.tv_usec * 1.0e-6;
    534c:	c4 e1 fb 2a 44 24 08 	vcvtsi2sdq 0x8(%rsp),%xmm0,%xmm0
	norm_sec = (double)tv.tv_sec - gtod_ref_time_sec;
    5353:	c5 f3 5c ca          	vsubsd %xmm2,%xmm1,%xmm1
	the_time = norm_sec + tv.tv_usec * 1.0e-6;
    5357:	c4 e2 f1 99 05 a0 0d 	vfmadd132sd 0xda0(%rip),%xmm1,%xmm0        # 6100 <_IO_stdin_used+0x100>
    535e:	00 00 

	return the_time;
}
    5360:	48 8b 44 24 18       	mov    0x18(%rsp),%rax
    5365:	64 48 2b 04 25 28 00 	sub    %fs:0x28,%rax
    536c:	00 00 
    536e:	75 05                	jne    5375 <_Z6dclockv+0x75>
    5370:	48 83 c4 28          	add    $0x28,%rsp
    5374:	c3                   	ret
    5375:	e8 16 be ff ff       	call   1190 <__stack_chk_fail@plt>
    537a:	66 0f 1f 44 00 00    	nopw   0x0(%rax,%rax,1)

0000000000005380 <_Z12Check_resultPfS_ll>:

int Check_result(float *C, float *C1, long M, long N)
{
    5380:	f3 0f 1e fa          	endbr64

  int i, j, flag = 0;

  for (i = 0; i < M; i++)
    5384:	48 85 d2             	test   %rdx,%rdx
    5387:	0f 8e cd 00 00 00    	jle    545a <_Z12Check_resultPfS_ll+0xda>
{
    538d:	55                   	push   %rbp
    538e:	4c 8d 0c 8d 00 00 00 	lea    0x0(,%rcx,4),%r9
    5395:	00 
  for (i = 0; i < M; i++)
    5396:	45 31 c0             	xor    %r8d,%r8d
{
    5399:	53                   	push   %rbx
    539a:	48 83 ec 08          	sub    $0x8,%rsp
    539e:	c5 fb 10 0d 62 0d 00 	vmovsd 0xd62(%rip),%xmm1        # 6108 <_IO_stdin_used+0x108>
    53a5:	00 
    53a6:	c5 fa 10 15 82 0d 00 	vmovss 0xd82(%rip),%xmm2        # 6130 <_IO_stdin_used+0x130>
    53ad:	00 
  {
    for (j = 0; j < N; j++)
    53ae:	48 89 fd             	mov    %rdi,%rbp
    53b1:	48 89 f3             	mov    %rsi,%rbx
    53b4:	31 c0                	xor    %eax,%eax
    53b6:	48 85 c9             	test   %rcx,%rcx
    53b9:	7f 16                	jg     53d1 <_Z12Check_resultPfS_ll+0x51>
    53bb:	e9 80 00 00 00       	jmp    5440 <_Z12Check_resultPfS_ll+0xc0>
    53c0:	48 83 c0 01          	add    $0x1,%rax
    53c4:	48 83 c3 04          	add    $0x4,%rbx
    53c8:	48 83 c5 04          	add    $0x4,%rbp
    53cc:	48 39 c1             	cmp    %rax,%rcx
    53cf:	74 6f                	je     5440 <_Z12Check_resultPfS_ll+0xc0>
    {
      if (abs(C[i * N + j] - C1[i * N + j]) > 1e-3)
    53d1:	c5 fa 10 45 00       	vmovss 0x0(%rbp),%xmm0
    53d6:	c5 fa 5c 03          	vsubss (%rbx),%xmm0,%xmm0
  abs(double __x)
  { return __builtin_fabs(__x); }

  inline _GLIBCXX_CONSTEXPR float
  abs(float __x)
  { return __builtin_fabsf(__x); }
    53da:	c5 f8 54 c2          	vandps %xmm2,%xmm0,%xmm0
    53de:	c5 fa 5a c0          	vcvtss2sd %xmm0,%xmm0,%xmm0
    53e2:	c5 f9 2f c1          	vcomisd %xmm1,%xmm0
    53e6:	76 d8                	jbe    53c0 <_Z12Check_resultPfS_ll+0x40>
    53e8:	89 c1                	mov    %eax,%ecx
    53ea:	44 89 c2             	mov    %r8d,%edx
    53ed:	bf 02 00 00 00       	mov    $0x2,%edi
    53f2:	31 c0                	xor    %eax,%eax
    53f4:	48 8d 35 24 0c 00 00 	lea    0xc24(%rip),%rsi        # 601f <_IO_stdin_used+0x1f>
    53fb:	e8 c0 bd ff ff       	call   11c0 <__printf_chk@plt>
      {
        printf("i = %-10d, j= %-10d\n", i, j);
        printf("C= %.3lf , C1= %.3lf\n", C[i * N + j], C1[i * N + j]);
    5400:	c5 f0 57 c9          	vxorps %xmm1,%xmm1,%xmm1
    5404:	bf 02 00 00 00       	mov    $0x2,%edi
    5409:	48 8d 35 24 0c 00 00 	lea    0xc24(%rip),%rsi        # 6034 <_IO_stdin_used+0x34>
    5410:	b8 02 00 00 00       	mov    $0x2,%eax
    5415:	c5 f2 5a 45 00       	vcvtss2sd 0x0(%rbp),%xmm1,%xmm0
    541a:	c5 f2 5a 0b          	vcvtss2sd (%rbx),%xmm1,%xmm1
    541e:	e8 9d bd ff ff       	call   11c0 <__printf_chk@plt>
    5423:	48 8d 3d 20 0c 00 00 	lea    0xc20(%rip),%rdi        # 604a <_IO_stdin_used+0x4a>
    542a:	e8 61 be ff ff       	call   1290 <puts@plt>
        printf("!\n");
        return 0;
    542f:	31 c0                	xor    %eax,%eax
      }
    }
  }
  // printf("\n");
  return 1;
}
    5431:	48 83 c4 08          	add    $0x8,%rsp
    5435:	5b                   	pop    %rbx
    5436:	5d                   	pop    %rbp
    5437:	c3                   	ret
    5438:	0f 1f 84 00 00 00 00 	nopl   0x0(%rax,%rax,1)
    543f:	00 
  for (i = 0; i < M; i++)
    5440:	49 83 c0 01          	add    $0x1,%r8
    5444:	4c 01 ce             	add    %r9,%rsi
    5447:	4c 01 cf             	add    %r9,%rdi
    544a:	49 39 d0             	cmp    %rdx,%r8
    544d:	0f 85 5b ff ff ff    	jne    53ae <_Z12Check_resultPfS_ll+0x2e>
  return 1;
    5453:	b8 01 00 00 00       	mov    $0x1,%eax
    5458:	eb d7                	jmp    5431 <_Z12Check_resultPfS_ll+0xb1>
    545a:	b8 01 00 00 00       	mov    $0x1,%eax
}
    545f:	c3                   	ret

Disassembly of section .fini:

0000000000005460 <_fini>:
    5460:	f3 0f 1e fa          	endbr64
    5464:	48 83 ec 08          	sub    $0x8,%rsp
    5468:	48 83 c4 08          	add    $0x8,%rsp
    546c:	c3                   	ret
